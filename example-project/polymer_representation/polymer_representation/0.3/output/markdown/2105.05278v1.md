# Polygrammar: Grammar for Digital Polymer Representation and Generation

## 1. Introduction



Polymers are important materials with diverse structure variations, and applications. To facilitate customized applications and deepen the fundamental understanding, it is ex- tremely beneficial to characterize, enumerate, and explore the full space of achievable poly- mer structures. Such a large (ideally exhaustive) collection of polymers would be particularly powerful in conjunction with machine learning and numerical simulation techniques, as a way to facilitate complicated tasks like human-guided molecular exploration[1-12], property predic- tion[13-17], and retro-synthesis[18,19]. Computational approaches based on chemical representa- tions and generated data[20-27] have also tremendously reduced the time, cost, and resources spent on physical synthesis in the chemistry lab[28-31]

Ideally, a chemical design model would include three components: (1) a well-defined representation capable of capturing known structures, (2) a generative model capable of enu- merating all structures in a given class, and (3) an inverse modeling procedure capable of translating known molecular structures into the representation. For a given class of molecules, an ideal chemical design model should satisfy the following five criteria: i. Complete: repre- sentation is able to encode all possible structures in the given class. ii. Explicit: representation directly specifies the molecular structure. iii. Valid: every generated output is a physically valid chemical structure in the given class. iv. Explainable: the generation process is under- standable to the user. v. Invertible: the inverse procedure can translate molecular structures into the given representation. However, designing a chemical model that meets all these crite- ria is challenging, especially for structurally complex molecules. Most existing approaches are limited to small, simple chemical structures[32-36]. Even with this limited scope, the design is labor intensive: the representation language is typically developed first, then extended for generation and inverse modeling. In particular, there have been many systems for molecular

2

line notations[32,33] and fragment-level description[34,35], which were then used as the basis for generative and inverse schemes[5-8]

Yet, a comprehensive chemical design model for large polymers remains elusive due to the polymers' inherent complexity. We present a detailed account for each property, includ- ing polymer-specific challenges and the performance of existing methods (see Table 1). Some of the most popular methods like SMILES and BigSMILES are only partial design models, as they define a representation but not a generative model. In this case, we assume the simplest generative model for our comparison: randomly chosen strings of permissible symbols. Other chemical design models like auto-encoders (AE)[5-8,36] have a direct mapping to our frame- work: the learned latent space is the representation, the decoder is the generative model, and the encoder is the inverse model. After exploring the state of the art for all five properties, we give an overview of our proposed approach.

Table 1. Comparison with related chemical design models. Since SMILES and BigSMILES only explicitly provide a representation, we assume the simplest generative modeling scheme: randomly choosing strings of permissible symbols. Our PolyGrammar is the only approach that satisfies all five properties.



||Representation||Generative Modeling||Inverse Modeling|
|---|---|---|---|---|---|
|Methods|Complete|Explicit|Valid|Explainable|Translation from SMILES|
|SMILES[28]|√
:selected:|√
:selected:|×
:selected:|√
:selected:|√
:selected:|
|BigSMILES[33]|√
:selected:|×
:selected:|×
:selected:|×
:selected:|√
:selected:|
|Auto-Encoders[5-8, 36]|×
:selected:|×
:selected:|×
:selected:|×
:selected:|√
:selected:|
|PolyGrammar|√
:selected:|√
:selected:|√
:selected:|√
:selected:|√
:selected:|


3

bis(phenyl isocyanate) (MDI) and poly(oxytetramethylene) diol (PTMO). Consider one possi- ble outcome of chain length 6, where chain length is defined as the sum of MDI and PTMO units. Disregarding more nuanced chemical restrictions (which are beyond the scope of this paper), any arrangement of the 3 MDI and 3 PTMO units is equally valid. Thus, for a chain of length 20, the component permutations can result in more than (20) ~ 105 possible struc- tures. This vast set of structures makes it challenging to design a complete and concise poly- mer representation. Some existing line notations[28-34] including SMILES[28] (designed for general molecules) and BigSMILES[33] (specifically designed for large polymers) are com- plete representations, since they can convert any given polymer structure instance into the form of strings. However, schemes relying on auto-encoders (AE) are not guaranteed to sat- isfy this property since the learned representation spaces (numeric vectors called latent varia- bles) may exclude polymer structures that do not exist in training data.

Explicit. The properties of a polymeric material are largely determined by the struc- ture of the polymer itself, including the identity and arrangement of its constituent mono- mers[37-39]. Thus, it is useful to have an explicit representation for polymers, in which specific structural information is directly expressed and easily understood. This is challenging because a polymer must be understood on many scales, including the overarching structure of repeated units, and the individual molecular and atomic sub-units that comprise them.

Low-level representations like SMILES are able to depict explicit polymeric struc- tures, but the strings are typically hard to parse due to their length. For example, the canonical SMILES representation for the polyurethane chain of length 30 (5 repetitions of the 6-length chain described above) requires more than 600 characters. By contrast, most representations designed for large polymers[32-34] are so high-level that they are unable to provide explicit in- formation about the complete polymer structure. For example, BigSMILES can express the constituent monomers and the bonding descriptions between them, but it cannot specify the

4

detailed arrangement of the polymer's components. As for the AE, the latent variable is an implicit representation and it is impractical to understand the polymer structures merely from the numeric vector.

Valid. Generative models that build on a well-defined representation scheme are highly coveted[40], particularly for their ability to efficiently build large corpora of example structures. However, the result is only useful if the examples generated by the model are guar- anteed to be chemically valid. This is challenging to enforce for polymers, as there are many hard chemical constraints (e.g., valency conditions) and other restrictions to account for. The likelihood of violating these constraints increases as the target molecules get larger.

Machine learning techniques including support vector machines (SVM)[41], recurrent neural networks (RNN)[1-4], generative adversarial networks (GAN)[9-12], and AE have been used as generative models for molecules. However, these methods often produce outputs that are chemically invalid, even when limited to small molecules. It is even more challenging for these methods to generate valid polymers, due to the large number of generation steps re- quired to realize such large molecules. Although several recent efforts based on AE[35,36] and reinforcement learning (RL)[42,43] have been proposed to produce valid polymers, it is not clear how well they generalize - i.e., the AE may be unable to ensure validity when generat- ing polymers that significantly deviate from the training data. Non-learning methods also struggle to enforce validity, particularly with simple probabilistic generative models - e.g., randomly choosing SMILES/BigSMILES strings. Even with additional considerations for line notation syntax and additional semantic constraints, these probabilistic generation schemes can produce invalid line notations[44]

Explainable. To ensure confidence in the results of the generative model, the genera- tion process itself must be fully transparent and understandable to chemists. This property is not necessarily more challenging for large polymers (compared to small molecules), but it is

5

much more critical to facilitate understanding of the resulting polymer structure. Interpretable generation processes also aid the exploration of possible polymer variations.

AE and other deep learning based generative models[1-4,9,10,45] produce structures based on implicit latent variables. These models are effectively black-box functions that cannot be easily interpreted. By contrast, the generative model of SMILES can be interpreted since each generated symbol has an explainable meaning: it either indicates the type of the generated atom, or the bonding relationship. The generative model based on BigSMILES is not explain- able since it cannot show the detailed arrangement of constituent monomers.

Invertible. When designing a new chemical design model, it is critical to ensure com- patibility with existing notations. In particular, it should be possible (via an inverse modelling procedure) to translate any final representation from an existing scheme into the proposed representation. This inverse procedure should yield the same process and final representation as if the structure were created via the integrated generative model. This is critical for two rea- sons: (i) it makes existing knowledge accessible in the new representation, and (ii) it confirms the representative power of the new chemical design model.

To judge invertibility for polymer models, we consider translation from one of the most popular molecule notations: SMILES. As shown in Table 1, invertibility is already an important feature common to many existing methods. For example, the encoder of a chemical AE takes a SMILES string as input, then outputs the corresponding latent variable. Big- SMILES is built directly upon SMILES so it can easily covert SMILES strings of polymers into the BigSMILES representation. When building our own representation, we also consider "invertibility" with respect to the SMILES format. However, in principle, it is possible to de- sign inverse procedures that translate from other existing representations schemes as well.

Our Approach. In this paper, we propose a new chemical design model for polymers that respects all five of the ideal properties discussed above. We introduce PolyGrammar, a

6

parametric context-sensitive grammar for polymers. In formal language theory, a grammar describes how to build strings from a language's alphabet following a set of production rules. PolyGrammar represents the chain structure as a hypergraph. In particular, each polymer chain is represented as a string of symbols, each of which refers to a particular molecular frag- ment of the original chain. This symbolic hypergraph representation supports explicit descrip- tions for infinite amount of diversely structured polymer chains by changing the form of sym- bolic strings.

Based on this representation, we establish a set of production rules that can effectively generate chemically valid symbolic strings. The recursive nature of grammar production makes it possible to generate any polymer in our given class using only a simple set of pro- duction rules. In particular, it is possible for PolyGrammar to enumerate all valid polymers structures within a given class.

Extract Rules



||PolyGrammar||
|---|---|---|
||IP1: None < > > None: None > hH(L)h||
||ip2: None < X' > None: None -> sS(L)s||
||HP3: None|<h > H(r): > > > hH(x -1)|
||P4: None <|h > H(x): x > > (x -1)|
||ip5: None|< h > H(x): x <1 > Null|
||ip6: None|<s > S(x): x ≥1 > hH(x -1)|
||ip7: None|<s > S(x): x ≥ 1 -> sS(x - 1)|
||ips: None|<s > S(x): x <1 -> Null|
||Pg: H(x) <|h > None: > > > H(x - 1)h|
||P10: H(x) <|h > None: x > > S(x - 1)s|
||P11: H(x)|<h > None: x < 1 -> Null|
||IP12: S(x) <|3 > None: x > > H(x - 1)h|
||HP13: S(x)
:selected:|<s > None: x ≥ 1 -> S(x - 1)s|
||HP14: S(x)|<s > None: x < 1 -> Null|
|||…|


=c=N

HN

P10, P3

hHHSs

. HSHASHs

P4, P12

-

0=

NH

ZI

NH

..

4

HyperGraph Conversion

HSSHASHISH

I

`=C=0

Figure 1. Schematic of our chemistry design model, PolyGrammar, which represents molecular chain structure as a string of symbols (center). PolyGrammar consists of a set of production rules {pili = 1, ... ,14} (left). The generation process starts from an initial symbol X. At each iteration, each non-terminal symbol (h, s or X) in the current string is replaced by the successor of a production rule whose predecessor matches the symbol. The generation process concludes when the string does not contain any non-terminal symbols. The resulting symbol string (center) is then translated to a polymer chain (right) by hypergraph conversion.

As a demonstrative example, we focus on a particular class of polymers: polyure-

thanes. We choose polyurethanes due to their wide-ranging applications, including antistatic coating[46], foams[47], elastomers[48], and drug delivery for cancer therapy[49]. Consider

7generating a polyurethane of chain length of 20, using 1 polyol type (e.g., PTMO) and 1 isoc- ynate type (e.g., MDI). Under these assumptions (which are representative of the average pol- yurethane chain[50]), PolyGrammar can generate more than 2 x 106 distinct polyurethane chains using only 14 production rules. Moreover, we show that PolyGrammar can be easily

extended to the other types of polymers, including both copolymers and homopolymers. We further propose an inverse modeling algorithm that translates a polymer's SMILES string into the sequence of production rules used to generate it. More than 600 polyurethanes collected from literature are validated by this inverse model, demonstrating the representative power of PolyGrammar. Schematic of our PolyGrammar is shown in Figure 1.## 2. Hypergraph-based Symbolic Representation



In this section, we introduce the hypergraph representation of polyurethane structures and describe how to use symbolic strings to represent polyurethane chains.

O=C=N

ZI

OH

(i) Graph:

(ii) Hypergraph:

(iii) Hypergraph representation:

:unselected:

,

Node Edge

Hyperedge

Figure 2. The structure produced by reacted by two monomers (1,3-bis(isocyanatomethyl)cy- clohexane and diethylene glycol). The standard graph representation (i) uses 21 nodes and 21 edges, but the hypergraph (ii) only requires two hyperedges. Each hyperedge corresponds to the nodes of a given monomer. Both hyperedges have the urethane group in common. We use the line graph (iii) to visualize the hypergraph representation in the remaining figures of the paper for convenience.

8

## 2.1. Polymers as Hypergraphs



It is a common practice[7,12,51,52] to regard the structural formula of a molecule as an or- dinary graph, where atoms are nodes, bonds are edges, and edges connect exactly two nodes. For polyurethanes, ordinary graph depictions would require prohibitively many nodes and edges. To address this, we employ a generalized graph called a hypergraph[53], which allows individual edges to join more than one node. Any edge that connects a subset of the nodes in the hypergraph is called a hyperedge. Consider the product of two monomers (1,3 bis(isocy- anatomethyl)cyclohexane and diethylene glycol) as shown in Figure 2(i). Originally, the graph required 21 nodes and 21 edges. However, if we construct each hyperedge by selecting the subset of nodes according to the monomer type, as shown in Figure 2(ii), the hypergraph for this molecule requires only 2 hyperedges. This dramatically reduces the representation cost for large polyurethane chains.

For increased convenience, we will visualize the hypergraph representations using the line graph[54] form shown in Figure 2(iii). In graph theory, the line graph refers to the duality of the original graph, where each edge in the original graph corresponds to a unique vertex of the line graph. With regards to the theory of hypergraph, the line graph contains one vertex for every hyperedge in the original hypergraph. Two vertices in the line graph are connected by a line if their corresponding hyperedges in the original hypergraph have a non-empty inter- section. For the hypergraph in Figure 2(ii), since the urethane group is shared by two hypered- ges in the hypergraph, the corresponding line graph can be visualized as two vertices connec- ted by an edge. By collapsing the original nodes based on molecular identity, the line graph form provides a more concise visualization of a hypergraph.

Complete polyurethane structures can also be represented in this manner. The molecu- lar fragments corresponding to the isocyanate and the polyol in the polyurethane chain are represented as hyperedges, which are visualized as vertices in the line graph. The urethane

9

groups connecting hard segment (HS) with soft segment (SS) and the chain extenders con- necting two diisocyanates are viewed as intersections between two hyperedges; thus, they are visualized as edges in the line graph. Two examples of hypergraph representations for polyu- rethane structures are shown in Figure 3.

(i) Polyurethanei Structure:

0=

Hypergraph representation:

(ii)

Polyurethane Structure:

DsCN

Hypergraph representation:

Figure 3. Examples of hypergraph representation. (i) Polyurethane chain synthesised by MDI, PTMO and 1,4-butanediol (BDO); (ii) Branched polyurethane chain synthesised by 4,4'- diisocyanato-methylenedicyclohexane (4,4'-HMDI), poly(caprolactone) diol (PCL) and tri- azine based polyhydric alcohol (3-THA).

## 2.2. Symbolic Representation



Given the hypergraph of a polyurethane chain, we construct a corresponding symbolic string for use in PolyGrammar. In the symbolic string, the hyperedges corresponding to the isocyanate (hard segment) are denoted with "H" and those corresponding to the polyol (soft segment) are denoted as "S". The chain extenders are omitted, since they can only exist be- tween two adjacent H (or S) symbols. For those polyurethanes containing multiple isocyanate or polyol types, we use subscripts i = 1, 2, ... to distinguish different subtypes of certain hy- peredge. For instance, if two different types of isocyanates are used[38], we use H1 and H2 to distinguish the hyperedges corresponding to each hard-segment type. These rules allow us to represent any polyurethane chain as a string of symbols. Examples are shown in Figure 4.

10

(i) Polyurethane Structure:

Isocyanate

O

N

O

O=C=N

v=C=0

H

Hypergraph representation:

Symbolic representation:

8

8

... HHHHHHHHS ...

Polyol

HO.

H

Chain Extender

OH

HO

Polyurethane Structure:

Isocyanate

O

ZI

IZ

fc

U=0

O=C=N

N=C=0

Hypergraph representation:

Symbolic representation:

4

... HSHSHSHS ...

H

Polyol

0

(111) Polyurethane Structure:

Isocyanate 1

O=C=N

N=C=O

O=C

0

O

=0

HN

Isocyanate 2

O=0.

N

N=C=0

IZ U=0

O=C

NH

HN

2

HO1

Polyol

O

-H

Hypergraph representation:

Symbolic representation:

2

... HISH1H2H2715717272 ·

Chain Extender

HO

OH

Figure 4. Symbolic representations for polyurethanes synthesized using: (i) MDI, PTMO and BDO; (ii) 1,6-diisocyanatohexane (HDI) and PCL; (iii) 4,4'-dibenzyl diisocyanate (DBDI), MDI, poly(ethylene adipate)diol (PEA) and ethylene glycol (EG). Note that (iii) includes mul- tiple diisocyanates.

We emphasize that our symbolic representation is invertible, such that a symbolic string can be converted back to the corresponding chemical structure if the constituent isocya- nate(s), polyol(s) and chain extender(s) are specified. We call this process hypergraph conver- sion. The invertibility of hypergraph representation ensures our PolyGrammar can simultane- ously serve as a representation and a generative model for polyurethanes.

## 3. PolyGrammar



In this section, we first present the basic mechanism of grammar production using an illustrative example. Then, we introduce our parametric context-sensitive PolyGrammar

11

comprehensively. Finally, we propose several advanced features based on our basic Poly- Grammar for the representation of polyurethanes, which encourage the generation of more general structures.

X

O=0 ==

|X > Hh

Hh

Th-Hh

HHh

HN

C=O

H: IPDI

S: PHA

h Ss

HHSS

Ts -> Null

HHS

O=C

NH

HN

O

O

OH

HyperGraph Conversion

Figure 5. An illustrative example of grammar production. Starting from the initial symbol X, we sequentially invoke four production rules from P = {X -> Hh; h => Hh; h -> Ss; s -> Null}. The process continues until all symbols in the string are terminal symbols. By specify- ing the constituent structures, i.e., isophorone diisocyanate (IPDI), polyhexamethylene car- bonate glycol (PHA) and EG, the string of the symbols can be translated to the corresponding polyurethane chain via hypergraph conversion.

## 3.1. Basic PolyGrammar



In formal language theory, a grammar G = (N,E, P) is used to describe a language, where N is a set of non-terminal symbols, 2 is a set of terminal symbols and P is a set of pro- duction rules, each of which consists of a predecessor and a successor separated by a right ar- row "->". In the language represented by the grammar G, each word is a finite-length string containing both terminal and non-terminal symbols. The non-terminal symbols in a word can be further replaced and expanded by invoking one production rule from P at a step. In our PolyGrammar, the set of non-terminal symbols N is {X, h, s} and the set of terminal symbols E is {H, S}. Figure 5 shows an illustrative example to demonstrate the process for producing a string via the grammar G. This example uses four production rules: P = {X > Hh; h >

12

Hh; h -> Ss; s -> Null}. Starting from the initial symbol X, at each iteration, each non-termi- nal symbol in the current string is replaced with the successor of a production rule whose pre- decessor matches the symbol. The process continues until no non-terminal symbols exist in the string.

According to Chomsky's classification[55], the grammar used in this illustrative exam- ple is a Type-2 grammar, also called context-free grammar, where the predecessor of each production rule consists of only one single non-terminal symbol. Similar paradigms are also utilized in L-systems to model the morphology of organisms[56,57] 3.1.1 Context-Sensitive Grammar

The context-free grammar discussed above is insufficient to imitate the polyurethane generation process because the symbolic string can only expand along one direction; however, polyurethanes generally grow along two opposite directions to form chain structures. To ad- dress this, our PolyGrammar utilizes a context-sensitive grammar. In particular, our Poly- Grammar is a Type-1 grammar, a more general form of Type-2 grammar[58], where the pro- duction rules also consider the context (i.e., the surrounding symbols) of the given non-termi- nal symbol within the string.

By considering the symbol contexts, the production rules of a context-sensitive gram- mar can explicitly depict the growing direction of the polyurethane chain. The production rules are as follows:



|P1 : None < > >|None|> hHh|
|---|---|---|
|Pz : None < > >|None|> sSs|
|P3 : None <h >|H|=> hH|
|P4 : None < h >|H|> SS|
|Ps : None <h >|H|-> Null|
|P6 : None <s >|S|=> hH|
|pz : None < s >|S|=> SS|


13



|Ps :|None|<s > S => Null|
|---|---|---|
|Pg :|H|< h > None > Hh|
|P10:|H|< h > None > Ss|
|P11:|ℋ|< h > None -> Null|
|P12:|S|< s > None -> Hh|
|P13:|S|< s > None -> Ss|
|P14:|S|< s > None -> Null|


In each production rule, the non-terminal symbol to be replaced is inside the angle brackets "<>" of the predecessor. The contexts are the symbols located at both sides of "< >" in the predecessor (None indicates no constraints). The rule can only be deployed when both contexts of the symbol have been matched.

Each rule has an intuitive function. Rules p1 and p2 initialize the start symbol X, while p5, P8, P11 and p14 terminate the growth. Rules p3, P4, P6 and p7 extend the string along the left direction, and p9, P10, P12 and p13 extend the string along the right direction. p3 and p9 indicate the reaction between two isocyanates, imitating the formation of the hard seg- ment, while p7 and p13 indicate the reaction between two polyols, imitating the formation of the soft segment. Lastly, p4, P6, P10 and p12 imitate the formation of the urethane group.

Another important feature of the PolyGrammar is that there are multiple possible pro- duction rules to expand a given symbol. For instance, p3, P4 and p5 share the same predeces- sor and expand the non-terminal symbol h along the left direction. There are many possible schemes for selecting among these options, including hand-tuned heuristics or manual inter- vention to guide the scheme toward particular results. For simplicity, we have implemented a uniformly random selection technique: at each iteration, we randomly sample one rule from all of the candidate rules that meet the contexts and apply it to the symbol. An example of the production process is illustrated in Figure 6.

14

SSs

hHh

H: TDI

Null

SS

Hh

Ss

S : PLA

sSHHh

Nul $$

Hh

Ss

T hHSHHSs

-NH

NH C=0

C=0

HN

Null

Sc

hHl

Hh

S.s

hHHSHHSHh

NH

HN

C=O

O=C

1=0=0

HN

Null

---

HHSHHSH

-

end

Null

HyperGraph Conversion

O

.NH

=O

Figure 6. Example of context-sensitive grammar. At each production step, only the rules that match the non-terminal symbol's context are adopted. Hence, the production process can ex- plicitly depict the growing direction of the polyurethane chain. If there are multiple candidate rules at a given step, selection can be done manually or randomly. The selected rule is then applied to the symbol to continue production.

## 3.1.2 Parametric Grammar



Although the context-sensitive grammar makes it possible to generate a variety of polyure- thane chain structures, its modeling power is still limited. One important problem is that the

total chain length of the generated polyurethanes cannot be controlled. In practice, the chain length is an essential factor that influences the physical and chemical properties of the polyu- rethanes[50, 59]. It is non-trivial to control the chain length of each generated polyurethane merely using the grammar discussed above due to the stochastic production. In order to ad- dress this problem, we introduce a parameter x associated with each terminal symbol in the grammar and augment our PolyGrammar as a parametric context-sensitive grammar. The proposed parametric grammar is illustrated as follows,

15

H: MDI

hH(3)h

T hH(2)HS(2)s

0 S: PBA

P=C=N

SS(1)HHSH(1)h

O=C

HN-

O=

ZI

hH(O)SHHSHS(O)s

Null

I Null

IHN

NH

HSHHSHS

HŇ

OH

end

HyperGraph Conversion

Figure 7. Example of parametric grammar. To control the length of generated polyurethane, we introduce parameters, denoted with parentheses "( )" after terminal symbols.

P1 : None < > > None: None > hH (L)h

P2 : None < > > None: None -> SS (L)s P3 : None <h > H(x): x ≥ 1-> hH(x-1)

p4 : None < h > H(x): x ≥1 -> SS(x-1) Ps : None < h > H(x): x < 1 > Null P6 : None <s > S(x): x ≥ 1 -> hH (x - 1) pz : None < s > S(x): x ≥ 1 -> SS(x - 1) Ps : None <s > S(x): x < 1 -> Null P9 : H(x) <h> None: x ≥1->H(x-1)h P10: H(x) <h> None: x≥1-> S(x-1)s P11: H (x) < h > None: x < 1 -> Null P12: S(x) <s > None: x ≥ 1 -> H(x-1)h

P13: S(x) <s > None: x ≥ 1 -> S(x -1)s

P14: S(x) < s > None: x < 1 -> Null

The production rules now feature parameters, which are denoted with parentheses "()" following terminal symbols. Furthermore, each production rule is augmented with a logical "condition" that determines whether the rule can be invoked or not (None indicates no con- straints). By specifying L (the initial value of parameter x in production rules p1 and p2), the

16

grammar can produce strings with length 2L + 1, corresponding to polyurethane chains with length 2L + 1. By varying the value of L, the chain length of generated polyurethanes can be controlled. An example of this production process is illustrated in Figure 7.

## 3.2. Advanced Features



## 3.2.1 Extensions for Branched Polyurethanes



So far, all of our polyurethanes have featured linear chain structures. However, it is possible for polyurethanes to have branched structures[60], as shown in Figure 3(ii). To gener- ate branched polyurethanes, we augment the parametric context-sensitive grammar with sev- eral rules:

P15 : None < h > H(x): x ≥ 1 => h[h]H (x -1) P16: None <h> H(x): x ≥ 1 -> s[s]S(x - 1) P17: H (x) <h > None: x ≥1-> H(x-1)[h]h P18: S(x) <s > None: x ≥ 1 -> S(x - 1)[s]s

A branch is delimited by the content inside a pair of square brackets "[ ]". The non- terminal symbols inside the square brackets can also be further expanded using the rules of the basic PolyGrammar. In the final string, all the terminal symbols inside a pair of square- brackets together form a sub-branch attached to the backbone. The above illustrated rules can generate polyurethane chains that have up to 2 branches at each bifurcation. The number of branches at each bifurcation can also exceed 2 by adding more square-bracket pairs attached to the non-terminal symbols. Examples are available in Supporting Information.

## 3.2.2 Global Controllable Parameters



We have already discussed the use of parameters for controlling the chain length of the generated polyurethanes. However, it is still difficult for our baseline parametric grammar to achieve more advanced controllable parameters such as the ratio of hard segment to soft segment. This is because the context-sensitive grammar only captures "local" information

17

about the chain during the generation process, as the view of each production rule is limited to the context immediately surrounding the predecessor symbol. When it comes to global con- straints, such as specific ratios of hard versus soft segments, the generative model needs to be aware of the relevant information (number of hard segments, chain length) over the whole chain. It is non-trivial to handle these constraints with the basic PolyGrammar discussed in previous sections.

To address this issue, we introduce an additional symbol "M" which serves as a mes- sage that can collect global information about the chain. The message is propagated back and forth between the left and right ends of the string. The propagation is achieved by switching the message's position with the adjacent symbol's one at a time; this continues along a certain direction until the message gets to the string end. At each position swap, the message updates its parameters to collect the information required for the control setting. When the message reaches the end of the string, the outcome of the production rule is influenced by the infor- mation contained in the message. The message is then reset and begins to propagate along the opposite direction, encoding information about the entirety of the structure, continuing the above process. Since the production rules are only applied at the end of the chain, this mecha- nism ensures that the string generation adheres to all parameter-controlled constraints. Multi- ple constraints can be considered simultaneously by adding more parameters to the message symbol. The full set of the production rules and an illustration of the message passing mecha- nism are shown in Supporting Information.

## 4. PolyGrammar as a Generative Model



Generative models are critical for the efficient, thorough exploration of possible poly- mer structures. These models are also particularly powerful in conjunction with machine learning algorithms, in order to address complicated problems like human-guided exploration

18

and property prediction. In this section, we discuss how our parametric context-sensitive Pol- yGrammar can serve as a generative model.

The generation process of PolyGrammar begins with a simple string that contains the initial symbol X. On each step, we traverse the symbols in the current string and find the po- sition of all the non-terminal symbols. For each non-terminal symbol, we identify a candidate set of production rules. Each candidate production rule must meet the following conditions: 1) the context in the predecessor clause matches the context of the current symbol in the string, and 2) the parameters of this symbol's context meet the logical condition of the production rule. If there are several candidate rules to expand a given symbol, a single rule is selected ac- cording to the desired scheme (random sampling scheme, manual intervention, etc.). We ap- ply the selected production rule to the appropriate non-terminal symbol, and repeat this pro- cess until no non-terminal symbols remain in the string. Once the final string is produced, we convert it into an explicit polyurethane hypergraph by replacing the symbols in the string with the chemical structures (e.g., MDI and PTMO) corresponding to each hyperedge. This yields a valid, explicit polyurethane chain, as desired. These structures can be further converted to other forms of representation such as SMILES.

Using our generative model, it is possible to enumerate all valid polyurethane struc- tures in a target class (e.g., length 20 with 1 type of polyol and 1 type of isocyanate). In partic- ular, any distinct sequence of production rules on the start symbol yields a distinct string, which in turn represents a unique polyurethane chain. Since the production rules encode all permissible local configurations of the constituent molecules, it follows that our grammar is able to generate any valid polyurethane.

To emphasize the volume of achievable molecules, we also quantitatively analyze the diversity of generated chains for our PolyGrammar. Given a chain length parameter L and the

19

number of isocyanate and polyol types (NH and Ns, respectively), the basic PolyGrammar

(with 14 production rules) allows the generation of a total number of

N =

i=0 2L+1 i! (2L + 1 - i)! (2L+ 1)! NÅN2L+1-i

polyurethane chains with different structures. With L = 10, NH = 1,Ns = 1, which are repre-

sentative of an average polyurethane chain[50], N is more than 2 x 106. This demonstrates the powerful capacity of our PolyGrammar. Several polyurethane chains generated using Poly- Grammar are shown in Figure 8. More examples can be found in Supporting Information.

(i)

{p2, P12, P6, P9, P10, P3, P9, P4, P6, P3, P4, P9, P8, P11 }

SHHSHHSHHSHH

1

(ii) {p2, p7, P12, P9, P6, P3, P10, P3, P12, P10, P8, P11, P14}

O=

O=O

H : IPDI

S : PHA

O=0

ZI 4

Htc

r

NH

SH [ H ] H SH

H: MDI

S : PTMO

NH

N=C=0

(iii) {p1, P17, P4, P9, P9, P10, P9, P12, P5, P14 }

HHHSSHHSHS

H : TDI S : PLA

O=C

O=0

ZI

ZI

NH

Figure 8. Examples of polyurethane chains generated using PolyGrammar. (i) Ordered chain with isophorone diisocyanate (IPDI), polyhexamethylene (PHA) and EG; (ii) Branched chain with MDI, PTMO and 3-THA; (iii) Unordered chain with Toluene diisocyanate (TDI), PLA and diethylene glycol (DEG).

20

## 5. Translation from SMILES



¡ Input:

HO

Search:

hHh

:unselected: :unselected:

:unselected: <--- x

1 / :unselected: h H Hl [h]h

-

K

:unselected: :unselected:

:unselected: SŞ's

HC

ZI

:unselected: hHH[Hh]h

:unselected:

:unselected:

?

N ...

Component Type

HyperGraph Conversion

H: IPDI

S: PHA

HHHSIHS

:selected:

:unselected:

:unselected:

> : Selected production rules

Figure 9. Schematic for translating a polyurethane from a SMILES string into our PolyGram- mar representation, which also reveals the complete sequence of rules required for its genera- tion. The pipeline can be regarded as a search process. Starting from the initial symbol, we it- eratively select and invoke production rules until all symbols in the string are terminal sym- bols. Then given the component types, we convert the symbolic string into a polyurethane structure by hypergraph conversion and compare it with the input structure. The total process repeats until the search structure matches with the input structure.

To complete our chemical design model, we also develop an inverse model capable of translating a SMILES string into the corresponding sequence of PolyGrammar production

rules. The overall pipeline of translation from SMILES can be regarded as a search process, as shown in Figure 9. Starting from the initial symbol, we iteratively select and invoke produc- tion rules until all symbols in the string are terminal symbols. Once we have a complete string and the specific component types, we use hypergraph conversion to convert the symbolic string into a polyurethane structure. We then compare our result with the input structure; if they do not match, we restart our search from scratch. The process repeats until our structure matches the original input.

Specifically, our inverse model proceeds as follows. Given the SMILES string of the polyurethane chain, we break it into multiple molecular fragments by disconnecting all of the

21

urethane groups, - NHCO-0 -. Then we exhaustively enumerate each molecular fragment and perform a string matching algorithm (KMP matching[63]) to identify the type of it: an isocya- nate, a polyol or a chain extender. During the enumeration, we also record the connectivity between each fragment. Based on the types and the connectivity of the fragments, we can ob- tain a hypergraph representation of the original SMILES string. The final step is to convert the hypergraph into the sequence of the production rules of PolyGrammar. We traverse the hypergraph using the breadth-first search (BFS) algorithm, which explores all of the neigh- bouring hyperedges at the present depth before moving on to the nodes at the next depth level. BFS starts at the tree root, which is an arbitrary hyperedge of the hypergraph. Each step of the exploration returns a tuple of two hyperedges, which is then matched with a specific produc- tion rule in the PolyGrammar. Hence, the sequence of the production rules can be obtained once the entire hypergraph has been explored. The pipeline of this algorithm is illustrated in Figure 10 and the corresponding pseudo-code is in Supporting Information.

o=C (CCCCOCCCCO ccccoccccocccco CCCCOCCCCOC (Nel ccc (Cc2ccc (NC (C )=O)cc2)cc1)=O) Nc3ccc (Cc4ccc (N C (OCCNC5=NC (NCC OC (Nc6ccc (Cc7cc c (NC (OCCCCOCCCC OCCCCOC)=O)cc7) cc6)=O)=NC(NCCO C (Nc8ccc (Cc9ccc (NC (OCCCCOCCCCO ccccoccccocccco C)=O)cc9)cc8)=O )=N5)=O)cc4)cc3

[0]ccccoccc coccccoc

CC (Nc$10ccc (Cc% 11ccc(NC(C)=O)c c%11)cc%10)=O

Ş

[0]CCNC$10=NC I I(NCCOC) =NC (NC !

H

(b) KMP Matching & Identifying the Type

(a) Disconnecting Urethane Groups

(c) BFS Search &

([0])=N$10

H

CC (Nc$10ccc (Cc% 11ccc(NC(C)=O)c

c%11)cc%10)=O

2

[0] ccccoccc CoccccoCCCC OCcccocccco CCCC[O]

5

CC (Nc%10ccc (Cc% 11ccc(NC(C)=O)c c%11)cc%10)=O

CC (Nc$10ccc (Cc%

S

S

11ccc(NC(C)=O)c c%11)cc%10)=O

H

[0] ccccoccc coccccocccc occcco

0

1

2

3

(4

5

(6 Rules Matching

7

0-> 1: P2

1->2: P12, P17

2->3: P9

2->4: P9

3->5: P10

4->6: P10

5->7: P12

H :

S: 400

Figure 10. Overview of the algorithm for translation from SMILES. The input SMILES string is first broken into a set of molecular fragments, which are identified via string matching. Based on the identity and connections of each fragment, we can construct the hypergraph representation of the molecule. Then, we search for a sequence of PolyGrammar rules that yields the desired result.

22

This pipeline is sufficient for our needs, but it could be improved with a heuristic search such as A* search[64], best-first search[65], or learned heuristic search[66] where a heuris- tic function accelerates the search process by directing attention toward the most promising regions of the search space.

To validate our approach and demonstrate the capacity of our proposed PolyGrammar, we have collected and inversely modelled over 600 polyurethane structures from literature. Many of these polyurethanes are commonly used in synthesis and real-world fabrication, and they feature a wide range of constituent molecules. In particular, the dataset features 8 differ- ent types of isocyanates, 11 types of polyols and 7 types of chain extenders. Additional details about our dataset - including information about how to add and translate new polyurethane structures - are described in Supporting Information. Supporting Information also contains several examples polyurethanes from our dataset, which were successfully converted from SMILES to the PolyGrammar representations. Moreover, we emphasize that each of the col- lected SMILES strings in our dataset can be successfully converted to a sequence of produc- tion rules in the PolyGrammar. This proves that our PolyGrammar has high representative ca- pacity over a large span of polyurethane structures.

## 6. Generalization to Other Polymers



Our PolyGrammar can also be easily extended to new classes of polymers. These ex- tensions would use the same framework described above, with very few modifications. In the Supporting Information, we illustrate the extended PolyGrammar for different types of copol- ymers, including alternating copolymers and block copolymers. Note that our PolyGrammar in the main paper can already cover random copolymers, branched copolymers, and graft co- polymers. Users only need to add new types of reactants to the symbolic representation in or- der to determine the species of monomer.

23

For now, PolyGrammar focus on the backbone structure, i.e., the arrangement of mon- omers, which largely determines the property of copolymers (derived from more than one species of monomer). The grammar treats the monomer fragment as a whole and distinguishes different monomer types using different symbols. However, there is also a wide range of pol- ymers consisting of only one single type of repeat unit, i.e., homopolymers, where the back- bone structures are not variable and the functional group (also called functional residue) of the monomer contributes to the polymer property. To handle this, we augment our PolyGrammar with an additional set of production rules focusing on the representation and generation of functional groups. We also demonstrate the effectiveness of our augmented PolyGrammar us- ing the polyacrylate as an illustrative example. This functional-group grammar together with the basic PolyGrammar (full set of the production rules in Supporting Information) serves as a hierarchical generative model for polymers, where the latter one handles the backbone and the former one focuses on the functional residue of each composed monomer. More examples are shown in Supporting Information.

## 7. Discussion



PolyGrammar is an effective chemistry design model that satisfies all five desirable properties discussed in Introduction. In particular, our symbolic representation can convey all possible polyurethane structures in an explicit yet concise manner. The generative model based on this representation is exhaustive (it is capable of generating any polyurethane) and trustworthy (every generated polyurethane is guaranteed to be valid). Moreover, the genera- tion process is fully transparent and understandable to the user, as it returns a sequence of meaningful production rules that yield our model's result. Lastly, the generation process is in- vertible, so molecules can be translated from other popular representations such as SMILES. These superior properties make PolyGrammar more comprehensive and practical than exist- ing representation schemes and generative models. Our full chemical design model

24

(representation, generative model, and inverse model) are also simple and efficient to use in practice. For a polyurethane chain of length 20, the average generation time via PolyGrammar is 4 ms and its translation from SMILES costs 11 ms on a PC with an Intel Core i7 CPU.

For now, our PolyGrammar focuses on single-chained molecular structures. However, real synthesized polyurethanes are a mixture of differently structured chains, where interac- tions between chains such as hydrogen bonding and crosslinking may occur[47,48]. These inter- actions influence the physical and chemical property of the polyurethane, largely determining whether the synthesized polyurethane is thermoset or thermoplastic. Such interactions are not currently addressed in PolyGrammar, but they could be added by augmenting the production rules to support interactions between multiple chains.

The current generative model of the PolyGrammar also only imitates the chain-growth polymerization. Although this polymerization mechanism has some benefits for the simula- tion of polyurethane chains[61], it would be ideal for our PolyGrammar to imitate step-growth polymerization as well. More advanced grammar such as universal grammar[62] will be helpful to achieve this.

These aforementioned features are intriguing and will be implemented and demon- strated in future work. However, even without these augmentations, our proposed PolyGram- mar takes an important step toward a more practical and comprehensive system for polymer discovery and exploration.

## 8. Conclusion



In summary, we propose a parametric context-sensitive grammar, called PolyGram- mar, for the representation and generation of polymers. The recursive nature of grammar pro- duction enables the generation of any polymer chain using only a simple set of production rules. We also implement an algorithm that can transfer a SMILES string of a polymer chain to the sequence of production rules used to generate it. Capable of reproducing a large

25

literature-collected dataset, this algorithm demonstrates the completeness and effectiveness of our PolyGrammar. Our PolyGrammar will benefit the polymer community in several ways. The most immediate contribution is our ability to efficiently generate an exhaustive collection of polymer samples. This corpus could be very powerful in conjunction with other methods (e.g., machine learning) to guide the synthesis of physical polymers and facilitate complex tasks like molecular discovery[2-4] and property optimization[13,14,17]. PolyGrammar is also helpful for the reverse engineering of polymer design and production. Our PolyGrammar serves as a blueprint to construct chemical design models for different classes of chemistries, including both organic and inorganic molecules. Eventually, PolyGrammar could improve chemical communication and exploration, by providing a more efficient and effective repre- sentation scheme that is widely suitable for complicated polymers.

## Supporting Information



Supporting Information is available from the author: production rules of global controllable grammar; collected dataset of polyurethane from literature; examples of translation from SMILES; generalized Polygrammar to other polymers; pseudo-code of translation from SMILES; examples of generated polyurethane chains; examples of branched polyurethane chains; examples of acrylate's functional groups; and abbreviations and acronyms.

26

## Acknowledgments



General: The authors would like to thank Dr. Xingcai Zhang and Dr. Ming Xiao from Har- vard University, and Dr. Pengfei Zhang from Qingdao University for their helpful comments.

## References



[1] Bjerrum, E. J .; Threlfall, R. Molecular generation with recurrent neural networks (RNNs). arXiv preprint arXiv:1705.04612 2017.

[2] Olivecrona, M .; Blaschke, T .; Engkvist, O .; Chen, H. Molecular de-novo design through deep reinforcement learning. Journal of cheminformatics 2017, 9, 48.

[3] Gupta, A .; Müller, A. T .; Huisman, B. J .; Fuchs, J. A .; Schneider, P .; Schneider, G. Generative recurrent networks for de novo drug design. Molecular informatics 2018, 37, 1700111.

[4] Sumita, M .; Yang, X .; Ishihara, S .; Tamura, R .; Tsuda, K. Hunting for organic mole- cules with artificial intelligence: molecules optimized for desired excitation energies. ACS central science 2018, 4, 1126-1133.

[5] Blaschke, T .; Olivecrona, M .; Engkvist, O .; Bajorath, J .; Chen, H. Application of gen- erative autoencoder in de novo molecular design. Molecular informatics 2018, 37, 1700123.

[6] Lim, J .; Ryu, S .; Kim, J. W .; Kim, W. Y. Molecular generative model based on condi- tional variational autoencoder for de novo molecular design. Journal of cheminformat- ics 2018, 10, 1-9.

[7] Jin, W .; Barzilay, R .; Jaakkola, T. Junction tree variational autoencoder for molecular graph generation. arXiv preprint arXiv:1802.04364 2018,

[8] Jørgensen, P. B .; Schmidt, M. N .; Winther, O. Deep generative models for molecular science. Molecular informatics 2018, 37, 1700133.

27

[9] Putin, E .; Asadulaev, A .; Ivanenkov, Y .; Aladinskiy, V .; Sanchez-Lengeling, B .; As- puru-Guzik, A .; Zhavoronkov, A. Reinforced adversarial neural computer for de novo molecular design. Journal of chemical information and modeling 2018, 58, 1194- 1204.

[10] Putin, E .; Asadulaev, A .; Vanhaelen, Q .; Ivanenkov, Y .; Aladinskaya, A. V .; Aliper, A .; Zhavoronkov, A. Adversarial threshold neural computer for molecular de novo de- sign. Molecular pharmaceutics 2018, 15, 4386-4397.

[11] Méndez-Lucio, O .; Baillif, B .; Clevert, D .- A .; Rouquié, D .; Wichard, J. De novo gen- eration of hit-like molecules from gene expression signatures using artificial intelli- gence. Nature communications 2020, 11, 1-10.

[12] Maziarka, Ł .; Pocha, A .; Kaczmarczyk, J .; Rataj, K .; Danel, T .; Warchoł, M. Mol- Cy- cleGAN: a generative model for molecular optimization. Journal of Cheminformatics 2020, 12, 1-18.

[13] Napolitano, F .; Zhao, Y .; Moreira, V. M .; Tagliaferri, R .; Kere, J .; D'Amato, M .; Greco, D. Drug repositioning: a machine learning approach through data integration. Journal of cheminformatics 2013, 5, 30.

[14] Montavon, G .; Rupp, M .; Gobre, V .; Vazquez-Mayagoitia, A .; Hansen, K .; Tkatchenko, A .; Müller, K .- R .; Von Lilienfeld, O. A. Machine learning of molecular electronic properties in chemical compound space. New Journal of Physics 2013, 15, 095003.

[15] Wu, Z .; Ramsundar, B .; Feinberg, E. N .; Gomes, J .; Geniesse, C .; Pappu, A. S .; Les- wing, K .; Pande, V. MoleculeNet: a benchmark for molecular machine learning. Chemical science 2018, 9, 513-530.

[16] Coley, C. W .; Jin, W .; Rogers, L .; Jamison, T. F .; Jaakkola, T. S .; Green, W. H .; Bar- zilay, R .; Jensen, K. F. A graph convolutional neural network model for the prediction of chemical reactivity. Chemical science 2019, 10, 370-377.

28

[17] Gao, H .; Struble, T. J .; Coley, C. W .; Wang, Y .; Green, W. H .; Jensen, K. F. Using machine learning to predict suitable conditions for organic reactions. ACS central sci- ence 2018, 4, 1465-1476.

[18] Schreck, J. S .; Coley, C. W .; Bishop, K. J. Learning retrosynthetic planning through simulated experience. ACS central science 2019, 5, 970-981.

[19] Liu, B .; Ramsundar, B .; Kawthekar, P .; Shi, J .; Gomes, J .; Luu Nguyen, Q .; Ho, S .; Sloane, J .; Wender, P .; Pande, V. Retrosynthetic reaction prediction using neural se- quence-to-sequence models. ACS central science 2017, 3, 1103-1113.

[20] Butler, K. T .; Davies, D. W .; Cartwright, H .; Isayev, O .; Walsh, A. Machine learning for molecular and materials science. Nature 2018, 559, 547-555.

[21] Raccuglia, P .; Elbert, K. C .; Adler, P. D .; Falk, C .; Wenny, M. B .; Mollo, A .; Zeller, M .; Friedler, S. A .; Schrier, J .; Norquist, A. J. Machine-learning-assisted materials dis- covery using failed experiments. Nature 2016, 533, 73-76.

[22] Barnes, B .; Rice, B .; Sifain, A. Machine Learning of Energetic Material Properties and Performance. Bulletin of the American Physical Society 2020, 65.

[23] Fooshee, D .; Mood, A .; Gutman, E .; Tavakoli, M .; Urban, G .; Liu, F .; Huynh, N .; Van Vranken, D .; Baldi, P. Deep learning for chemical reaction prediction. Molecular Sys- tems Design & Engineering 2018, 3, 442-452.

[24] Schwaller, P .; Gaudin, T .; Lanyi, D .; Bekas, C .; Laino, T. "Found in Translation": pre- dicting outcomes of complex organic chemistry reactions using neural sequence-to- sequence models. Chemical science 2018, 9, 6091-6098.

[25] Segler, M. H .; Preuss, M .; Waller, M. P. Planning chemical syntheses with deep neural networks and symbolic AI. Nature 2018, 555, 604-610.

[26] Henson, A. B .; Gromski, P. S .; Cronin, L. Designing algorithms to aid discovery by chemical robots. ACS central science 2018, 4, 793-804.

29

[27] Roch, L. M .; Hase, F .; Kreisbeck, C .; Tamayo-Mendoza, T .; Yunker, L. P .; Hein, J. E .; Aspuru-Guzik, A. ChemOS: An orchestration software to democratize autonomous discovery. PLoS One 2020, 15, e0229862.

[28] Weininger, D. SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules. Journal of chemical information and computer sciences 1988, 28, 31-36.

[29] Ash, S .; Cline, M. A .; Homer, R. W .; Hurst, T .; Smith, G. B. SYBYL line notation (SLN): A versatile language for chemical structure representation. Journal of Chemi- cal Information and Computer Sciences 1997, 37, 71-79.

[30] Vollmer, J. J. Wiswesser line notation: an introduction. Journal of Chemical Education 1983, 60, 192.

[31] Heller, S. R .; McNaught, A .; Pletnev, I .; Stein, S .; Tchekhovskoi, D. InChI, the IU- PAC international chemical identifier. Journal of cheminformatics 2015, 7, 23.

[32] Drefahl, A. CurlySMILES: a chemical language to customize and annotate encodings of molecular and nanodevice structures. Journal of cheminformatics 2011, 3, 1-7.

[33] Lin, T .- S .; Coley, C. W .; Mochigase, H .; Beech, H. K .; Wang, W .; Wang, Z .; Woods, E .; Craig, S. L .; Johnson, J. A .; Kalow, J. A., et al. BigSMILES: a structurally-based line notation for describing macromolecules. ACS central science 2019, 5, 1523-1531.

[34] Zhang, T .; Li, H .; Xi, H .; Stanton, R. V .; Rotstein, S. H. HELM: a hierarchical nota- tion language for complex biomolecule structure representation. 2012.

[35] Kajino, H. Molecular hypergraph grammar with its application to molecular optimiza- tion. International Conference on Machine Learning. 2019; pp 3183-3191.

[36] Jin, W .; Barzilay, R .; Jaakkola, T. Hierarchical Generation of Molecular Graphs using Structural Motifs. arXiv preprint arXiv:2002.03230 2020.

[37] Sperling, L. H. Introduction to physical polymer science; John Wiley & Sons, 2005.

30

[38] Petrovic, Z. S .; Ferguson, J. Polyurethane elastomers. Progress in Polymer Science 1991, 16,695-836.

[39] Cowie, J. M. G .; Arrighi, V. Polymers: chemistry and physics of modern materials; CRC press, 2007.

[40] Elton, D. C .; Boukouvalas, Z .; Fuge, M. D .; Chung, P. W. Deep learning for molecu- lar design-a review of the state of the art. Molecular Systems Design & Engineering 2019, 4, 828-849.

[41] Cao, D .- S .; Zhao, J .- C .; Yang, Y .- N .; Zhao, C .- X .; Yan, J .; Liu, S .; Hu, Q .- N .; Xu, Q .- S .; Liang, Y .- Z. In silico toxicity prediction by support vector machine and SMILES representation-based string kernel. SAR and QSAR in Environmental Re- search 2012, 23, 141-153.

[42] You, J .; Liu, B .; Ying, Z .; Pande, V .; Leskovec, J. Graph convolutional policy net- work for goal-directed molecular graph generation. Advances in neural information processing systems. 2018; pp 6410-6421.

[43] Zhou, Z .; Kearnes, S .; Li, L .; Zare, R. N .; Riley, P. Optimization of molecules via deep reinforcement learning. Scientific reports 2019, 9, 1-10.

[44] Dai, H .; Tian, Y .; Dai, B .; Skiena, S .; Song, L. Syntax-directed variational autoen- coder for structured data. arXiv preprint arXiv: 1802.08786 2018.

[45] Nouira, A .; Sokolovska, N .; Crivello, J .- C. Crystalgan: learning to discover crystallo- graphic structures with generative adversarial networks. arXiv preprint arXiv:1810.11203 2018.[46] Tian, Y .; Zhang, X .; Geng, H .- Z .; Yang, H .- J .; Li, C .; Da, S .- X .; Lu, X .; Wang, J .; Jia, S .- L. Carbon nanotube polyurethane films with high transparency, low sheet resistance and strong adhesion for antistatic application. RSC advances 2017, 7, 53018-53024.

[47] Oertel, G .; Abele, L. Polyurethane handbook: chemistry, raw materials, processing, application, properties; 1994.

31

[48] Engels, H .- W .; Pirkl, H .- G .; Albers, R .; Albach, R. W .; Krause, J .; Hoffmann, A .; Casselmann, H .; Dormish, J. Polyurethanes: versatile materials and sustainable prob- lem solvers for today's challenges. Angewandte Chemie International Edition 2013, 52, 9422-9441.

[49] Niu, Y .; Stadler, F. J .; He, T .; Zhang, X .; Yu, Y .; Chen, S. Smart multifunctional poly- urethane microcapsules for the quick release of anticancer drugs in BGC 823 and HeLa tumor cells. Journal of Materials Chemistry B 2017, 5, 9477-9481.

[50] Czech, P .; Okrasa, L .; Méchin, F .; Boiteux, G .; Ulanski, J. Investigation of the polyu- rethane chain length influence on the molecular dynamics in networks crosslinked by hyperbranched polyester. Polymer 2006, 47, 7207-7215.

[51] Li, Y .; Vinyals, O .; Dyer, C .; Pascanu, R .; Battaglia, P. Learning deep generative models of graphs. arXiv preprint arXiv:1803.03324 2018.

[52] Winter, R .; Montanari, F .; Noé, F .; Clevert, D .- A. Learning continuous and datadriven molecular descriptors by translating equivalent chemical representations. Chemical science 2019, 10, 1692-1701.

[53] Berge, C. Hypergraphs: combinatorics of finite sets; Elsevier, 1984; Vol. 45.

[54] Bermond, J .- C .; Heydemann, M .- C .; Sotteau, D. Line graphs of hypergraphs I. Dis- crete Mathematics 1977, 18, 235-241.

[55] Chomsky, N. Three models for the description of language. IRE Transactions on infor- mation theory 1956, 2, 113-124.

[56] Lindenmayer, A. Mathematical models for cellular interactions in development II. Simple and branching filaments with twosided inputs. Journal of theoretical biology 1968, 18, 300-315.

[57] Prusinkiewicz, P .; Lindenmayer, A. The algorithmic beauty of plants; Springer Sci- ence & Business Media, 2012.

32

[58] Hopcroft, J. E .; Motwani, R .; Ullman, J. D. Introduction to automata theory, lan- guages, and computation. Acm Sigact News 2001, 32, 60-65.

[59] Gee, E .; Liu, G .; Hu, H .; Wang, J. Effect of varying chain length and content of poly (dimethylsiloxane) on dynamic dewetting performance of NP-GLIDE polyurethane coatings. Langmuir 2018, 34, 10102- 10113.

[60] Mahapatra, S. S .; Yadav, S. K .; Yoo, H. J .; Cho, J. W .; Park, J .- S. Highly branched polyurethane: Synthesis, characterization and effects of branching on dispersion of carbon nanotubes. Composites Part B: Engineering 2013, 45, 165-171.

[61] Ghoreishi, R .; Suppes, G. Chain growth polymerization mechanism in polyurethane- forming reactions. RSC advances 2015, 5, 68361-68368.

[62] Chomsky, N. Tool Module: Chomsky's Universal Grammar. 2018.

[63] Knuth, D. E .; Morris, J. H., Jr; Pratt, V. R. Fast pattern matching in strings. SIAM journal on computing 1977, 6, 323-350.

[64] Korf, R. E. Artificial intelligence search algorithms. 1999.

[65] Pearl, J. Intelligent search strategies for computer problem solving. Addison Wesley 1984.

[66] Bhardwaj, M .; Choudhury, S .; Scherer, S. Learning heuristic search via imitation. arXiv preprint arXiv: 1707.03034 2017.

33

Supporting Information

Polygrammar: Grammar for Digital Polymer Representation and Generation

Minghao Guo, Wan Shou, Liane Makatura, Timothy Erps, Michael Foshey, Wojciech Matusik*## S1. Production Rules of Global Controllable Grammar



The basic idea of the global controllable grammar is to use a message to collect global information about the chain. The message passes back and forth between the left and right ends of the string. It is achieved by swapping the message's position with the adjacent symbol's one at a time. This swapping continues along a certain direction until the message gets to the string end. At each position swap, the message updates its parameters to collect the information required for the control setting. The full set of the production rules for the message passing mechanism is illustrated as follows. Note that in this case, all of the symbols are non-terminal symbols.

P1 .. None

<>>

None:

None > hM (1,1,0,1)Hh

P2 .. None

<>> None:

None -> hHM(1,1,0,0)h

P3 .. None

< > >

None:

None -> sM(1,0,1,1)Ss

p4 ∶ None < > >

None:

None

-> SSM(1,0,1,0)s

P5 ∶ None < lower > M (l,r, t,d): d = 1 and l < L and r < R > hM (0,0,0,0)}

P6 .. None < lower > M (l,r, t, d):

d == 1 and l < L -> sM (0,0,1,0)S

₱7 ∶ lower < M (l,r,t,d) > upper:

d == 1

Ps : M(l,r,t,d) <H > H:

d == 0

P9 : M(l,r, t,d) <H > h:

d == 0

P10 : M (l,r,t,d) <H > S:

d == 0 -> M (1 +1,+++1, 1, d)

P11 : M (l,r,t,d) <> > H:

d == 0 -> M (1 +1,rxl, 0, d) 'T+1'

P12 : M(l,r,t,d) <> > S:

d == 0

P13 : M (l,r,t, d) < > > S:

d == 0

P14 : lower < M (l,r,t,d) > upper:

-> Null

> M (1 + 1,r*l+1

1+1 1,0,d)

-> M (1 +1,- l+1 , 0, d)

r*l+1

r*l+1

-> M (1 +1,, 1,d)

> M (1 +1,r), r*l

7+1 1,d)

d == 0 and t == 1 →

P15 : lower < M (l,r, t, d) > upper:

d == 0 and t == 1

ℋ

P16 : upper < M (l,r,t,d) > upper:

P17 : upper < M(l,r,t,d) > upper:

t == 1

t == 0

34

> S

> H

P18 : M (l,r,t,d) < lower > P19 : M(l,r, t, d) < lower >

None:

None:

d == 1 and l < Land r < R -> HM(0,0,0,1)h

d == 1 and l < L

- SM (0,0,1,1)s



|P20 :|upper <|M (l,r,t,d) >|lower:|d == 0|> Null|
|---|---|---|---|---|---|
|P21 :|ℋ|<H >|M (l,r, t, d):|d == 1|-> M (1 +1,- r*l+1 *+1, 0, d) 1+1|
|P22 :|ℎ|< H >|M(l,r,t,d):|d == 1|> M (1 + 1,r*+1, 0, d)|
|P23 :|S|< H >|M (l,r, t,d):|d == 1|> M (1 +1, 1+1 , 1,d) r*l+1|
|P24 :|ℋ|< H >|M (l, r,t, d):|d == 1|-> M (1 + 1,r+2, 0, d)|
|P25 :|S|<H >|M (l,r, t, d):|d == 1|-> M (1 +1,2+1, '1+1 1,d)|
|P26 :|S|< H >|M (l,r, t, d):|d == 1|-> M (1 + 1,r) "I+1' ,1,d)|
|P27 :|upper <|M (l,r,t,d) >|lower:|d == 1 and t == 1|>> S|
|P28 :|upper <|M(l,r,t,d) >|lower:|d = 1 and t = 0|> H|


Similar to the PolyGrammar in the main paper, the global controllable grammar is also a context-sensitive parametric grammar. M denotes the message, lower indicates the lower case symbols, containing h and s, upper indicates the upper case symbols, containing H and S. For each production rule in the grammar, the "->" separates the predecessor and the successor. The symbol to be replaced is inside the "<>". The contexts are the symbols located at both sides of "<>" in the predecessor (None indicates no constraints). Parameters of message symbol M locates inside "( )". The logic condition of the parameters for each production rule is between ":" and "->" (None also indicates no constraints here). During the production process, the production rule can only be applied to a symbol when both of its context and the logic condition are satisfied. The production process will stop when no production rules can be invoked, i.e. for each symbol of the string, there are no production rules that can meet the condition and the contexts of the symbol.

With this set of production rules, we can control two constraints of the polyurethane chain: the chain length L and the ratio R of hard segment to soft segment. The message symbol M propagates back and forth between the left and right end of the string, collects global information of the chain and determines how to expand the string meeting the

35

constraints. The propagation is achieved by switching the message's position with the adjacent symbol's along a certain direction one at a time until the message gets to the string end. At each swap, the message updates its parameters to collect information needed for the control setting. There are four parameters in M in total: l indicates the current chain length, r indicates the current chain's ratio of hard segment to soft segment, t is an auxiliary parameter to record the symbol that M is switching with (0 for H, 1 for S), and d indicates the direction that the message is propagating (0 for right, 1 for left). As for the roles that each production rule serves, p1, P2, P3 and p4 initialize the start symbol X. Taking p5, P6 and p7 together, when the left-propagating message arrives at the left end, the string is expanded according to

the collected information and the constraints. Meanwhile, this left-propagating message disappears, and a right-propagating message is generated. This right-propagating message continually switches its position with its right-neighbor symbol using the rules p8, P9, P10, P11, P12, P13, P14, P15, P16 and p17. Similarly, p18, P19 and p20 expand the string when the right-propagating message arrives at the right end and generate a left-propagating message. P21, P22, P23, P24, P25, P26, P27, P28, P16 and p17 propagate the left-propagating message by iteratively switching its position with its left-neighbor symbol. A detailed illustrative example of the message passing mechanism is shown in Figure. S1.

The example in Figure. S1 illustrates the production process under the constraints L = 3, R = 0.67, where the chain length is 3 and the ratio of hard segment to soft segment is lower than 0.7. At step 1, p1 expands the initial symbol X. The parameters of M indicate that the message is currently propagating along the left direction (d = 1). Since it has already reached the left end of the string and the current ratio r = 1 is larger than the constraint R = 0.67, at step 2, p6 expands the left end of the string with S and also generates a new message M (l = 0, r = 0) propagating along the right direction (d = 0). Meanwhile, the previous message disappears by p7. Then at step 3 and step 4, the message propagates along the right direction

36

by switching position with its right neighbor. The switching is assisted with the auxiliary parameter t. Also during the propagation, l and r are updated to record the information of chain length and the ratio of hard segment to soft segment. At step 5, the message reaches the right end of the string, so p18 expands the string with H as the ratio r = 0.5 is smaller than R = 0.67. A new left-propagating message is generated and the old message disappears. At step 6, 7, and 8, the message carries on the propagation and collects the information. At step 9, when the message reaches the left end, since the chain length l = 3 meets the constraints L = 3, the message disappears and the production process concludes.



|Step|Production Process|Parameters of M|
|---|---|---|
|1|17 P1|None|
|2|hMHh Null|l=1,r=1,t= 0, d = 1|
|3|SMSHh|l=0, r= 0, t = 1, d = 0|
||PIA P11||
|4|SSMHh|l=1,r=0,t = 0, d = 0|
||P17 Pg||
|5|1 SSHMh P20 P18 Null|l=2, r= 0.5, t = 0, d = 0|
|6|SSHHMh P21|l=0, r= 0, t = 0, d = 1|
|7|SSHMHh P23|l=1,r=1,t=0, d = 1|
|8|SSMHHh 1 P26 PIG|l=2, r=1,t = 0, d = 1|
|9|SMSHHh 1 P7 1 Null|l=3, r= 0.67, t = 0, d = 1|
||SSHHh||


Figure. S1. Illustrative example of the message passing mechanism with constraints L = 3, R = 0.67.

37

## S2. Collected Dataset of Polyurethane from Literature



We have collected a dataset of polyurethane data from literature, including 8 different types of isocyanates, 11 types of polyols and 7 types of chain extenders. Each sample is illustrated in the form of BigSMILES. Detailed samples are illustrated as follows,



|Name|BigSMILES|
|---|---|
|Diisocynates||
|TDI|CC1=CC=C(NC(=O)>)C=C1NC(=O)>|
|MDI|>C(=O)Nc1ccc(Cc2cccNC(=O)>cc2)cc1|
|HDI|>C(=O)NCCCCCCNC(=O)>|
|IPDI|CC1(C)CC(NC(=O)>)CC(CNC(=O)>)(C)C1|
|DBDI|>C(=O)Nc1ccc(CCc2ccc(NC(=O)>)cc2)cc1|
|HMDI|>C(=O)NC1CCC(CC2CCC(NC(=O)>)CC2)CC1|
|NDI|>C(=O)Nc1cccc2c(NC(=O)>)cccc12|
|TMDI|CC(CCNC(=O)>)CC(C)(C)CNC(=O)>|
|Polyols||
|PTMO/ PTHF|<OCCC { [<] occcc [ > ] } O<|
|PEG/ PEO|<OCC { [<] occ [> ] } O<|
|PEA|<OCCOC (=0) CCCCC (=0) { [<]occoc (=0) CCCCC (=0) [>] }O<|
|PBA|<0CCCCOC (=0) CCCCC (=0) { [<]occccoc (=0) CCCCC (=0) [>] }0<|
|PBU|CC=CC|
|PCL/ PCD|<OCCCCCC (=0) Occcccc (=0) { [<] occcccc (=0) occcccc (=0) [>] }0<|
|PHA|<0CCCCCCOC (=0) occccccoc (=0) 0{ [<]occccccoc (=0) occccccoc (=0) 0 [>] }0 <|
|PET|<OC(=O)c1ccc(cc1)C(=O)OCC{[<]OC(=O)c1ccc(cc1)C(=O)OCC[>]}O<|
|PLA|<OC(C)C(=O){[<]OC(C)C(=O)[>]}O<|
|CHDM|<OCC1CCC (CC1) C{ [<] occ1ccc (CC1 ) C [> ] } O<|
|||
|Poly bd|<OCC=CCCC (C=C) CC=CC { [<]occ=CCCC (C=C) CC=CC } O<|


38



|Chain Extenders||
|---|---|
|BDO/ BD/BG|<OCCCCO<|
|EG|<OCCO<|
|DEG|<OCCOCCO<|
|DAPO|<Nc1ccc(cc1)-c2nnc(o2)-c3ccc(cc3)N<|
|DAB|<Nc1ccc (CCc2ccc (N<) cc2) cc1|
|DAPy|C1=CC(=NC(=C1) N (<) ) N<|
|MDA|<Nc1ccc (Cc2ccc (N<) cc2) cc1|


By combining 3 types of components, this dataset contains 8 × 11 x 7 = 616 types of polyurethanes that are commonly used in the synthesis and real-world fabrication. The full names of the abbreviations in the dataset are listed in Table S5. These data samples are stored in a ".CSV" file and can be easily handled using Python code to perform the algorithms of generative model and translation from SMILES. It is also capable to add new structures to this dataset. The only thing to do is to convert the structure to the BigSMILES format and add it to the ".CSV" file.

## S3. Examples of Translation from SMILES



## 1. Input SMILES:



CC1 (C) CC (NC (=0) occccoccccoccccoccccoc (=0) NCC2 (C) CC (NC (=0) OCCCCOC(=O)NCC3(C)CC(NC(=O)OCCCCOC(=O)NCC4(C)CC(NC(=O)OCC CCOCCCCOC(=O)NCC5(C)CC(NC(=O)OCCCCOC(=O)NCC6(C)CC(NC(=O)O ccccoccccoccccoccccocccCO) CC (C) (C) C6) CC (C) (C) C5) CC (C) (C) C 4)CC(C)(C)C3)CC(C)(C)C2)CC(C)(CN=C=O)C1

Translation Results:

Component types: IPDI, PTMO, BDO

39

Symbolic hypergraph string: HSHHHSHHS

Production rules: {p1, P10, P12, P9, P9, P10, P12, P9, P10, P5, P14}

## 2. Input SMILES:



Cc1ccc (NC (=0) Occccoc (=0) Nc2cc (NC (=0) occccoccccoccccocccco ccccoccccoccccoc (=0) Nc3cc (NC (=0) OCCOC (=0) Nc4cc (NC (=0) OCCO C(=0) Nc5cc (NC(=0) OCCCCOC (=0) Nc6cc (NC (=0) occcc0) ccc6C) ccc5 C) ccc4C) ccc3C) ccc2C) cc1NC (=0) occcco

Translation Results:

Component types: TDI, PTMO, EG Symbolic hypergraph string: SHSHHHSHSHS

Production rules: {p1, P4, P10> P6, P4, P6, P3, P3, P4, P6, P4, P8, P14}

## 3. Input SMILES:



CC(OC(=O)Nc1cccc2c(NC(=O)OCCCCOC(=O)Nc3cccc4c(NC(=O)OCCCC OC(=O)Nc5cccc6c(NC(=O)OC(=O)C(C)OC(=O)C(C)OC(=O)Nc7cccc8c (NC(=O)OC(=O)C(C)OC(=O)Nc9cccc%10c(NC(=O)OCCCCOC(=O)Nc%11 cccc%12c(N=C=O)cccc%11%12)cccc9%10)cccc78)cccc56)cccc34)c ccc12) C(=0)OC(=0)Nclcccc2c(NC(=0) OccccOC (=0) Nc3cccc4c (NC ( =O)OC(C)C(=O)OC(=O)Nc5cccc6c(NC(=O)OCCCCOC(=O)Nc7cccc8c(N C(=0) occccOC (=0) Nc9cccc%10c (NC (=0) OccccOC (=0) Nc%11cccc%12 c(N=C=O)cccc%11%12)cccc9%10)cccc78)cccc56)cccc34)cccc12

Translation Results:

Component types: NDI, PLA, BDO

Symbolic hypergraph string: HHSHSHHHSHHSHHHH

Production rules: {p2, P6> P12> P3, P9, P3, P10, P4, P12, P6, P9, P4, P9, P6, P9, P3, P5, P11}

## 4. Input SMILES:



40

O=C(NC1CCC(CC2CCC(NC(=O)OCCOCCOC(=O)NC3CCC(CC4CCC(NC(=O)O CCOC(=O)NC5CCC(CC6CCC(NC(=O)OCCOC(=O)NC7CCC(CC8CCC(NC(=O) ocCOCCOC (=0) NC9CCC (CC%10CCC (NC (=0) Occoccoc (=0) NC%11CCC (CC %12CCC (NC (=0) Occoccoc (=0) NC%13CCC (CC%14CCC (NC (=0) Occoc (=0 ) NC%15CCC (CC%16CCC (NC (=0) occocco) CC%16) CC%15) CC%14) CC%13) CC%12) CC%11) CC%10) CC9) CC8) CC7) CC6) CC5) CC4) CC3) CC2) CC1) OCC occoccocco

Translation Results:

Component types: HMDI, PEG, DEG Symbolic hypergraph string: SHHHHHHHHHHHS

Production rules: {p1, P10>P3,P3, P3, P3, P3, P3, P3, P3, P3, P3, P4, P8, P14}

## 5. Input SMILES:



O=C=Nc1ccc (Cc2ccc (NC(=0) occccoccccoccccoc (=0) Nc3ccc (Cc4cc c (NC (=0) occoccoc (=0) Nc5ccc (Cc6ccc (NC (=0) Occccoc (=0) Nc7ccc (Cc8ccc (NC (=0) occoccoc (=0) Nc9ccc (Cc%10ccc (NC (=0) occccoccc coccccoccccoccccOC (=0) Nc%11ccc (Cc%12ccc (NC (=0) Occccoc (=0) Nc%13ccc(Cc%14ccc(N=C=O)cc%14)cc%13)cc%12)cc%11)cc%10)cc9 ) cc8) cc7) cc6) cc5) cc4) cc3) cc2) cc1

Translation Results:

Component types: MDI, PTMO, DEG

Symbolic hypergraph string: HSHHSHHSHSH

Production rules: {p1, P10, P12, P9, P10, P12, P9, P10, P12, P10, P12, P5, P11}

## 6. Input SMILES:



O=C=NCCCCCCNC (=0) Occcccc (=0) occcccc (=0) occcccc (=0) occcccc

(=0) oCccccc (=0) occcccc (=0) occcccc (=0) occcccc (=0) Occcccc (=

41

0) OCCCCCC (=0) Occcccc (=0) OCCCCCC (=0) OC (=0) NCCCCCCNC (=0) OCC OC (=0) NCCCCCCNC (=0) OCCOC (=0) NCCCCCCNC (=0) OccccCC (=0) Occcc CC (=0) Occcccc (=0) occcccc (=0) occcccc (=0) occcccc (=0) OC (=0) N CCCCCCNC (=0) occcccc (=0) occcccc (=0) OC (=0) NCCCCCCNC (=0) OCco C(=O)NCCCCCCN=C=O

Translation Results:

Component types: HDI, PCL, EG

Symbolic hypergraph string: HSHHHSHSHH

Production rules: {p1, P10, P12> P9, P9, P10, P12, P10, P12, P9, P5, P11}

## 7. Input SMILES:



CC(O)C(=O)OC(C)C(=O)OC(=O)Nc1ccc(Cc2ccc(NC(=O)OC(C)C(=O)O C(=O)Nc3ccc(Cc4ccc(NC(=O)OCCCCOC(=O)Nc5ccc(Cc6ccc(NC(=O)O CCCCOC(=O)Nc7ccc(Cc8ccc(NC(=O)OC(C)C(=O)OC(C)C(=O)OC(C)C( =O)OC(=O)Nc9ccc(Cc%10ccc(NC(=O)OC(C)C(=O)OC(=O)Nc%11ccc(C c%12ccc(NC(=O)OC(C)C(=O)OC(=O)Nc%13ccc(Cc%14ccc(NC(=O)OCC CCOC(=O)Nc%15ccc(Cc%16ccc(NC(=O)OC(C)C(=O)O)cc%16)cc%15)c c%14) cc%13) cc%12) cc(11) cc%10) cc9) cc8) cc7) cc6) cc5) cc4) cc3) cc2) cc1

Translation Results:

Component types: MDI, PLA, BDO

Symbolic hypergraph string: SHSHHHSHSHSHHS

Production rules: {p2, P12, P10, P12, P9, P9, P10, P12, P10, P12, P10, P12, P9, P10, P8, P14}

## 8. Input SMILES:



C=CC (CC=CO) CCC=CCOC=CCC (C=C) CCC=CCOC=CCC (C=C) CCC=CCOC=CCC (C=C)CCC=CCOC(=O)NC1CC(C)(C)CC(C)(CNC(=O)OC=CCC(C=C)CCC=C

42

COC(=O)NC2CC(C)(C)CC(C)(CNC(=O)Nc3cccc(NC(=O)NC4CC(C)(C)C C(C)(CNC(=O)OC=CCC(C=C)CCC=CCOC=CCC(C=C)CCC=CCOC=CCC(C=C) CCC=CCOC(=O)NC5CC(C)(C)CC(C)(CNC(=O)OC=CCC(C=C)CCC=CCOC=C CC(C=C)CCC=CCOC(=O)NC6CC(C)(C)CC(C)(CNC(=O)NC7CCCC(NC(=O) NC8CC(C)(C)CC(C)(CNC(=O)Nc9cccc(NC(=O)NC%10CC(C)(C)CC(C)( CN=C=O)C%10)n9)C8)n7)C6)C5)C4)n3)C2)C1

Translation Results:

Component types: IPDI, Poly bd, DAPy Symbolic hypergraph string: SHSHS Production rules: {p2, P12, P10, P13, P12, P10, P13, P13, P8, P14}

## 9. Input SMILES:



C=CC (CC=COCC=CCCC (C=C) CC=COC (=0) Nc1ccc (Cc2ccc (NC (=0) OCCoc COC(=O)Nc3ccc(Cc4ccc(NC(=O)OCC=CCCC(C=C)CC=COC(=O)Nc5ccc( Cc6ccc(NC(=O)OCC=CCCC(C=C)CC=COC(=O)Nc7ccc(Cc8ccc(NC(=O)O CC=CCCC (C=C) CC=COC (=0) Nc9ccc (Cc%10ccc (NC (=0) Occoccoc (=0) N c%11ccc(Cc%12ccc(NC(=O)OCC=CCCC(C=C)CC=COC(=O)Nc%13ccc(Cc %14ccc(NC(=O)OCC=CCCC(C=C)CC=COC(=O)Nc%15ccc(Cc%16ccc(N=C =O)cc%16)cc%15)cc%14)cc%13)cc%12)cc%11)cc%10)cc9)cc8)cc7) cc6)cc5)cc4)cc3)cc2)cc1)CCC=CCOC=CCC(C=C)CCC=CCOC(=O)Nc1c cc(Cc2ccc(N=C=O)cc2)cc1

Translation Results:

Component types: MDI, Poly bd, DEG Symbolic hypergraph string: HSHSHHSHSHSHHSH

Production rules: {p2, P6, P12, P3, P4, P6, P4, P6, P4, P6, P3, P4, P6, P4, P6, P5, P11}

## 10. Input SMILES:



43

O=C(O)CCCCC(=O)OCCOC(=O)Nc1cccc2c(NC(=O)OC(=O)CCCCC(=O)OC COC (=0) Nc3cccc4c(NC(=0) OC(=0) CCCCC (=0) Occoc (=0) CCCCC (=0) 0 CCOC(=O)Nc5cccc6c(NC(=O)Nc7cccc(NC(=O)Nc8cccc9c(NC(=O)Nc% 10cccc(NC(=O)Nc%11cccc%12c(NC(=O)Nc%13cccc(NC(=O)Nc%14ccc c%15c(NC(=O)Nc%16cccc(NC(=O)Nc%17cccc%18c(NC(=O)Nc%19cccc (NC(=O)Nc%20cccc%21c(NC(=O)OC(=O)CCCCC(=O)OCCOC(=O)Nc%22c ccc%23c(NC (=0) OC (=0) CCCCC (=0) OCCOc (=0) CCCCC (=0) Occoc (=0) C CCCC (=0) occo) cccc%22%23) cccc%20%21) nº19) cccc%17%18) nº16) c ccc%14%15) nº13) cccc%11%12) nº10) cccc89) n7) cccc56) cccc34) cc cc12

Translation Results:

Component types: NDI, PEA, DAPy Symbolic hypergraph string: SHSHSHS

Production rules: {p2, P12, P10, P12, P10, P13, P13, P13, P13, P13, P12, P10, P8, P14}

## S4. Generalized PolyGrammar to Other Polymers



The extended PolyGrammar for different types of copolymers and functional groups is illus- trated as follows,

· for block copolymers,

P1 : None < > > None: None > hH (0.5LH)h P2 : None < > > None: None -> SS (0.5Ls)s P3 : None < h > H(x): x ≥ 1 -> hH (x -1) p4 : None < h > H(x): x < 1 -> SS(Ls) Ps : None <h > H(x): x <1 -> Null P6 : None <s > S(x): x ≥ 1 -> SS(x-1) P7 : None < > > S(x): x < 1 > hH (LH) Ps : None <s > S(x): x < 1 -> Null p9 : H(x) <h> None: x ≥1-> H(x-1)h

44

P10: H (x) <h > None: x < 1 -> S(Ls)s P11: H (x) <h > None: x < 1 -> Null P12: S(x) <s> None: x ≥1-> S(x-1)s P13: S(x) < > > None: x < 1 > H (LH)h P14: S(x) < > > None: x < 1 > Null

## · for alternating copolymers,



P1 : None < > > None: None ~> hH (L)h P2 : None < > > None: None -> SS (L)s P3 : None <h> H(x): x≥1-> SS(x-1) P4 : None < h > H(x): x < 1 > Null Ps : None <s > S(x): x ≥ 1 -> hH(x-1) P6 : None <s > S(x): x < 1 -> Null pz: H(x) <h>None:x ≥1->S(x-1)s Ps : H(x) <h > None: x <1-> Null P9: S(x) <s > None: x ≥ 1 -> H(x-1)h P10: S(x) < > > None: x < 1 > Null

· for functional groups of polyacrylates,

P1:b(x) < F > None: y = x + z → c(y)A(z) P2 : None < A(z) > None: z > 1-> [A(z-1)]A(1) P3 : None < A(z) > None: z ≥ 1 -> [b(x)]F p4 : None < A(z) > None: z ≤ 1 -> None

## S5. Pseudo-code of Translation from SMILES



The inverse design process contains three parts: disconnecting carbamate bonds, constructing the hypergraph and BFS searching for rules matching. The pseudo code is illustrated as follows.

Algorithm 1: Pseudo-code of translation from SMILES. Input:

SMILES string of polyurethane chain P The set of production rules of PolyGrammar {pil i = 1, ... , N} The set of SMILES strings of isocyanate candidates {J¿ | i = 1, ... , N}}

45

The set of SMILES strings of macrodiol candidates {Dil i = 1, ... , ND}

The set of SMILES strings of chain-extender candidates {Cil i = 1, ... , Nc} Output:

The sequence of the production rules {pk|k = ii, ... , ik} to produce P

Function GetSubstructMatches (a, s) :

/ *

input :

SMILES string, a (the substructure sought) SMILES string, s (the total molecule to be searched) output : an array of integers or Ø, P (positions in s at which a is * / /* standard substructure matching algorithm */ return P;

found)

Function KMPMatching (a, s) : / * input :

SMILES string, a (the word sought) SMILES string, s (the text to be searched) output : an array of integers, P positions in s at which a is found) * / /* standard KMP string matching algorithm */ return P;

Function ConstructGraph (a, n) :

/ * input :

adjacency matrix, a an array of nodes, n output : an undirected graph, G */ /* standard undirected graph construction algorithm */ return G;

Function BFSearch (G) :

/ * input : an undirected graph, G output : an array of traversed edges, e * / /* standard Breadth-first Search algorithm */ return e;

/* 1. Disconnecting carbamate bonds */

1 CBondSMILES < SMILES of Carbamate Bond;

2 CBondIdx + GetSubstructMatches (CBondSMILES, P) ;

3 n + length (CBondIdx) ;

46

4 FragmentSet « Ø;

5 CBondSet + Ø;

6 StartIdx + 0;

7 for i + 0 to n do

8 if i == n then

9 location « i;

10 else

11 EndIdx + CBondIdx[i];

12 FragmentSet + FragmentSet U {P[StartIdx: EndIdx]};

13 BondEndIdx < EndIdx + length (CBond) ;

14 CBondSet { CBondSet U {P [EndIdx: BondEndIdx]};

15 StartIdx + BondEndIdx;

/* 2. Identifying the symbol type and constructing the hypergraph */

16 n + length (FragmentSet) ;

17 AdjacencyMatrix + n xn zero matrix ;

18 HyperNodes + Ø; /* get the adjacency matrix */

19 for i + 0 to n - 1 do

20 CBond + CBondSet [i];

21 CBondStart « CBond[0];

22 CBondEnd + CBond [end];

23 for j + 0 to n - 1 do

24 Fragment + FragmentSet[i];

25 if CBondStart in Fragment then

26 StartIdx = j;

27 else if CBondEnd in Fragment then

28 EndIdx = j;

29 Adjacency Matrix [StartIdx][EndIdx] = 1; Adjacency Matrix [EndIdx] [StartIdx] = 1;

30 /* get the symbol type */

## 31 for i + 0 to n - 1 do



32 if {KMPMatching (Fragment , Ji) } is not Ø then

33 Hyper Nodes < HyperNodes U {'H'};

34 else if {KMPMatching (Fragment, Di) } is not Ø then

35 HyperNodes « HyperNodes U {'S'};

36 else if {KMPMatching (Fragment, Ci) } is not Ø then

37 38 HyperGraph + ConstructGraph (AdjacencyMatrix, HyperNodes) ; 3. BES searching the graph and rules matching */

HyperNodes « HyperNodes U {'u'};

39 EdgeList < BFSearch (HyperGraph) ;

40 P + Ø;

41 n + length (EdgeList) ;

42 for i + 0 to n - 1 do

43 Edge « EdgeList[i];

44 Pre « Edge. predecessor;

45 Suc + Edge. successor;

46 Rule { {pi}. find (<Pre, Suc>) ;

47 P + PU Rule;

## 48 return P



47

S6. Examples of Generated Polyurethane Chains

Index

Diisocyanate

1

DBDI

2

TMDI

Macrodiol

Chain Extender

Generated Hypergraph Symbolic String

PTMO

DAPO

O

O

O

O

O

N

N

O

O

O

O

H

H

N

N

N

N

O

O

O

O

N

N

N

N

H

H

O

O

O

O

O

O

N

O

N

N

O

C

O

O

O

O

N

C

N

O

O

H

H

N

O

O

O

N

O

N

N

N

O

O

O

O

N

N

O

O

N

N

H

H

O

O

O

N

N

PCL

DAB

HSHHSHHSHSHHHHS

O

C

N

O

O

O

O

O

O

H

N

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

H

O

N

O

O

O

O

O

O

O

O

O

O

3

NDI

O

O

O

O

O

O

O

H

H

N

O

H

O

N

N

O

O

O

N

N

H

H

O

N

N

H

H

PEA

DAPy

SHSHHSHHS

O

O

O

O

O

O

O

O

O

O

O

4

DBDI

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

N

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

N

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

PCL

MDA

HHSHSHHSHHSHSHS

48

H

H

N

N

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

N

C

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

5

MDI

O

O

PHA

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

BDO

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

6

DBDI

Poly bd

O

DAB

O

O

O

O

O

O

O

SHSHHHSHS

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

SHSHHHSHHHSHHSH

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

N

O

C

O

O

7

NDI

O

O

PTMO

DAB

49

SHHHHSHSHSHSHHS

O

O

O

O

O

O

O

O

O

O

O

O

8

MDI

PTMO

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

EG

SHHHSHSHSHSHS

O

O

H

N

O

O

H

O

N

O

O

O

O

O

O

O

O

O

O

O

O

O

9

HDI

O

PBU

O

O

O

O

O

N

H

O

O

O

O

O

O

O

N

H

O

DAPy

HSHSHHSHSHHHSHS

O

O

O

O

O

C

N

O

O

O

O

O

O

O

O

O

O

O

N

O

O

O

10

MDI

PCL

O

H

N

O

O

O

N

N

H

N

H

O

N

H

N

H

N

O

O

N

H

O

O

O

O

O

DAPy

SHHHSHHSHHSHHHSH

50

O

O

O

O

C

O

N

O

O

O

N

N

H

O

N

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

N

O

O

N

O

O

O

O

N

N

H

H

O

O

N

H

N

H

O

N

O

N

N

H

O

H

N

O

O

H

O

N

N

H

N

H

S7. Examples of Branched Polyurethane Chains



|Index|Diisocyanate|Macrodiol|Chain Extender|Generated Hypergraph Symbolic String|
|---|---|---|---|---|
|1|TDI|PET|DAPy, 3THA|HSHHHHHH HHHH]SHHH|


N

C

O

O

N

O

O

O

N

O

O

O

O

O

O

O

O

O

O

N

C

O

O

O

O

N

N

O

O

N

O

C

O

N

O

O

O

N

O

N

O

O

O

O

N

O

O

N

N

O

N

O

N

O

O

N

O

O

O

O

O

O

O

O

2

DBDI

PTMO

MDA, 3THA

3

DBDI

PCD

EG, 3THA

HH [H]HHSHSHHSH

51

O

C

O

N

O

O

O

H

O

N

H

O

N

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

N

O

O

O

O

N

N

O

O

O

O

O

O

O

O

O

O

O

N

O

H

N

O

C

O

O

O

O

O

O

O

N

C

O

4

HDI

PBA

BG, 3THA

## HSHSHH [HS]SHHS



O

C

N

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

O

H

N

O

O

N

H

O

O

O

O

O

O

O

N

N

N

N

H

O

O

O

O

O

O

O

O

O

O

O

O

N

H

H

N

O

O

O

O

O

O

O

O

O

O

O

5



|NDI|CHDM|EG, 3THA||
|---|---|---|---|
|O N O O||O O O N O N O O N O C O O O O N O N O N O O O O O O O O O|O O O O O O O O O O|


52

## S8. Examples of Acrylate's Functional Groups





|Index|Generated Hypergraph Symbolic String|Acrylate's Functional Group|
|---|---|---|
|1 1|b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(2)||
|2|b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(4) [b(1)c(1)][b(1)c(1)]b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(4)[b(1)c(1)] [b(1)c(1)]b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(4)[b(1)c(1)][b(1)c(1)] b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(1)||
|3|b(1)c(4)[b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(1)][b(1)c(1)]b(1)c(4) [b(1)c(1)][b(1)c(1)]b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(1)|*|
|4|b(1)c(4)[b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(1)][b(1)c(4)[b(1)c(1)] [b(1)c(1)]b(1)c(1)][b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(1)]|*|
|5|b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(2) b(1)c(4)b(1)c(1)[b(1)c(1)][b(1)c(1)]|O *|
|6|b(1)c(2)b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(2)b(1)c(4)[b(1) c(1)][b(1)c(1)]b(1)c(1)|*|
|7|b(1)c(4)[b(2)c(2)]b(1)c(3)[b(1)c(1)]b(1)c(1)|O * 'NH2|
|8|b(1)c(2)b(2)c(2)b(1)c(4)[b(1)c(1)][b(1)c(4)[b(1)c(1)][b(1)c(1)] b(1)c(1)b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(1)|O *|
|9|b(1)c(4)[b(1)c(2)b(1)c(1)][b(1)c(1)]b(1)c(4)[b(1)c(4)[b(1)c(1)][ b(1)c(1)]b(1)c(1)][b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(1)][b(1)c(4) [b(1)c(1)][b(1)c(1)]b(1)c(1)]|OH|


53

b(1)c(2)b(1)c(2)b(1)c(4)[b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(1)] [b(1)c(4)[b(1)c(1)][b(1)c(1)]b(1)c(1)][b(1)c(4)[b(1)c(1)][b(1)c(1)] b(1)c(1)]b(1)c(2)b(1)c(2)b(1)c(1)

10

O

*

"OH

## S9. Abbreviations and Acronyms





|MDI|4,4'-methylenebis(phenyl isocyanate)|
|---|---|
|TDI|toluene-diisocyanate|
|DBDI|4,4'-dibenzyl diisocyanate|
|HDI|1,6-diisocyanatohexane|
|HMDI|hydrogenated MDI|
|IPDI|isophorone diisocyanate|
|NDI|1,5-Naphthalene diisocyanate|
|TMDI|2,2,4-trimethyl-1,6-hexamethylelne diisocyanate|
|PEG / PEO|poly(oxyethylene) glycol|
|PEA|poly(ethylene adipate)diol|
|PBA|poly(butane adipate) diol|
|PTMO / PTHF|poly(oxytetramethylene) diol / polytetrahydrofurane diol|
|PBU|poly(butadiene)diol|
|PCL / PCD|polycaprolactone diol|
|PHA|polyhexamethylene carbonate glycol|
|PET|polyethylene terephthalate|
|PLA|polylactic acid (lactic acid)|
|CHDM|1,4-cyclohexane dimethanol|
|Poly bd|polybutadiene diol|
|BD / BG / BDO|1,4-butanediol|
|EG|ethylene glycol|
|DEG|diethylene glycol|
|DAPO|2,5-bis-(4-amino-phenylene)-1,3,4-oxadiazole|
|DAB|4,4'-diamino-dibenzyl|


54



|DAPy|2,6-diamino-pyridine|
|---|---|
|MDA|4,4'-methylene-dianiline|


55

