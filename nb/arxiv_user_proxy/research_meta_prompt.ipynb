{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM models:  ['gpt-4']\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "from autogen import AssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    file_location=\"..\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-3.5-turbo\", \"gpt-35-turbo\", \"gpt-35-turbo-0613\", \"gpt-4\", \"gpt4\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"LLM models: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n",
    "\n",
    "# Termination message definition\n",
    "termination_msg = (\n",
    "    lambda x: isinstance(x, dict)\n",
    "    and str(x.get(\"content\", \"\")).upper() == \"TERMINATE\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": config_list,  # config_list should be defined or imported\n",
    "    \"timeout\": 120,\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Literal, Optional, Union, Dict\n",
    "from autogen.agentchat.conversable_agent import ConversableAgent\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "def run_meta_prompting(expert_name: Annotated[str, \"Name of the expert. Should follow the format: Expert xxx.\"], \n",
    "                   expert_identity: Annotated[str, \"A high-quality description about the most capable and suitable expert to answer the instruction. In second person perspective. For example, You are a linguist, well-versed in the study of language and its structures. You are equipped with a good understanding of grammar rules and can differentiate between nouns, verbs, adjectives, adverbs, etc. You can quickly and accurately identify the parts of speech in a sentence and explain the role of each word in the sentence. Your expertise in language and grammar is highly valuable in analyzing and understanding the nuances of communication.\"], \n",
    "                   task: Annotated[str, \"The task that needs to be solved by the expert.\"]) -> str:\n",
    "    \"\"\"\n",
    "    Run Meta-prompting to solve the task.\n",
    "    The method is adapted from \"Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding\".\n",
    "    Paper available at https://arxiv.org/abs/2401.12954\n",
    "    \"\"\"\n",
    "    print(\"Running meta prompting...\")\n",
    "    print(\"Querying expert: \", expert_name)\n",
    "\n",
    "    expert = autogen.AssistantAgent(\n",
    "        name=expert_name,\n",
    "        human_input_mode=\"NEVER\",\n",
    "        llm_config=llm_config,\n",
    "        system_message='You are an AI assistant that helps people find information. Please answer the following question. Once you have determined the final answer, please present it using the format below:\\n\\n>> FINAL ANSWER:\\n\"\"\"\\n[final answer]\\n\"\"\"',\n",
    "        max_consecutive_auto_reply=1,\n",
    "    )\n",
    "    user_proxy = autogen.UserProxyAgent(\n",
    "        name=\"user_proxy\",\n",
    "        human_input_mode=\"NEVER\",\n",
    "        default_auto_reply=\"TERMINATE\",\n",
    "        code_execution_config={\n",
    "            \"work_dir\": \"coding\",\n",
    "            \"use_docker\": False,\n",
    "        },\n",
    "        max_consecutive_auto_reply=1,\n",
    "    )\n",
    "    task += \"\\nYou have access to python code interpreter. Suggest python code block starting with '```python' and the code will be automatically executed. You can use code to solve the task or for result verification. You should always use print statement to get the value of a variable.\"\n",
    "    user_proxy.initiate_chat(expert, message=expert_identity + \"\\n\" + task, silent=True)\n",
    "\n",
    "    expert_reply = user_proxy.chat_messages[expert][1][\"content\"]\n",
    "    proxy_reply = user_proxy.chat_messages[expert][2][\"content\"]\n",
    "\n",
    "    if proxy_reply != \"TERMINATE\":\n",
    "        code_result = proxy_reply[proxy_reply.find(\"Code output:\") + len(\"Code output:\") :].strip()\n",
    "        expert_reply += f\"\\nThis is the output of the code blocks when executed:\\n{code_result}\"\n",
    "    else:\n",
    "        expert_reply.replace(\n",
    "            \"FINAL ANSWER:\",\n",
    "            f\"{expert_name}'s final answer:\\n\",\n",
    "        )\n",
    "\n",
    "    return expert_reply\n",
    "\n",
    "\n",
    "class MetaAgent(ConversableAgent):\n",
    "    SYSTEM_MESSAGE = \"\"\"You are Meta-Expert, an extremely clever expert with the unique ability to collaborate with multiple experts (such as Expert Problem Solver, Expert Mathematician, Expert Essayist, etc.) to tackle any task and solve any complex problems. Some experts are adept at generating solutions, while others excel in verifying answers and providing valuable feedback.\n",
    "As Meta-Expert, your role is to oversee the communication between the experts, effectively using their skills to answer a given question while applying your own critical thinking and verification abilities.\n",
    "To communicate with a expert, call function \"meta_prompting\" with the expert's name, identity information and the task that needs to be solved. The function will return a response from the expert.\n",
    "Ensure that your instructions are clear and unambiguous, and include all necessary information within the triple quotes. You should assign personas to the experts (e.g., \"You are a physicist specialized in...\").\n",
    "You can interact with only one expert at a time, and break complex problems into smaller, solvable tasks. Each interaction is treated as an isolated event, so include all relevant details in every call.\n",
    "Refrain from repeating the very same questions to experts. Examine their responses carefully and seek clarification if required, keeping in mind they don't recall past interactions.\n",
    "Upon the completion of all tasks and verifications, you should conclude the result and reply \"TERMINATE\".\n",
    "\"\"\"\n",
    "    # TOOL = {\n",
    "    #     \"type\": \"function\",\n",
    "    #     \"function\": {\n",
    "    #         \"name\": \"meta_prompting\",\n",
    "    #         \"description\": \"Solve a task by querying an expert. Provide the expert identity and the task that needs to be solved, and the function will return the response of the expert.\",\n",
    "    #         \"parameters\": {\n",
    "    #             \"type\": \"object\",\n",
    "    #             \"properties\": {\n",
    "    #                 \"task\": {\n",
    "    #                     \"type\": \"string\",\n",
    "    #                     \"description\": \"[REQUIRED] The task that needs to be solved by the expert.\",\n",
    "    #                 },\n",
    "    #                 \"expert_name\": {\n",
    "    #                     \"type\": \"string\",\n",
    "    #                     \"description\": \"[REQUIRED] Name of the expert. Should follow the format: Expert xxx.\",\n",
    "    #                 },\n",
    "    #                 \"expert_identity\": {\n",
    "    #                     \"type\": \"string\",\n",
    "    #                     \"description\": \"[REQUIRED] A high-quality description about the most capable and suitable expert to answer the instruction. In second person perspective. For example, You are a linguist, well-versed in the study of language and its structures. You are equipped with a good understanding of grammar rules and can differentiate between nouns, verbs, adjectives, adverbs, etc. You can quickly and accurately identify the parts of speech in a sentence and explain the role of each word in the sentence. Your expertise in language and grammar is highly valuable in analyzing and understanding the nuances of communication.\",\n",
    "    #                 },\n",
    "    #             },\n",
    "    #         },\n",
    "    #     },\n",
    "    # }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: Optional[str] = None,\n",
    "        llm_config: Optional[Union[Dict, Literal[False]]] = None,\n",
    "        is_termination_msg: Optional[Callable[[Dict], bool]] = None,\n",
    "        max_consecutive_auto_reply: Optional[int] = None,\n",
    "        human_input_mode: Optional[str] = \"NEVER\",\n",
    "        code_execution_config: Optional[Union[Dict, Literal[False]]] = False,\n",
    "        description: Optional[\n",
    "            str\n",
    "        ] = \"A helpful AI assistant that can build a group of agents at a proper time to solve a task.\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            system_message=self.SYSTEM_MESSAGE,\n",
    "            llm_config=llm_config,\n",
    "            is_termination_msg=is_termination_msg,\n",
    "            max_consecutive_auto_reply=max_consecutive_auto_reply,\n",
    "            human_input_mode=human_input_mode,\n",
    "            code_execution_config=code_execution_config,\n",
    "            description=description,\n",
    "            **kwargs,\n",
    "        )\n",
    "        # self.update_tool_signature(self.TOOL, is_remove=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running meta prompting...\n",
      "Querying expert:  Expert Researcher\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As an AI language model, I do not have real-time access to external databases like Arxiv or the ability to execute Python code. However, I can guide you on how to find the latest research articles related to the modeling of reliability and safety mechanisms in AI systems, especially Large Language Models (LLMs).\\n\\nTo find the latest articles on Arxiv, one would typically follow these steps:\\n\\n1. Visit the Arxiv website (https://arxiv.org/).\\n2. Use the search functionality to find papers related to your topic of interest.\\n   - You can use keywords such as \"reliability in AI systems,\" \"safety mechanisms in AI,\" \"Large Language Models safety,\" etc.\\n3. Filter the results by selecting the \"Sort by Submission Date\" to get the most recent submissions.\\n4. Review the abstracts of papers that seem relevant to your topic.\\n5. Download the full papers for a detailed understanding of the proposed models and approaches.\\n\\nSince I\\'m unable to perform a live search for you, I can still provide general guidance on the types of keywords and search strings you might want to use in your search:\\n\\nSearch Query Examples:\\n- \"reliability of Large Language Models\"\\n- \"safety in AI systems\"\\n- \"robustness in neural networks\"\\n- \"error detection in Large Language Models\"\\n- \"safety mechanisms for AI\"\\n\\nTheoretical and empirical works in this area may focus on a range of topics, including but not limited to the following:\\n- Methods for evaluating and measuring the reliability of LLMs.\\n- Techniques for improving the robustness of LLMs against adversarial attacks.\\n- Investigation into the ethical considerations and safety implications of deploying LLMs in various domains.\\n- Reducing bias and ensuring fairness in the outputs of LLMs.\\n- Best practices for designing and deploying safety mechanisms in AI.\\n\\nIf you wish to conduct such a search, you would need to manually follow these steps. If you are interested in broad trends or general information about reliability and safety in LLMs, I can provide you with a summary based on existing knowledge up to my current cutoff date.\\n\\n>> FINAL ANSWER:\\nUnfortunately, I cannot provide real-time search results from Arxiv or execute code, but I have provided guidance on how you might conduct such a search for the latest research articles manually. If you\\'re seeking specific articles, you would need to follow the steps outlined above.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_meta_prompting(**{\n",
    "  \"task\": \"Please provide me with the latest research or review articles related to the modeling of reliability and safety mechanisms in AI systems, with a focus on Large Language Models.\",\n",
    "  \"expert_name\": \"Expert Researcher\",\n",
    "  \"expert_identity\": \"You are an expert researcher with access to the latest academic databases and the ability to provide summaries of the most recent articles from Arxiv. Your expertise is in parsing through large volumes of academic literature to identify relevant papers, especially those pertaining to the fields of artificial intelligence, machine learning, and their applications. You are up-to-date with current trends and advancements in AI, and you can quickly discern which articles will be most useful for constructing a comprehensive blog post on a given topic.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": config_list,  # config_list should be defined or imported\n",
    "    \"timeout\": 120,\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "import autogen.runtime_logging\n",
    "\n",
    "\n",
    "PROBLEM = \"Write a comperhansive blog post about the modelling of reliability and safety mechanisms in AI system. You should get update knowledge from Arxiv before start writing. The focus should be on Large Language Models.\"\n",
    "\n",
    "proxy = autogen.UserProxyAgent(\n",
    "    name=\"proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    max_consecutive_auto_reply=1,\n",
    "    default_auto_reply=\"Continue. If you think the task is solved, please reply me only with 'TERMINATE'.\",\n",
    ")\n",
    "\n",
    "\n",
    "agent = MetaAgent(\n",
    "    name=\"Meta-Expert\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=15,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.llm_config['tools']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'description': 'Solve a task by querying an expert. Provide the expert identity and the task that needs to be solved, and the function will return the response of the expert.',\n",
       "   'name': 'run_meta_prompting',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'expert_name': {'type': 'string',\n",
       "      'description': 'Name of the expert. Should follow the format: Expert xxx.'},\n",
       "     'expert_identity': {'type': 'string',\n",
       "      'description': 'A high-quality description about the most capable and suitable expert to answer the instruction. In second person perspective. For example, You are a linguist, well-versed in the study of language and its structures. You are equipped with a good understanding of grammar rules and can differentiate between nouns, verbs, adjectives, adverbs, etc. You can quickly and accurately identify the parts of speech in a sentence and explain the role of each word in the sentence. Your expertise in language and grammar is highly valuable in analyzing and understanding the nuances of communication.'},\n",
       "     'task': {'type': 'string',\n",
       "      'description': 'The task that needs to be solved by the expert.'}},\n",
       "    'required': ['expert_name', 'expert_identity', 'task']}}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autogen.agentchat.register_function(\n",
    "    run_meta_prompting,\n",
    "    caller=agent,\n",
    "    executor=proxy,\n",
    "    description=\"Solve a task by querying an expert. Provide the expert identity and the task that needs to be solved, and the function will return the response of the expert.\",\n",
    "    )\n",
    "\n",
    "agent.llm_config['tools']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_meta_prompting': <function __main__.run_meta_prompting(expert_name: typing.Annotated[str, 'Name of the expert. Should follow the format: Expert xxx.'], expert_identity: typing.Annotated[str, 'A high-quality description about the most capable and suitable expert to answer the instruction. In second person perspective. For example, You are a linguist, well-versed in the study of language and its structures. You are equipped with a good understanding of grammar rules and can differentiate between nouns, verbs, adjectives, adverbs, etc. You can quickly and accurately identify the parts of speech in a sentence and explain the role of each word in the sentence. Your expertise in language and grammar is highly valuable in analyzing and understanding the nuances of communication.'], task: typing.Annotated[str, 'The task that needs to be solved by the expert.']) -> str>,\n",
       " 'meta_prompting': <function __main__.<lambda>(**args)>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy.register_function(function_map={\"meta_prompting\": lambda **args: run_meta_prompting(**args)})\n",
    "proxy.function_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mproxy\u001b[0m (to Meta-Expert):\n",
      "\n",
      "Write a comperhansive blog post about the modelling of reliability and safety mechanisms in AI system. You should get update knowledge from Arxiv before start writing. The focus should be on Large Language Models.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMeta-Expert\u001b[0m (to proxy):\n",
      "\n",
      "\u001b[32m***** Suggested tool Call (call_mPBAmHzWNGuOfJLGffi0hy1Z): run_meta_prompting *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"expert_name\": \"Expert Researcher\",\n",
      "  \"expert_identity\": \"You are a researcher with up-to-date knowledge and access to scientific articles, particularly from repositories such as Arxiv. You possess the skill to quickly scan and summarize recent literature, especially related to reliability and safety mechanisms in AI systems.\",\n",
      "  \"task\": \"Please provide a summary of the most recent advancements or discussions from Arxiv on the topic of reliability and safety mechanisms in AI systems, focusing specifically on Large Language Models.\"\n",
      "}\n",
      "\u001b[32m***********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION run_meta_prompting...\u001b[0m\n",
      "Running meta prompting...\n",
      "Querying expert:  Expert Researcher\n",
      "\u001b[33mproxy\u001b[0m (to Meta-Expert):\n",
      "\n",
      "\u001b[33mproxy\u001b[0m (to Meta-Expert):\n",
      "\n",
      "\u001b[32m***** Response from calling tool \"call_mPBAmHzWNGuOfJLGffi0hy1Z\" *****\u001b[0m\n",
      "Error: unsupported operand type(s) for +=: 'NoneType' and 'str'\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMeta-Expert\u001b[0m (to proxy):\n",
      "\n",
      "\u001b[32m***** Suggested tool Call (call_jqOVjhQArAOMegtwbLjy79m5): run_meta_prompting *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"expert_name\": \"Expert Researcher\",\n",
      "  \"expert_identity\": \"You are a researcher with expertise in the field of artificial intelligence. You are up-to-date with the latest research and have access to archives such as Arxiv for scientific papers. You have the ability to quickly scan and provide summaries of recent advancements in AI, focusing on the safety and reliability of systems, particularly Large Language Models.\",\n",
      "  \"task\": \"Please search for and summarize the most recent advancements or discussions on Arxiv regarding the modeling of reliability and safety mechanisms in AI systems, with a focus on Large Language Models.\"\n",
      "}\n",
      "\u001b[32m***********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/autogen/autogen/autogen/agentchat/conversable_agent.py:1121: UserWarning: Cannot extract summary using last_msg: 'NoneType' object has no attribute 'replace'. Using an empty str as summary.\n",
      "  warnings.warn(f\"Cannot extract summary using last_msg: {e}. Using an empty str as summary.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Write a comperhansive blog post about the modelling of reliability and safety mechanisms in AI system. You should get update knowledge from Arxiv before start writing. The focus should be on Large Language Models.', 'role': 'assistant'}, {'tool_calls': [{'id': 'call_mPBAmHzWNGuOfJLGffi0hy1Z', 'function': {'arguments': '{\\n  \"expert_name\": \"Expert Researcher\",\\n  \"expert_identity\": \"You are a researcher with up-to-date knowledge and access to scientific articles, particularly from repositories such as Arxiv. You possess the skill to quickly scan and summarize recent literature, especially related to reliability and safety mechanisms in AI systems.\",\\n  \"task\": \"Please provide a summary of the most recent advancements or discussions from Arxiv on the topic of reliability and safety mechanisms in AI systems, focusing specifically on Large Language Models.\"\\n}', 'name': 'run_meta_prompting'}, 'type': 'function'}], 'content': None, 'role': 'assistant'}, {'content': \"Error: unsupported operand type(s) for +=: 'NoneType' and 'str'\", 'tool_responses': [{'tool_call_id': 'call_mPBAmHzWNGuOfJLGffi0hy1Z', 'role': 'tool', 'content': \"Error: unsupported operand type(s) for +=: 'NoneType' and 'str'\"}], 'role': 'tool'}, {'tool_calls': [{'id': 'call_jqOVjhQArAOMegtwbLjy79m5', 'function': {'arguments': '{\\n  \"expert_name\": \"Expert Researcher\",\\n  \"expert_identity\": \"You are a researcher with expertise in the field of artificial intelligence. You are up-to-date with the latest research and have access to archives such as Arxiv for scientific papers. You have the ability to quickly scan and provide summaries of recent advancements in AI, focusing on the safety and reliability of systems, particularly Large Language Models.\",\\n  \"task\": \"Please search for and summarize the most recent advancements or discussions on Arxiv regarding the modeling of reliability and safety mechanisms in AI systems, with a focus on Large Language Models.\"\\n}', 'name': 'run_meta_prompting'}, 'type': 'function'}], 'content': None, 'role': 'assistant'}], summary='', cost=({'total_cost': 0.10200000000000001, 'gpt-4': {'cost': 0.10200000000000001, 'prompt_tokens': 2416, 'completion_tokens': 492, 'total_tokens': 2908}}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start logging\n",
    "# logging_session_id = autogen.runtime_logging.start(config={\"dbname\": \"logs.db\"})\n",
    "# print(\"Logging session ID: \" + str(logging_session_id))\n",
    "\n",
    "proxy.initiate_chat(agent, message=PROBLEM)\n",
    "\n",
    "# End logging\n",
    "# autogen.runtime_logging.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
