{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM models:  ['gpt-4', 'gpt-4-32k', 'gpt-4-0613', 'gpt-35-turbo', 'gpt-35-turbo-16k']\n",
      "Summarizer LLM models:  ['gpt-4-32k', 'gpt-35-turbo-16k']\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Dict, List, Optional, Union, Callable\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from autogen.agentchat.contrib.web_surfer import WebSurferAgent \n",
    "from autogen.agentchat.contrib.agent_builder import AgentBuilder\n",
    "from autogen.formatting_utils import colored\n",
    "from typing_extensions import Annotated\n",
    "import autogen\n",
    "\n",
    "\n",
    "from teachability import Teachability\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import arxiv\n",
    "\n",
    "import requests\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "version = \"0.0.1\"\n",
    "ProjectID = \"FinNews\"\n",
    "initiate_db = True\n",
    "config_file = \"OAI_CONFIG_LIST\"\n",
    "agents_json = \"./news-0.0.1.json\"\n",
    "\n",
    "\n",
    "Project_dir = Path(f\"./{ProjectID}/{version}\")\n",
    "\n",
    "if not os.path.exists(Project_dir): initiate_db = True\n",
    "\n",
    "output_dir = f'{Project_dir}/pdf_output'\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "\n",
    "db_dir = f'{Project_dir}/memo-db/'\n",
    "# check if db_dir exists, delete it if it does\n",
    "if initiate_db:\n",
    "\n",
    "    if not os.path.exists(Project_dir): \n",
    "        shutil.rmtree(Project_dir)\n",
    "        os.makedirs(Project_dir)\n",
    "    if os.path.exists(db_dir): shutil.rmtree(db_dir)\n",
    "\n",
    "    # create a list of papers that have been read and saved it in a pickle file\n",
    "    read_papers = []\n",
    "    with open(f'{Project_dir}/read_papers.pkl', 'wb') as f:\n",
    "        pickle.dump(read_papers, f)\n",
    "\n",
    "    # create a list of abstract that have been read and saved it in a pickle file\n",
    "    read_abstracts = []\n",
    "    with open(f'{Project_dir}/read_abstracts.pkl', 'wb') as f:\n",
    "        pickle.dump(read_abstracts, f)\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    config_file,\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-32k\", \"gpt-4\", \"gpt4\", \"gpt-35-turbo-16k\", \"gpt-4-0613\", \"gpt-3.5-turbo\", \"gpt-35-turbo\", \"gpt-35-turbo-0613\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"LLM models: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n",
    "\n",
    "# Configuration for the Language Model (LLM)\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,  # config_list should be defined or imported\n",
    "    \"timeout\": 120,\n",
    "    # \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Configuration for the manager using the same config_list as llm_config\n",
    "manager_config = {\n",
    "    \"config_list\": config_list,  # config_list should be defined or imported\n",
    "    \"timeout\": 60,\n",
    "    # \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Termination message definition\n",
    "termination_msg = (\n",
    "    lambda x: isinstance(x, dict)\n",
    "    and str(x.get(\"content\", \"\")).upper() == \"TERMINATE\"\n",
    ")\n",
    "\n",
    "######################\n",
    "bing_api_key = \"bc0eaf95b2034706812cbc2ba03c1a99\"\n",
    "\n",
    "summarizer_llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 44,  # change the seed for different trials\n",
    "    \"config_list\": autogen.config_list_from_json(\n",
    "        config_file,\n",
    "        filter_dict={\"model\": [\"gpt-4-32k\", \"gpt-35-turbo-16k\"]},\n",
    "    ),\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "print(\"Summarizer LLM models: \", [summarizer_llm_config[\"config_list\"][i][\"model\"] for i in range(len(summarizer_llm_config[\"config_list\"]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_teachable_groupchat(assitant_name, user_name, db_dir, config_list, verbosity=0):\n",
    "    \n",
    "    # Start by instantiating any agent that inherits from ConversableAgent.\n",
    "    assistant = autogen.ConversableAgent(\n",
    "        name=assitant_name,  # The name is flexible, but should not contain spaces to work in group chat.\n",
    "        llm_config={\"config_list\": config_list, \"timeout\": 120, \"cache_seed\": None},  # Disable caching.\n",
    "    )\n",
    "\n",
    "    # Instantiate the Teachability capability. Its parameters are all optional.\n",
    "    teachability = Teachability(\n",
    "        verbosity=verbosity,  # 0 for basic info, 1 to add memory operations, 2 for analyzer messages, 3 for memo lists.\n",
    "        reset_db=False,  \n",
    "        path_to_db_dir=db_dir,\n",
    "        recall_threshold=1.5,  # Higher numbers allow more (but less relevant) memos to be recalled.\n",
    "    )\n",
    "\n",
    "    # Now add the Teachability capability to the agent.\n",
    "    teachability.add_to_agent(assistant)\n",
    "\n",
    "    user = autogen.UserProxyAgent(\n",
    "        name=user_name,\n",
    "        human_input_mode=\"NEVER\",\n",
    "        is_termination_msg=termination_msg,\n",
    "        max_consecutive_auto_reply=0,\n",
    "        code_execution_config={\"use_docker\": False},\n",
    "    )\n",
    "\n",
    "    return assistant, user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"\n",
    "As a seasoned financial analysis writer, your expertise is called upon to compose an insightful weekly blog post that delves into the pivotal financial happenings from the preceding week. \n",
    "By web surfing, you MUST get the most up-to-date news. \n",
    "Your readers rely on your analytical prowess to unpack complex financial events and trends. \n",
    "Address the following crucial inquiries in your upcoming blog post to provide them with the clarity they seek:\n",
    "\n",
    "Insights from recent central bank officials' statements, particularly from the Federal Reserve (Fed) and the European Central Bank (ECB).\n",
    "Emerging trends in global monetary policy.\n",
    "Key outcomes and implications from the latest Federal Reserve meeting.\n",
    "Notable monetary policy meetings that occurred last week, with a focus on actions by the ECB, Fed, Bank of England (BoE), and Bank of Japan (BoJ).\n",
    "A review of the latest inflation data from the Euro Area, the United Kingdom, Japan, and the United States.\n",
    "Analysis of recent labor market reports from the USA and the Euro Area, including an examination of wage negotiations in Germany, France, Spain, and Italy.\n",
    "Factors influencing the EUR/USD exchange rate fluctuations over the past week, including inflation data, fiscal budgets, and trade-related tariffs.\n",
    "Developments in the pricing of inflation swaps in both the Eurozone and the United States.\n",
    "Your discerning analysis is not just expected, but essential for readers who depend on your weekly posts to make informed financial decisions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function\n",
    "### bing search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memorize_web_search(search_results, query):\n",
    "\n",
    "    # Create a TeachableAgent and UserProxyAgent to represent the researcher and the user, respectively.\n",
    "    learner, learner_user = create_teachable_groupchat(\"learner\", \"learner_user\", db_dir, config_list, verbosity=0)\n",
    "\n",
    "    learner_user.initiate_chat(learner,\n",
    "                       silent=True,\n",
    "                       message=f\"The following is the results of bing search for:'{query}': \\n\\n '{search_results}'\")\n",
    "    \n",
    "\n",
    "def bing_search(query: str) -> str:\n",
    "    # create websurfer agent\n",
    "    web_surfer = WebSurferAgent(\n",
    "        \"web_surfer\",\n",
    "        llm_config=llm_config,\n",
    "        summarizer_llm_config=summarizer_llm_config,\n",
    "        browser_config={\"viewport_size\": 4096, \"bing_api_key\": bing_api_key},\n",
    "    )\n",
    "\n",
    "    user_proxy = autogen.UserProxyAgent(\n",
    "        \"user_proxy\",\n",
    "        human_input_mode=\"NEVER\",\n",
    "        code_execution_config=False,\n",
    "        default_auto_reply=\"\",\n",
    "        is_termination_msg=lambda x: True,\n",
    "        )\n",
    "    \n",
    "    res = user_proxy.initiate_chat(web_surfer, message=query)\n",
    "\n",
    "    memorize_web_search(res, query)\n",
    "\n",
    "def web_search(queries: Annotated[List[str], \"liest of queries to search\"]) -> str:\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(bing_search, query) for query in queries]\n",
    "        for future in as_completed(futures):\n",
    "            future.result() \n",
    "\n",
    "    # [bing_search(query) for query in queries]\n",
    "\n",
    "    return f\"The search results have been memorized. go ahead and accomplish your task: \\n\\n {task} \\n\\n if you need any help, let me know\"\n",
    "\n",
    "# web_search([\"what is the best way to invest in stock market\",\n",
    "#             \"how to invest in stock market\",\n",
    "#             ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from ./news-0.0.1.json\n",
      "==> Creating agents...\n",
      "Creating agent financial_news_research_analyst with backbone gpt-4...\n",
      "Creating agent central_banks_insights_specialist with backbone gpt-4...\n",
      "Creating agent global_monetary_policy_analyst with backbone gpt-4...\n",
      "Creating agent financial_data_analyst with backbone gpt-4...\n",
      "Creating agent python_financial_news_aggregator_developer with backbone gpt-4...\n",
      "Adding user console proxy...\n"
     ]
    }
   ],
   "source": [
    "new_builder = AgentBuilder(config_file_or_env=config_file)\n",
    "agent_list, agent_configs = new_builder.load(agents_json)\n",
    "\n",
    "agents_dict = {}\n",
    "for agent in agent_list:\n",
    "    agents_dict[agent.name] = agent\n",
    "\n",
    "\n",
    "\n",
    "# add teachablitity to \"financial_news_research_analyst\"\n",
    "\n",
    "teachability = Teachability(\n",
    "        verbosity=0,  # 0 for basic info, 1 to add memory operations, 2 for analyzer messages, 3 for memo lists.\n",
    "        reset_db=False,  \n",
    "        path_to_db_dir=db_dir,\n",
    "        recall_threshold=1.5,  # Higher numbers allow more (but less relevant) memos to be recalled.\n",
    "    )\n",
    "\n",
    "teachability.add_to_agent(agents_dict[\"financial_news_research_analyst\"])\n",
    "\n",
    "# add web_search function to \"financial_news_research_analyst\"\n",
    "\n",
    "for func, func_name, description in zip([web_search],\n",
    "                                        [\"web_search\", ],\n",
    "                                        [\"Search the web for a list of queries.\"] ):\n",
    "    \n",
    "    for caller, executor in zip([agents_dict[\"financial_news_research_analyst\"]],\n",
    "                                [agents_dict[\"User_console_and_code_interpreter\"]]):\n",
    "        autogen.agentchat.register_function(\n",
    "                func,\n",
    "                caller=caller,\n",
    "                executor=executor,\n",
    "                name=func_name,\n",
    "                description=description\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_task(execution_task: str, agents: Dict[str, Union[str, List[str]]]):\n",
    "    agent_list = list(agents.values())\n",
    "    group_chat = autogen.GroupChat(agents=agent_list, \n",
    "                                   messages=[], \n",
    "                                   max_round=50) # type: ignore\n",
    "    manager = autogen.GroupChatManager(groupchat=group_chat, llm_config={\"config_list\": config_list, **llm_config})\n",
    "    agent_list[0].initiate_chat(manager,  # type: ignore\n",
    "                                message=execution_task,\n",
    "                                summary_method=\"reflection_with_llm\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_console_and_code_interpreter\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "As a seasoned financial analysis writer, your expertise is called upon to compose an insightful weekly blog post that delves into the pivotal financial happenings from the preceding week. \n",
      "By web surfing, you MUST get the most up-to-date news. \n",
      "Your readers rely on your analytical prowess to unpack complex financial events and trends. \n",
      "Address the following crucial inquiries in your upcoming blog post to provide them with the clarity they seek:\n",
      "\n",
      "Insights from recent central bank officials' statements, particularly from the Federal Reserve (Fed) and the European Central Bank (ECB).\n",
      "Emerging trends in global monetary policy.\n",
      "Key outcomes and implications from the latest Federal Reserve meeting.\n",
      "Notable monetary policy meetings that occurred last week, with a focus on actions by the ECB, Fed, Bank of England (BoE), and Bank of Japan (BoJ).\n",
      "A review of the latest inflation data from the Euro Area, the United Kingdom, Japan, and the United States.\n",
      "Analysis of recent labor market reports from the USA and the Euro Area, including an examination of wage negotiations in Germany, France, Spain, and Italy.\n",
      "Factors influencing the EUR/USD exchange rate fluctuations over the past week, including inflation data, fiscal budgets, and trade-related tariffs.\n",
      "Developments in the pricing of inflation swaps in both the Eurozone and the United States.\n",
      "Your discerning analysis is not just expected, but essential for readers who depend on your weekly posts to make informed financial decisions.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Number of requested results 0, cannot be negative, or zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# By employing the 'get_news' function with precise queries, you can access the most up-to-date news.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstart_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m, in \u001b[0;36mstart_task\u001b[0;34m(execution_task, agents)\u001b[0m\n\u001b[1;32m      3\u001b[0m group_chat \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mGroupChat(agents\u001b[38;5;241m=\u001b[39magent_list, \n\u001b[1;32m      4\u001b[0m                                messages\u001b[38;5;241m=\u001b[39m[], \n\u001b[1;32m      5\u001b[0m                                max_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m      6\u001b[0m manager \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mGroupChatManager(groupchat\u001b[38;5;241m=\u001b[39mgroup_chat, llm_config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: config_list, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mllm_config})\n\u001b[0;32m----> 7\u001b[0m \u001b[43magent_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreflection_with_llm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/autogen/autogen/agentchat/conversable_agent.py:985\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **context)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    984\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcontext)\n\u001b[0;32m--> 985\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[1;32m    987\u001b[0m     summary_method,\n\u001b[1;32m    988\u001b[0m     summary_args,\n\u001b[1;32m    989\u001b[0m     recipient,\n\u001b[1;32m    990\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m    991\u001b[0m )\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[0;32m~/autogen/autogen/agentchat/conversable_agent.py:627\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    625\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 627\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m~/autogen/autogen/agentchat/conversable_agent.py:786\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/autogen/autogen/agentchat/conversable_agent.py:1874\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   1872\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 1874\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1875\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[1;32m   1876\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/autogen/autogen/agentchat/groupchat.py:616\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    614\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m groupchat\u001b[38;5;241m.\u001b[39mselect_speaker(speaker, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# let the speaker speak\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;66;03m# let the admin agent speak if interrupted\u001b[39;00m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m groupchat\u001b[38;5;241m.\u001b[39madmin_name \u001b[38;5;129;01min\u001b[39;00m groupchat\u001b[38;5;241m.\u001b[39magent_names:\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;66;03m# admin agent is one of the participants\u001b[39;00m\n",
      "File \u001b[0;32m~/autogen/autogen/agentchat/conversable_agent.py:1861\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# Call the hookable method that gives registered hooks a chance to process the last message.\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# Message modifications do not affect the incoming messages or self._oai_messages.\u001b[39;00m\n\u001b[0;32m-> 1861\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_last_received_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[38;5;66;03m# Call the hookable method that gives registered hooks a chance to process all messages.\u001b[39;00m\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;66;03m# Message modifications do not affect the incoming messages or self._oai_messages.\u001b[39;00m\n\u001b[1;32m   1865\u001b[0m messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_all_messages_before_reply(messages)\n",
      "File \u001b[0;32m~/autogen/autogen/agentchat/conversable_agent.py:2616\u001b[0m, in \u001b[0;36mConversableAgent.process_last_received_message\u001b[0;34m(self, messages)\u001b[0m\n\u001b[1;32m   2614\u001b[0m processed_user_content \u001b[38;5;241m=\u001b[39m user_content\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hook_list:\n\u001b[0;32m-> 2616\u001b[0m     processed_user_content \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_user_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processed_user_content \u001b[38;5;241m==\u001b[39m user_content:\n\u001b[1;32m   2618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m messages  \u001b[38;5;66;03m# No hooks actually modified the user's message.\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/autogen/usecases/nb/arxiv_user_proxy/rag_teachablitity/teachability.py:96\u001b[0m, in \u001b[0;36mTeachability.process_last_received_message\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     94\u001b[0m expanded_text \u001b[38;5;241m=\u001b[39m text\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemo_store\u001b[38;5;241m.\u001b[39mget_last_memo_id() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 96\u001b[0m     expanded_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consider_memo_retrieval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mexpanded_text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpanded_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmagenta\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/workspaces/autogen/usecases/nb/arxiv_user_proxy/rag_teachablitity/teachability.py:170\u001b[0m, in \u001b[0;36mTeachability._consider_memo_retrieval\u001b[0;34m(self, comment)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLOOK FOR RELEVANT MEMOS, AS QUESTION-ANSWER PAIRS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlight_yellow\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 170\u001b[0m memo_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve_relevant_memos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Next, if the comment involves a task, then extract and generalize the task before using it as the lookup key.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_analyze(\n\u001b[1;32m    174\u001b[0m     comment,\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoes any part of the TEXT ask the agent to perform a task or solve a problem? Answer with just one word, yes or no.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/autogen/usecases/nb/arxiv_user_proxy/rag_teachablitity/teachability.py:202\u001b[0m, in \u001b[0;36mTeachability._retrieve_relevant_memos\u001b[0;34m(self, input_text)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retrieve_relevant_memos\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_text):\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns semantically related memos from the DB.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     memo_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemo_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_related_memos\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_num_retrievals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecall_threshold\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(memo_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTHE CLOSEST MEMO IS BEYOND THE THRESHOLD:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlight_yellow\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/workspaces/autogen/usecases/nb/arxiv_user_proxy/rag_teachablitity/teachability.py:358\u001b[0m, in \u001b[0;36mMemoStore.get_related_memos\u001b[0;34m(self, query_text, n_results, threshold)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves memos that are related to the given query text within the specified distance threshold.\"\"\"\u001b[39;00m\n\u001b[1;32m    357\u001b[0m n_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_results, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muid_text_dict))\n\u001b[0;32m--> 358\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvec_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m memos \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    360\u001b[0m num_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/chromadb/api/models/Collection.py:322\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    318\u001b[0m valid_query_uris \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    319\u001b[0m     maybe_cast_one_to_many_uri(query_uris) \u001b[38;5;28;01mif\u001b[39;00m query_uris \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    321\u001b[0m valid_include \u001b[38;5;241m=\u001b[39m validate_include(include, allow_distances\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 322\u001b[0m valid_n_results \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_n_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# If query_embeddings are not provided, we need to compute them from the inputs\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_query_embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/chromadb/api/types.py:465\u001b[0m, in \u001b[0;36mvalidate_n_results\u001b[0;34m(n_results)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected requested number of results to be a int, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    463\u001b[0m     )\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_results \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of requested results \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, cannot be negative, or zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m     )\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_results\n",
      "\u001b[0;31mTypeError\u001b[0m: Number of requested results 0, cannot be negative, or zero."
     ]
    }
   ],
   "source": [
    "# By employing the 'get_news' function with precise queries, you can access the most up-to-date news.\n",
    "\n",
    "start_task(task, agents_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
