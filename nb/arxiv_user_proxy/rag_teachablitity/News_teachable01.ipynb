{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM models:  ['gpt-4', 'gpt-4-32k', 'gpt-35-turbo', 'gpt-35-turbo-16k']\n",
      "Summarizer LLM models:  ['gpt-4-32k', 'gpt-35-turbo-16k']\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Dict, List, Optional, Union, Callable\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from autogen.agentchat.contrib.web_surfer import WebSurferAgent \n",
    "from autogen.agentchat.contrib.agent_builder import AgentBuilder\n",
    "from autogen.formatting_utils import colored\n",
    "from typing_extensions import Annotated\n",
    "import autogen\n",
    "\n",
    "from teachability import Teachability\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import arxiv\n",
    "\n",
    "import requests\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "version = \"0.0.1\"\n",
    "ProjectID = \"FinNews\"\n",
    "initiate_db = False\n",
    "config_file = \"OAI_CONFIG_LIST-sweden-505\"\n",
    "agents_json = \"./news-0.0.1.json\"\n",
    "\n",
    "\n",
    "Project_dir = Path(f\"./{ProjectID}/{version}\")\n",
    "\n",
    "if not os.path.exists(Project_dir): initiate_db = True\n",
    "\n",
    "output_dir = f'{Project_dir}/pdf_output'\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "\n",
    "db_dir = f'{Project_dir}/memo-db/'\n",
    "# check if db_dir exists, delete it if it does\n",
    "if initiate_db:\n",
    "\n",
    "    if not os.path.exists(Project_dir): \n",
    "        shutil.rmtree(Project_dir)\n",
    "        os.makedirs(Project_dir)\n",
    "    if os.path.exists(db_dir): shutil.rmtree(db_dir)\n",
    "\n",
    "    # create a list of papers that have been read and saved it in a pickle file\n",
    "    read_papers = []\n",
    "    with open(f'{Project_dir}/read_papers.pkl', 'wb') as f:\n",
    "        pickle.dump(read_papers, f)\n",
    "\n",
    "    # create a list of abstract that have been read and saved it in a pickle file\n",
    "    read_abstracts = []\n",
    "    with open(f'{Project_dir}/read_abstracts.pkl', 'wb') as f:\n",
    "        pickle.dump(read_abstracts, f)\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    config_file,\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-32k\", \"gpt-4\", \"gpt4\", \"gpt-35-turbo-16k\", \"gpt-4-0613\", \"gpt-3.5-turbo\", \"gpt-35-turbo\", \"gpt-35-turbo-0613\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"LLM models: \", [config_list[i][\"model\"] for i in range(len(config_list))])\n",
    "\n",
    "# Configuration for the Language Model (LLM)\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,  # config_list should be defined or imported\n",
    "    \"timeout\": 120,\n",
    "    # \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Configuration for the manager using the same config_list as llm_config\n",
    "manager_config = {\n",
    "    \"config_list\": config_list,  # config_list should be defined or imported\n",
    "    \"timeout\": 60,\n",
    "    # \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Termination message definition\n",
    "termination_msg = (\n",
    "    lambda x: isinstance(x, dict)\n",
    "    and str(x.get(\"content\", \"\")).upper() == \"TERMINATE\"\n",
    ")\n",
    "\n",
    "######################\n",
    "bing_api_key = \"bc0eaf95b2034706812cbc2ba03c1a99\"\n",
    "\n",
    "summarizer_llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 44,  # change the seed for different trials\n",
    "    \"config_list\": autogen.config_list_from_json(\n",
    "        config_file,\n",
    "        filter_dict={\"model\": [\"gpt-4-32k\", \"gpt-35-turbo-16k\"]},\n",
    "    ),\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "print(\"Summarizer LLM models: \", [summarizer_llm_config[\"config_list\"][i][\"model\"] for i in range(len(summarizer_llm_config[\"config_list\"]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from ./news-0.0.1.json\n",
      "==> Creating agents...\n",
      "Creating agent financial_news_research_analyst with backbone gpt-4...\n",
      "Creating agent central_banks_insights_specialist with backbone gpt-4...\n",
      "Creating agent global_monetary_policy_analyst with backbone gpt-4...\n",
      "Creating agent financial_data_analyst with backbone gpt-4...\n",
      "Creating agent python_financial_news_aggregator_developer with backbone gpt-4...\n",
      "Adding user console proxy...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'verbosity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m web_surfer \u001b[38;5;241m=\u001b[39m WebSurferAgent(\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_surfer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39mllm_config,\n\u001b[1;32m     12\u001b[0m     summarizer_llm_config\u001b[38;5;241m=\u001b[39msummarizer_llm_config,\n\u001b[1;32m     13\u001b[0m     browser_config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviewport_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4096\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbing_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: bing_api_key},\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# add teachablitity to \"financial_news_research_analyst\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m teachability \u001b[38;5;241m=\u001b[39m Teachability(\n\u001b[0;32m---> 19\u001b[0m         verbosity\u001b[38;5;241m=\u001b[39m\u001b[43mverbosity\u001b[49m,  \u001b[38;5;66;03m# 0 for basic info, 1 to add memory operations, 2 for analyzer messages, 3 for memo lists.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         reset_db\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \n\u001b[1;32m     21\u001b[0m         path_to_db_dir\u001b[38;5;241m=\u001b[39mdb_dir,\n\u001b[1;32m     22\u001b[0m         recall_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m,  \u001b[38;5;66;03m# Higher numbers allow more (but less relevant) memos to be recalled.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     25\u001b[0m agents_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinancial_news_research_analyst\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mteachability \u001b[38;5;241m=\u001b[39m teachability\n\u001b[1;32m     27\u001b[0m agents_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_surfer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m web_surfer\n",
      "\u001b[0;31mNameError\u001b[0m: name 'verbosity' is not defined"
     ]
    }
   ],
   "source": [
    "new_builder = AgentBuilder(config_file_or_env=config_file)\n",
    "agent_list, agent_configs = new_builder.load(agents_json)\n",
    "\n",
    "agents_dict = {}\n",
    "for agent in agent_list:\n",
    "    agents_dict[agent.name] = agent\n",
    "\n",
    "# create websurfer agent\n",
    "web_surfer = WebSurferAgent(\n",
    "    \"web_surfer\",\n",
    "    llm_config=llm_config,\n",
    "    summarizer_llm_config=summarizer_llm_config,\n",
    "    browser_config={\"viewport_size\": 4096, \"bing_api_key\": bing_api_key},\n",
    ")\n",
    "\n",
    "# add teachablitity to \"financial_news_research_analyst\"\n",
    "\n",
    "teachability = Teachability(\n",
    "        verbosity=verbosity,  # 0 for basic info, 1 to add memory operations, 2 for analyzer messages, 3 for memo lists.\n",
    "        reset_db=False,  \n",
    "        path_to_db_dir=db_dir,\n",
    "        recall_threshold=1.5,  # Higher numbers allow more (but less relevant) memos to be recalled.\n",
    "    )\n",
    "\n",
    "agents_dict[\"financial_news_research_analyst\"].teachability = teachability\n",
    "\n",
    "agents_dict[\"web_surfer\"] = web_surfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_task(execution_task: str, agents: Dict[str, Union[str, List[str]]]):\n",
    "    group_chat = autogen.GroupChat(agents=list(agents.values()), messages=[], max_round=12)\n",
    "    manager = autogen.GroupChatManager(groupchat=group_chat, llm_config={\"config_list\": config_list, **llm_config})\n",
    "    agent_list[0].initiate_chat(manager, message=execution_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_console_and_code_interpreter\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "As a seasoned financial analysis writer, your expertise is called upon to compose an insightful weekly blog post that delves into the pivotal financial happenings from the preceding week. \n",
      "By web surfing, you MUST get the most up-to-date news. \n",
      "Your readers rely on your analytical prowess to unpack complex financial events and trends. \n",
      "Address the following crucial inquiries in your upcoming blog post to provide them with the clarity they seek:\n",
      "\n",
      "Insights from recent central bank officials' statements, particularly from the Federal Reserve (Fed) and the European Central Bank (ECB).\n",
      "Emerging trends in global monetary policy.\n",
      "Key outcomes and implications from the latest Federal Reserve meeting.\n",
      "Notable monetary policy meetings that occurred last week, with a focus on actions by the ECB, Fed, Bank of England (BoE), and Bank of Japan (BoJ).\n",
      "A review of the latest inflation data from the Euro Area, the United Kingdom, Japan, and the United States.\n",
      "Analysis of recent labor market reports from the USA and the Euro Area, including an examination of wage negotiations in Germany, France, Spain, and Italy.\n",
      "Factors influencing the EUR/USD exchange rate fluctuations over the past week, including inflation data, fiscal budgets, and trade-related tariffs.\n",
      "Developments in the pricing of inflation swaps in both the Eurozone and the United States.\n",
      "Your discerning analysis is not just expected, but essential for readers who depend on your weekly posts to make informed financial decisions.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# By employing the 'get_news' function with precise queries, you can access the most up-to-date news.\n",
    "\n",
    "task = \"\"\"\n",
    "As a seasoned financial analysis writer, your expertise is called upon to compose an insightful weekly blog post that delves into the pivotal financial happenings from the preceding week. \n",
    "By web surfing, you MUST get the most up-to-date news. \n",
    "Your readers rely on your analytical prowess to unpack complex financial events and trends. \n",
    "Address the following crucial inquiries in your upcoming blog post to provide them with the clarity they seek:\n",
    "\n",
    "Insights from recent central bank officials' statements, particularly from the Federal Reserve (Fed) and the European Central Bank (ECB).\n",
    "Emerging trends in global monetary policy.\n",
    "Key outcomes and implications from the latest Federal Reserve meeting.\n",
    "Notable monetary policy meetings that occurred last week, with a focus on actions by the ECB, Fed, Bank of England (BoE), and Bank of Japan (BoJ).\n",
    "A review of the latest inflation data from the Euro Area, the United Kingdom, Japan, and the United States.\n",
    "Analysis of recent labor market reports from the USA and the Euro Area, including an examination of wage negotiations in Germany, France, Spain, and Italy.\n",
    "Factors influencing the EUR/USD exchange rate fluctuations over the past week, including inflation data, fiscal budgets, and trade-related tariffs.\n",
    "Developments in the pricing of inflation swaps in both the Eurozone and the United States.\n",
    "Your discerning analysis is not just expected, but essential for readers who depend on your weekly posts to make informed financial decisions.\n",
    "\"\"\"\n",
    "\n",
    "start_task(task, agents_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
