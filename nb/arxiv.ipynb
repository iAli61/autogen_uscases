{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "\n",
    "paper = next(arxiv.Client().results(arxiv.Search(id_list=[\"2010.07683v1\"])))\n",
    "# Download the archive to the PWD with a default filename.\n",
    "paper.download_source()\n",
    "# Download the archive to the PWD with a custom filename.\n",
    "paper.download_source(filename=\"downloaded-paper.tar.gz\")\n",
    "# Download the archive to a specified directory with a custom filename.\n",
    "paper.download_source(dirpath=\"./mydir\", filename=\"downloaded-paper.tar.gz\")\n",
    "\n",
    "file = \"./mydir/downloaded-paper.tar.gz\"\n",
    "# unzipping the file\n",
    "import tarfile\n",
    "tar = tarfile.open(file)\n",
    "tar.extractall(\"./mydir\")\n",
    "tar.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import latex2markdown\n",
    "with open(\"./mydir/achemso-demo.tex\", \"r\") as f:\n",
    "    latex_string = f.read()\n",
    "\n",
    "l2m = latex2markdown.LaTeX2Markdown(latex_string)\n",
    "\n",
    "markdown_string = l2m.to_markdown()\n",
    "\n",
    "with open(\"./mydir/markdown_file.md\", \"w\") as f:\n",
    "    f.write(markdown_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the tex file to markdown\n",
    "import pypandoc\n",
    "output = pypandoc.convert_file(\"./mydir/achemso-demo.tex\", 'md', format='latex')\n",
    "\n",
    "with open(\"./mydir/achemso-demo-1.md\", \"w\") as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Introduction\\n\\nPolymers are one of the most important classes of material in modern\\nsociety, as its applications range from the plastic bags and bottles\\nused in daily life to a variety of electronics, and even structural\\ncomponents in the aerospace industry. A polymer is a material made of a\\ncollection of chains that are built by connecting many repeated units,\\ncalled monomers. These chains can form diverse structures that\\ncontribute to the highly diverse physical and chemical properties of\\ndifferent types of polymers. Some polymers can be consisting of more\\nthan one type of monomer to form even more complicated topological\\nstructures across different length scales. The research field of polymer\\nscience and engineering emerged to understand, control, and design novel\\npolymers that can be used to satisfy the rapidly growing demand on\\nhighly functional materials coming from different aspects of modern\\nlife. While polymers can be categorized into natural or synthetic\\npolymers, we will focus our discussion on the latter in this paper.\\n\\nFollowing the mainstream of materials science, polymer science has gone\\nthrough multiple major paradigm shifts. The early studies of polymers\\nflourished in the first half of the 20th century was closely associated\\nwith H. Staudinger who received the Nobel Prize in\\n1953[@polymer_history]. Initially, discovery of polymers was mainly\\nbased on an empirical approach, i.e., relying on many trial-and-error\\nexperiments. Accumulation of experimental experiences has led to\\ndevelopments of theoretical and simple statistical models for guiding\\nthe design of new polymers. These include many important work by the\\n1974 Nobel prize recipient P. J. Flory, the group contribution method\\nand so on[@Flory1969; @VKBook; @BiceranoBook]. Following the rapid\\nadvances of computing power in the last few decades, computational\\nmethods has become one of the main tools to study properties of\\npolymers[@polymer_MD]. Recent developments of simulation techniques for\\nvarious types of polymers opened up opportunities to computationally\\nstudy polymers across different length\\nscales[@MDReview2009; @Gartner:2019aa]. While generating experimental\\ndata of polymers is often costly and time-consuming, modern\\nsupercomputers provide new opportunities for building larger databases\\nof polymers computationally. With the drastic expansion of data size in\\nscience, a data-driven approach for scientific discovery is said to be\\nthe 4th paradigm of science. Polymer informatics is an interdisciplinary\\nresearch field of polymer science, computer science, information science\\nand machine learning that serves as a platform to mine the precious\\npolymer data for new knowledge. Yet, there has been notable challenges\\nof the development of polymer informatics attributed to the complex\\nhierarchical structures of polymers[@Audus:2017aa; @kumar_li_jun_2019].\\n\\nDesign of a polymer can be broken down into three parts corresponding to\\nthe three steps in the typical production process of polymers: design of\\nmonomers (polymerization), microstructures (crystallization), and\\nmaterial processing (manufacturing) (see Figure\\n[1](#fig:polymer_production){reference-type=\"ref\"\\nreference=\"fig:polymer_production\"}). Monomers, the building blocks of\\npolymers, contribute to the foundation of potential properties of the\\neventually produced polymers. While molecular size is one of the\\nimportant factors that influences the properties of an organic material,\\nthe \"size effect\\\\\" of polymers is not directly correlated with the size\\nof the monomers because a large collection of small monomers (e.g.,\\nethylene) can also build long polymer chains the same way large monomers\\ndo. Instead, various metrics based on the molecular weight distribution\\n(MWD) of a polymer are often used as a reference to relate the \"size of\\npolymer\\\\\" to polymer properties. Different polymers built from the same\\nmonomer can have different MWD by controlling the polymerization\\nprocess, which can lead to significantly different physical and chemical\\nproperties[@Imrie:1994aa; @doi:10.1002/pen.760220402; @Fetters:1994aa].\\nFurthermore, the collection of polymer chains can form very different\\ncrystal structures through a variety of crystallization processes,\\naffecting the material properties of the resulting polymers. For\\nexample, @C8NR05407J controlled the crystallinity and orientation of\\npoly(3-hexylthiophene) molecules to optimize the performance of solar\\ncells[@C8NR05407J]. Finally, the same type of polymer in the microscopic\\nscale can undergo different manufacturing process, such as stretching or\\nmixing additives, to further enhance or alter its properties in order to\\nfulfil specific needs from a broad range of\\napplications[@PolyethleneBK]. Ideally, the design space of polymers\\ncovers all parameters involved in the three production steps, for\\nexample, the molecule space of a single or multiple monomer(s) (namely\\nhomopolymers or copolymers, respectively), temperature and types of\\npolymerization process, additives or fillers, molding methods, etc. In\\npractice, we often focus on a subset of the parameters while keeping\\nother fixed to reduce the enormous search space. For example, @Wu:2019aa\\nfocused on the design of monomer that has a high probability of making\\nliquid crystal polymers with high thermal conductivity after compressed\\nto a polymer thin film[@Wu:2019aa].\\n\\n![Overview of polymer design across different length\\nscales.](Figure1.pdf){#fig:polymer_production width=\"14cm\"}\\n\\nA machine learning approach of polymers design on such a large design\\nspace requires a very large data set, in terms of both quantity and\\ndiversity. Unfortunately, openly available large polymer database is\\nstill limited[@Audus:2017aa] and historical data is often highly biased\\nto a few types of polymers or polymer properties. For example, in\\nPoLyInfo[@PoLyInfo; @PoLyInfo:2011], which is one of the largest\\ndatabase of polymers, around 30% of data related to thermal properties\\nare covered by only 10 different polymers and over 40% of data is glass\\ntransition temperature (see Figure\\n[2](#fig:PI_data){reference-type=\"ref\" reference=\"fig:PI_data\"}). In\\norder to achieve a fully data-driven process of polymer design,\\ncontinuous efforts have been made to bridge the demand of machine\\nlearning technologies and the current state of polymer informatics. In\\nthis paper, we review and discuss the applications of machine learning\\non different aspects of the polymer design process through four\\nperspectives: polymer databases, representation (descriptor) of\\npolymers, predictive models for polymer properties, and polymer design\\nstrategy. Illustrative examples are also given using the open-source\\nmaterials informatics software, XenonPy[@XenonPy]. We hope that this\\npaper can serve as an entry point for researchers interested in the\\nfield of polymer informatics, who may be coming from any of the\\nscientific fields covered by polymer informatics.\\n\\n![Statistics of 54151 data entries of 83 different polymer properties\\nrelated to thermal properties recorded in PoLyInfo (extracted on April\\n2016). (a) Histogram of the number of data for the top 100 polymers with\\nthe most data is plotted in descending order. (b) Histogram of the\\nnumber of data for 83 different polymer properties is plotted in\\ndescending order.](Figure2.pdf){#fig:PI_data width=\"16cm\"}\\n\\n# Machine learning in polymer informatics\\n\\nThe goal of machine learning is to develop computer algorithms that can\\nautomatically improve their ability to solve a target problem by\\nextracting information from past experience (training data). A basic\\nimplementation of this idea is to build a mapping $f$ from an input $x$\\nto an output $y$ when given some relevant data $D$. Here, $x$ is the\\nrepresentation (or descriptor) of a problem of interest, which we will\\ndiscuss in detail in the next section. Depending on the choice of $f$,\\n$y$ and $D$, machine learning is often categorized into:\\n\\n-   **Supervised learning** \\xa0\\xa0 Directly building $f$ that maps $x$ to\\n    the desired output of interest $y$ by learning from many examples of\\n    pairings between different $x$ and $y$ in $D$. Such data that\\n    contains pairs of $x$ and $y$ is called labelled data. Supervised\\n    machine learning is often subcategorized into regression or\\n    classification, where $y$ is either a continuous variable or a\\n    discrete variable, respectively. An example would be building a\\n    model to predict the glass transition temperature of homopolymers\\n    ($y$) from composition and bonding information of the corresponding\\n    monomers ($x$)[@Wu:2016aa; @Kim:2018aa].\\n\\n-   **Unsupervised learning** \\xa0\\xa0 Learning the underlying structure of\\n    $x$ using unlabelled data, i.e., $D$ has no information about the\\n    output of interest $y$. Typical techniques of unsupervised machine\\n    learning are clustering and dimension reduction, where $x$ is mapped\\n    to some categorical labels or lower dimensional space, respectively.\\n    For example, @PhysRevE.99.043307 used these techniques to study\\n    phase transitions of polymer configurations[@PhysRevE.99.043307].\\n    Note that the learned mapping is not necessarily directly correlated\\n    with the targeted $y$ as such information is not included in $D$.\\n\\n-   **Reinforcement learning** \\xa0\\xa0 Learning a strategy to achieve a\\n    certain goal in an interactive environment. Closely related to the\\n    problem of experimental design, the goal here is to learn $f$ that\\n    maps the current state $x$ to a possible action $y$. Successful\\n    training of $f$ through repeated engagement to the system can take\\n    the system closer to the final goal. Typically, a reward function is\\n    defined to quantify the progress of the system and the size of $D$\\n    increases continuously during the interactive engagement process. An\\n    example would be developing optimal strategy to control MWD of a\\n    class of polymers[@C7ME00131B].\\n\\nDepending on the nature of application, available data and computing\\nresources, it is important for researchers to frame their problems under\\nan appropriate class of machine learning, to pick a suitable learning\\nalgorithm, and to represent the materials of interest using an effective\\ndescriptor. We attempt to provide useful hints from existing literature\\nand our own experience in the following sections.\\n\\n# Database\\n\\nOne of the most important components in machine learning is data. The\\nquality and quantity of available data determine the scope of solvable\\nproblems in an application. A rule of thumb in machine learning is that\\npurely data-driven models are not reliable when extrapolating. In other\\nwords, it is dangerous to trust the prediction of a model on a material\\nthat is not similar to the ones in the training data. Therefore, high\\nquality large database for a diverse set of polymers is always of high\\ndemand in polymer informatics. Table [1](#tab:DB){reference-type=\"ref\"\\nreference=\"tab:DB\"} shows a list of online databases that contain\\npolymer data. There also exists large amount of publications on polymer\\ntechnology or database that collects recipes of polymer synthesis (e.g.,\\nNIST Synthetic Polymer MALDI Recipes Database[@MALDI]). These types of\\ninformation require extra processing effort before being useful for\\npolymer informatics.\\n\\n::: {#tab:DB}\\n  Name (link)                                                         Descriptions\\n  ------------------------------------------------------------------- ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  PoLyInfo (polymer.nims.go.jp)                                       Polymer database supported by National Institute for Materials Science (NIMS) where data is mainly extracted from academic literature (covering 18,044 literature data). The database includes 367,711 property data points of various kinds of polymers built from 18,015 different monomers[@PoLyInfo; @PoLyInfo:2011].\\n  Polymer Genome - Khazana (khazana.gatech.edu)                       An open online platform that stores computational and experimental data from 24 publications. The database includes property data of 1,412 different polymers/organic materials and 2,657 different inorganic materials[@Huan:2016aa; @Kim:2018aa].\\n  Polymer Property Predictor and Database (pppdb.uchicago.edu)        Online polymer database maintained by CHiMaD that includes 263 and 212 data entries of Flory-Huggins $\\\\chi$ value and glass transition temperature, respectively, extracted from the literature.\\n  NanoMine \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 (materialsmine.org/nm#)   An open platform for data sharing that includes images of polymer microstructures and property data of polymers[@Zhao:2016aa; @Zhao:2018aa].\\n  Cambridge Structural Database (www.ccdc.cam.ac.uk/structures)       Crystal structure database of organic and inorganic materials that includes more than 1,000,000 structures, where around 11% is polymeric.\\n  CROW (polymerdatabase.com)                                          An online data source that includes thermo-physical data of polymers. The source is either experimental data from the literature and/or calculated values from similarity analysis or quantitative structure property relationships.\\n  Polymers: A Property Database (poly.chemnetbase.com)                Online database of various polymer properties used to support the book *Polymers: A Property Database* by Wiley[@PDB_book].\\n  Citrination (citrination.com)                                       Materials informatics platform that includes publically available data of mechanical properties and solid surface energy of polymers.\\n  CAMPUS (www.campusplastics.com)                                     Material property database of 9,236 commercial polymer grades.\\n  Identify (www.netzsch-thermal-analysis.com)                         Commercial software and database that includes differential scanning calorimetry curves for more than 600 commercial polymers.\\n\\n  : List of online polymer databases. Numbers are extracted on September\\n  25, 2020.\\n:::\\n\\nComparing to other research fields (e.g., image recognition) that\\nbenefit from modern machine learning technology, deep learning\\nspecifically, the number and size of open databases in polymer\\ninformatics are significantly smaller. We have accumulated a large\\namount of polymer data throughout the history of polymer science, but\\nmany historical data recorded in handbooks or publications are not\\nwell-organized, and a lot of the industry-owned data are not openly\\navailable. These issues have become the bottleneck for the development\\nof polymer informatics[@Audus:2017aa]. With the advancements of\\ncomputational simulation technologies and supercomputers, we expect an\\nincreasing interest and opportunity to build large scale computational\\ndatabases of polymers. Meanwhile, technology of high-throughput\\nexperiments[@Oliver:2019aa] and the use of robotics combined with\\nartificial intelligence[@Burger:2020aa] provide new opportunities to\\nbuild experimental database of polymers efficiently. Making these\\ndatabases open for research purposes will be the key to the success of\\npolymer informatics.\\n\\n# Descriptor\\n\\nThe fundamental purpose of a material descriptor is to uniquely encode\\nmaterials in a compact form in order to allow for efficient machine\\nlearning. This is particularly difficult for polymers due to their\\nhierarchical structures[@HS_polymer]. An example of unique\\nrepresentation of polymers would be the Polymer Markup Language, which\\nis designed to include complete information of a polymer ranging from\\ncompositional information to all the processing\\nparameters[@Adams:2008aa]. While this representation may be suitable for\\nbuilding polymer databases, it is not compact enough to be used as input\\nof a model for machine learning purposes. In fact, a good material\\ndescriptor should consider the tradeoff between ability to uniquely\\nrepresent a material, easiness to obtain or calculate, and sensitivity\\nto targeted application[@ZHOU20191017]. In other words, while possible,\\nit is unlikely that a single descriptor can be used for all polymer\\napplications. For example, to search for an efficient polyimide for\\ncontrolled inkjet deposition, descriptor needs to be sensitive to\\nspecific microstructures formed by the polymer chains[@C5PY00622H]. On\\nthe other hand, designing polymers with certain phase transition\\nproperties will require a descriptor that identifies key atomic-level\\nstructures. Different level of \"fineness\\\\\" of descriptor should be\\nselected depending on the physical and chemical properties of interest\\nto the target problem[@Ramprasad:2017aa]. One example that attempted to\\ncapture such hierarchy of descriptor in a Python package is the\\nMaterials knowledge systems[@Brough:2017aa]. Here, we introduce and\\ncompare a few descriptors that could be useful in polymer informatics.\\n\\nProcessing conditions of polymers, such as temperature, additives and\\nsolvents, can be directly included in a descriptor. Representations of\\nthe microstructure and molecular structure of polymer chains are less\\nintuitive. Certain machine learning models in deep learning allow direct\\nuse of images as input, but often require a significant amount of data\\nto train the models[@NIPS2012_4824]. Persistant homology is a technique\\nto extract statistical features from topological\\nstructures[@Buchet2018], but its application in polymer informatics is\\nyet to be investigated. Graphical kernel is another option to\\nnumerically encode the polymer structures that can be represented in a\\nsimple graph[@JMLR:v11:vishwanathan10a]. However, finding an efficient\\ngraph representation for the complex polymer structures is challenging,\\nespecially because different types of polymer chains can form structures\\nin different length scales. Many of the descriptors commonly used in\\npolymer informatics focus on capturing the molecular structure of\\nmonomers composing the polymer chains.\\n\\nMaterial descriptors or fingerprints developed for small organic\\nmolecules are directly applicable to represent polymers based on their\\nmonomers. Modern machine learning algorithms also allow direct use of\\nmolecular graph or simplified molecular-input line-entry system\\n(SMILES)[@SMILES:1988] strings as input of a model[@MICCIO2020122341].\\nPicking a descriptor suitable for the problem of interest may\\nsignificantly improves the efficiency of machine\\nlearning[@Ramprasad:2017aa]. However, such representation omits\\ninformation about the chemical bonds between the monomers. An\\nalternative is to consider oligmer consisting of $n$ monomers, but there\\nis no clear answer to how to pick $n$. The larger $n$ is, the more\\nrepresentative the oligmer would be to the polymer. Nevertheless,\\ncertain types of descriptors, such as the physical descriptors, will\\ntake significantly longer time to calculate for a larger molecule.\\nFurthermore, some fingerprints could be biased toward polymers with\\nsmaller or larger monomers depending on the choice of $n$. For example,\\na fingerprint that counts if there are more than 3 benzene rings in a\\nmolecule will not be able to distinguish between polystyrene and\\npoly(bisphenol A carbonate) when $n > 3$. Figure\\n[3](#fig:fingerprints){reference-type=\"ref\"\\nreference=\"fig:fingerprints\"} shows how different fingerprints may have\\ndifferent convergence behavior with respect to $n$. @Wu:2016aa proposed\\nto calculate descriptor of polymers using an infinitely long chain of\\ntheir corresponding monomers[@Wu:2016aa]. However, the bias issue for\\nsome fingerprints remains unsolved.\\n\\n![Convergence of the change of fingerprints for two polymers as a\\nfunction of the number of monomers in the oligmer. The change is\\nmeasured by Tanimoto index between the fingerprints of the monomer and\\nthe oligmer ($n$ from 2 to 10), which represents the similarity of the\\ntwo fingerprints. Three RDKit fingerprints implemented in XenonPy are\\nused: *RDKitFP* denotes the standard fingerprint, *ECFP* denotes the\\nMorgan fingerprint, and *MACCS* denotes the MACCS\\nkeys.](Figure3.pdf){#fig:fingerprints width=\"12cm\"}\\n\\nPolymer chain can be separated into a backbone and its side chains.\\nDistinguishing the two components is theoretically important to predict\\npolymer properties. However, it is not clear how to efficiently encode\\nsuch information into a general descriptor for different classes of\\npolymers. Similarly, developing descriptors for polymers consisting of\\nmore than one type of monomer is still an open challenge. For\\nalternating copolymer, we can simply consider the combined repeating\\nunit of multiple monomers as a \"metamonomer\\\\\", but the molecule may\\nbecome too big that conventional descriptors or fingerprints are not\\nefficient anymore. Efficient descriptor for block or graft copolymers is\\nyet to be found. Embedding methods using neural network can be a\\npotential option, but problems such as invariance to the input order of\\nmonomers or generality to different types of chemical reactions used to\\nform the polymers using multiple monomers remain to have no clear\\nsolution.\\n\\n# Predictive models\\n\\nOne of the key components in polymer design is the prediction of polymer\\nproperties relevant to a target application. Some of the important\\nproperties often considered in the polymer industry include\\ntransparency, glass transition temperature, toughness,\\netc[@Willbourn1976]. The ability to predict properties of different\\nclasses of polymers opens up new computational design approaches for\\npolymers, such as high-throughput screening and inverse design, which\\nwill be discussed in the next section. One approach to predict polymer\\nproperties is building empirical equations based on physical descriptors\\nand some basic properties of polymers. An effort to collect such\\nequations in Python has been made by the *thermo* package[@thermo]. This\\napproach can be very powerful, but could be difficult to use when\\npredicting properties for a new design with not much knowledge available\\nyet. Another approach that is more suitable for design purpose, called\\nthe quantitative structure--property relationship (QSPR) modeling, aims\\nat mapping structural descriptors of a material to its property. In\\nparticular, models that rely only on 2D structure information of the\\npolymer is preferred as it avoids intensive geometry optimization for\\nthe polymer molecules. To date, around 300 articles can be found on the\\nweb of science database when searching with keywords QSPR and polymer.\\n\\nGroup contribution method is one of the earliest data-driven approaches\\nto predict complex properties of different polymers[@VKBook]. The basic\\nidea is that certain groups of bonded atoms within different molecules\\nmay have common effects on a specific material property. Linear\\nregression is used to model the interaction between groups when data is\\nlimited, but higher order models can also be used. Machine learning\\nmodels using fingerprints as input can be seen as an extension to this\\nidea, since the fingerprints are collections of rules that check the\\nexistence of different structural groups. Some commonly used models\\ninclude elastic net, support vector machine, random forest, Gaussian\\nprocess, neural network, etc. Table [2](#tab:pred){reference-type=\"ref\"\\nreference=\"tab:pred\"} summarizes some recent applications of these\\nalgorithms in polymer informatics.\\n\\n::: {#tab:pred}\\n  Property                                   Data size   Descriptor   Model   Test method   RMSE    MAE     $\\\\text{R}^2$   Unit\\n  ------------------------------------------ ----------- ------------ ------- ------------- ------- ------- -------------- ---------------\\n  $\\\\Delta E$[@Kim:2018aa]                    392         Mix          GP      CV-5          0.01    0.01    0.999          eV/atom\\n  $\\\\epsilon_{gap}$[@Wu:2016aa]               155         ICD          SVM     Split-20      ---     ---     0.88           eV\\n  $\\\\epsilon_{gap}$[@Kim:2018aa]              382         Mix          GP      CV-5          0.3     0.23    0.971          eV\\n  $\\\\epsilon_{gap}$[@doi:10.1063/1.5023563]   3,989       Str          VAE     CV-5          ---     74      ---            meV\\n  $\\\\kappa$[@Wu:2016aa]                       155         ICD          SVM     Split-20      ---     ---     0.96           ---\\n  $\\\\kappa$[@Kim:2018aa]                      384         Mix          GP      CV-5          0.48    0.32    0.815          ---\\n  $\\\\rho$[@Kim:2018aa]                        173         Mix          GP      CV-5          0.05    0.03    0.938          g/cm${}^3$\\n  HOMO[@doi:10.1063/1.5023563]               3,989       Str          VAE     CV-5          ---     66      ---            meV\\n  LUMO[@doi:10.1063/1.5023563]               3,989       Str          VAE     CV-5          ---     43      ---            meV\\n  $\\\\epsilon_{opt}$[@doi:10.1063/1.5023563]   3,989       Str          VAE     CV-5          ---     70      ---            meV\\n  $\\\\eta$[@Kim:2018aa]                        384         Mix          GP      CV-5          0.08    0.05    0.892          ---\\n  $\\\\eta$[@Khan:2018aa]                       221         D&P          PLS     Split-30      ---     0.004   0.899          ---\\n  $\\\\eta$[@doi:10.1063/5.0008026]             527         Mix          GP      Select-27     0.05    ---     0.88           ---\\n  $\\\\delta$[@Kim:2018aa]                      113         Mix          GP      CV-5          0.56    0.4     0.955          MPa${}^{1/2}$\\n  $T_g$[@Wu:2016aa]                          270         ICD          SVM     Split-20      ---     ---     0.95           K\\n  $T_g$[@Kim:2018aa]                         451         Mix          GP      CV-5          17.74   12.79   0.944          K\\n  $E_g$[@D0ME00020E]                         11,000      Img          CNN     Split-15      ---     0.68    ---            \\\\%${}^*$\\n  $E_r$[@D0ME00020E]                         11,000      Img          CNN     Split-15      ---     3.12    ---            \\\\%${}^*$\\n  tan$\\\\delta_{max}$[@D0ME00020E]             11,000      Img          CNN     Split-15      ---     3.58    ---            \\\\%${}^*$\\n\\n  : Examples of QSPR for different polymer properties using machine\\n  learning technologies. Corresponding references are cited in the\\n  property column. For properties, $\\\\Delta E$ denotes atomization\\n  energy, $\\\\epsilon_{gap}$ denotes bandgap, $\\\\kappa$ denotes dielectric\\n  constant, $\\\\rho$ denotes density, HOMO denotes highest occupied\\n  molecular orbital, LUMO denotes lowest unoccupied molecular orbital,\\n  $\\\\epsilon_{opt}$ denotes optical gap, $\\\\eta$ denotes refractive index,\\n  $\\\\delta$ denotes solubility parameter, $T_g$ denotes glass transition\\n  temperature, $E_g$ denotes glass modulus, $E_r$ denotes rubber\\n  modulus, and tan$\\\\delta_{max}$ denotes peak height of viscoelastic\\n  loss tangent. For descriptors, *Mix* denotes a mix of various\\n  descriptors specified by @Kim:2018aa[@Kim:2018aa], *ICD* denotes the\\n  infinite chain descriptors[@Wu:2016aa], *Str* denotes customized\\n  strings by @doi:10.1063/1.5023563[@doi:10.1063/1.5023563], *D&P*\\n  denotes a combination of the Dragon[@Dragon] and PaDEL[@Yap:2011aa]\\n  descriptors, and *Img* denotes direct use of 2D microstructure images.\\n  For models, *GP* denotes Gaussian process, *SVM* denotes support\\n  vector machine, *PLS* denotes partial least squares regression, *VAE*\\n  denotes using the best regression model based on the hidden layer of a\\n  variational autoencoder as described by\\n  @doi:10.1063/1.5023563[@doi:10.1063/1.5023563], and *CNN* denotes a\\n  multi-task learning convolutional neural network. For test method to\\n  calculate root mean squared error (RMSE), mean absolute error (MAE)\\n  and coefficient of determination (R${}^2$) of the QSPR models, *CV-5*\\n  denotes a 5-fold cross validation, *Split-X* denotes a X% random\\n  splitting of test data from the full data set, and *Select-27* denotes\\n  manually picking 27 data points as test data. (${}^*$\\xa0Mean absolute\\n  percentage error is measured for these studies)\\n:::\\n\\nMachine learning models are inherently interpolative, i.e., their\\npredictions are reliable only around the domain close to the training\\ndata. The range of properties prediction for certain types of polymers\\nwith a reasonable accuracy governs the potential search space one can\\ncover, i.e., the performance of the final design. In other words, the\\ntraining data determines the feasible design space of the target\\napplication. The concept of applicability domain (AD) developed in\\nCheminformatics is used to quantify the reliable region of a QSPR\\nmodel.[@Sheridan:2004aa] The concept of uncertainty in statistics is\\nalso a popular metric believed to be strongly correlated with the\\nvalidity of a prediction.[@Chatfield:1995aa] Figure\\n[4](#fig:P2O){reference-type=\"ref\" reference=\"fig:P2O\"} shows how\\ndifferent models fail to predict different materials properties when\\nextrapolating from the given data. One idea to tackle this issue is\\ncalled transfer learning, that is to exploit information learned from a\\nrelevant task for improving prediction of another task. @Yamada:2019aa\\ndemonstrated the successful applications of transfer learning in\\ndifferent materials science problem, including polymers[@Yamada:2019aa].\\nIntuitive ideas for knowledge transfer include transferring from a\\nglobal material space to a local domain, from a material property with\\nrich data to a physically linked property with little data, or from\\ncomputational data to experimental data. The latter idea is also called\\nmulti-fidelity learning, which has been successfully applied to predict\\ncrystallization tendency[@Venkatram:2020aa] and\\nbandgap[@PATRA2020109286] of polymers.\\n\\n![Demonstrating extrapolation power of machine learning models using\\ndata from Polymer Genome[@Kim:2018aa]. (a) Visualization of a 2D\\nprojection of the 200 physical descriptors in RDKit using t-distributed\\nStochastic Neighbor Embedding[@TSNE] with perplexity = 30. The data is\\nfurther separated into five groups, either randomly or through K-means\\nclustering[@kmeans] with number of cluster = 5. The groupings are used\\nfor cross validation to test the prediction performance on glass\\ntransition temperatures (Tg) and Hildebrand solubility parameter (HSP).\\n(b) Plots of predictions versus observed data for Tg and HSP based on\\nBayesian ridge regression (BR) and random forest (RF). Crosses are\\nresults from cross validation based on K-means clustering, i.e., each\\nset of test data is not similar to the training data (extrapolation).\\nCircles are results from cross validation based on random picking. The\\nextrapolation case has a worse prediction accuracy all four cases, where\\nthe failure patterns are different between BR and\\nRF.](Figure4.pdf){#fig:P2O width=\"16cm\"}\\n\\n# Polymer design\\n\\nWhile there are increasing examples of machine-assisted polymer design,\\nthere has not been any report of end-to-end design example that covers\\nevery step from monomer design to manufacturing process. Instead,\\npolymer informatics has been used to improve design efficiency within\\neach step of of the polymer design process. For example, @Wu:2019aa\\ndiscovered new homopolymers with high thermal conductivity that are\\nvalidated experimentally[@Wu:2019aa] and @C7ME00131B developed an\\nalgorithm that discovers optimal strategy to experimentally control MWDs\\nof various polymers[@C7ME00131B]. There are three types of design\\nstrategies based on machine learning technology: high-throughput\\nscreening, inverse design, and experimental design. We will discuss\\nvarious efforts of applying these methods to polymer design in this\\nsection.\\n\\n## High-throughput screening\\n\\nHigh-throughput screening aims at identifying potential candidates of\\ninterest by conducting computational or experimental tests on a large\\npool of candidates. In polymer informatics, a library of chemically or\\nsynthetically feasible polymer candidates is built and then\\ncomputationally screened by predictive models relevant to the target\\nmaterial properties. When the search space is finite and tractable, the\\nlibrary is simply composed of the exhaustive list of candidates, such as\\nselection of optimal processing method within the existing technologies.\\nOne can also use a library from any open databases. Otherwise, a\\ngenerative algorithm is needed to construct a pool of candidates of\\ninterest. For example, a conventional approach is to define a set of\\nmolecular fragments of interest and exhaustively combine different\\nnumbers of fragments up to an upper limit to form the candidate set.\\nFragment can be obtained from organic molecules which have more large\\nopen databases, such as GDB-17[@Ruddigkeit:2012aa] or\\nPubchem[@Kim:2016]. To expand beyond the search space limited by a\\nfinite variety of fragments, @doi:10.1002/minf.201900107 implemented a\\nlanguage model proposed by @Ikebata:2017[@Ikebata:2017] on polymers\\nrepresented in SMILES.[@doi:10.1002/minf.201900107] Different deep\\nneural networks are also used to learn the SMILES or graph\\nrepresentation of organic\\nmolecules[@Cao2018MolGANAI; @10.5555/3327345.3327537; @Popovaeaap7885].\\n\\nGiving a library of candidates, one can use pretrained predictive models\\nto computationally screen out candidates with target properties. There\\nis a significant amount of literature that applies high-throughput\\nscreening to different polymer applications. Recent examples of\\nhigh-throughput screening in polymer designs using machine learning\\nmodels include searching of high refractive index\\npolymers[@Khan:2018aa; @JABEEN2017215; @Afzal:2019aa] and screening\\noptoelectronic properties of conjugated polymers[@Wilbraham:2018aa].\\nThis strategy of polymer design may sound inefficient to solve a single\\ndesign problem, because a significantly large library is needed to\\nincrease the probability of finding candidates of interest. However, a\\nwell-developed library that contains diverse candidates can be reused\\nfor many different design problems. With a rich database of candidates,\\nhigh-throughput screening is a very attractive tool in many industrial\\napplications.\\n\\n## Inverse design\\n\\nAnother design strategy, referred as the inverse design, is to perform\\ntargeted search in a materials space guided by knowledge extracted from\\nexisting data. While predictive model is a mapping from an input $x$\\n(polymer) to an output $y$ (material property), the goal of inverse\\ndesign is to map a targeted range of $y$ to a sub-domain of $x$. This\\ncan be achieved by solving an optimization problem using sophisticated\\nalgorithms, such as genetic algorithms, or by sampling the set of $x$\\nwith high probability to be in the targeted range of $y$ under a\\nBayesian framework. Both approaches can be implemented in an iterative\\nalgorithm:\\n\\n1.  Start with a set of initial candidates.\\n\\n2.  Propose a new set of candidates based on the existing ones.\\n\\n3.  Evaluate likeliness of the candidates to have the desired material\\n    properties.\\n\\n4.  Repeat step 2 and 3 for fixed number of times or until convergence.\\n\\nIn step 2, a generative algorithm is needed to propose new candidates\\nsimilar to the one in the high-throughput screening. In the case of\\noptimization, the likeliness metric in step 3 is usually a loss function\\nmeasuring the distance of the predicted properties for the candidates\\nand the targeted properties. For sampling, the likeliness metric is\\nusually correlated with the probability of observing the candidates\\nconditional on the targeted properties.\\n\\nThe inverse design problem is inherently ill-posed, i.e., there are\\ndifferent types of materials that may have the target properties. It is\\nimportant that an inverse design algorithm can produce a diverse set of\\ncandidates in order to maximize the probability of discovering novel\\nfunctional materials. Typical optimization algorithm can only search for\\nthe optimal solution. Sampling methods can have a higher chance to\\nprovide diverse candidates, but can also be trapped in a local mode,\\nespecial when the search space is high dimensional. Many efforts have\\nbeen made to address this issue, such as limiting the search space size,\\nprojecting the search space to a low dimensional space, or employing an\\nannealing algorithm, etc. Table [3](#tab:inv){reference-type=\"ref\"\\nreference=\"tab:inv\"} shows some recent examples of successful inverse\\ndesign of different polymer applications using machine learning\\ntechnologies.\\n\\n::: {#tab:inv}\\n  Publication                                                                                 Target property         Method\\n  ------------------------------------------------------------------------------------------- ----------------------- ---------------------------------------\\n  Mannodi-Kanakkithodi                                                                        Dielectric constant     Optimization using\\n  et al. ([-@Mannodi-Kanakkithodi:2016aa])[@Mannodi-Kanakkithodi:2016aa]                      and bandgap             genetic algorithm\\n  @doi:10.1063/1.5023563 ([-@doi:10.1063/1.5023563])[@doi:10.1063/1.5023563]                  LUMO and                Gradient-based optimization on\\n                                                                                              optical gap energy      embedded space in deep neural network\\n  @Pilania:2019aa ([-@Pilania:2019aa])[@Pilania:2019aa]                                       Glass transition        Optimization using\\n                                                                                              temperature             genetic algorithm\\n  @Kumar:2019aa ([-@Kumar:2019aa])[@Kumar:2019aa]                                             Phase behavior          Optimization using\\n                                                                                                                      particle swarm optimization\\n  @Wu:2019aa ([-@Wu:2019aa])[@Wu:2019aa]                                                      Thermal                 Sampling with\\n                                                                                              conductivity            sequential Monte Carlo\\n  @Schadler_2020 ([-@Schadler_2020])[@Schadler_2020]                                          Three different         Optimization using\\n                                                                                              dielectric properties   genetic algorithm\\n  @doi:10.1002/minf.201900107 ([-@doi:10.1002/minf.201900107])[@doi:10.1002/minf.201900107]   Dielectric constant     Sampling with\\n                                                                                              and bandgap             sequential Monte Carlo\\n\\n  : Examples of polymer inverse design using machine learning\\n  technologies.\\n:::\\n\\n## Experimental design\\n\\nThe previous two design strategies relies heavily on efficiency of the\\ngenerative model and accuracy of the predictive model, which, in turn,\\nrelies on the quality and quantity of training data. Since many\\nproperties of polymers have only limited data, increasing data size with\\nextra experimental or computational tests is inevitable to ensure that\\nthe machine learning models can cover a large enough design space.\\nInstead of randomly picking candidates to perform the new tests, one can\\nemploy a recursive design process, i.e., new test candidates are\\noptimally selected and tested, and the results are added to the existing\\ndata set for improving the optimal candidate selection in the next round\\nof tests. Such trial-and-error design process is what a chemist would do\\nin practice.\\n\\nThe goal of experimental design is to minimize the amount of new\\nexperiments required to reach a design goal. There are two perspectives\\nto the optimality of candidate selection: (1) exploit the knowledge\\nembedded in the existing data to make the best guess of which candidates\\nmay satisfy the design goal, or (2) explore candidates with the least\\ninformation from the existing data to infer their properties. In a\\ntypical experimental design algorithm, we define a utility function that\\nbalance the tradeoff between the two perspectives. Candidates that\\noptimize the utility function are selected for the next round of tests.\\nBayesian optimization and reinforcement learning are two commonly used\\nalgorithms for experimental design. The former considers candidates with\\na high prediction uncertainty as exploratory and optimize the utility\\nfunction accordingly. The latter treats the problem as a game with\\nreward when achieving the design goal, where an agent is trying to learn\\nthe best strategy (minimum number of experiments) to get the maximum\\nreward (reaching the design goal). Table\\n[4](#tab:exp){reference-type=\"ref\" reference=\"tab:exp\"} shows some\\nrecent examples of experimental design applications on different stages\\nof the hierarchical polymers design process.\\n\\n::: {#tab:exp}\\n  Publication                                                                                                                                                                     Target                           Search space              Method\\n  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -------------------------------- ------------------------- ---------------\\n  @Li:2017aa ([-@Li:2017aa])[@Li:2017aa]                                                                                                                                          Median length, median            Five synthetic            Bayesian\\n                                                                                                                                                                                  diameter and quality of fibers   process parameters        optimization\\n  @C7ME00131B ([-@C7ME00131B])[@C7ME00131B]                                                                                                                                       Shape of MWD                     Amount of five            Reinforcement\\n                                                                                                                                                                                                                   chemical reagents         learning\\n  @WANG2018146 ([-@WANG2018146])[@WANG2018146]                                                                                                                                    Interphase properties            Hyperparameters in        Bayesian\\n                                                                                                                                                                                  (dielectric and viscoelastic)    two interphase models     optimization\\n  @minami_kawata_fujita_murofushi_uchida_omori_okuno_2019 ([-@minami_kawata_fujita_murofushi_uchida_omori_okuno_2019])[@minami_kawata_fujita_murofushi_uchida_omori_okuno_2019]   Glass transition                 Mixing ratios of          Bayesian\\n                                                                                                                                                                                  temperature                      three selected polymers   optimization\\n  @kim_chandrasekaran_jha_ramprasad_2019 ([-@kim_chandrasekaran_jha_ramprasad_2019])[@kim_chandrasekaran_jha_ramprasad_2019]                                                      Glass transition                 736 predefined            Bayesian\\n                                                                                                                                                                                  temperature                      candidates in database    optimization\\n\\n  : Examples of polymer experimental design using machine learning\\n  technologies.\\n:::\\n\\nExperimental design algorithm is the ideal solution when we do not have\\na large enough polymer database to begin with. However, polymer\\nexperiments are costly and syntheses of new polymers are difficult.\\nComputational simulations are becoming more and more accessible, yet\\ncalculations for new polymers often required labor-intensive tuning of\\nmodel parameters. Automatic simulation, synthetic planning, and property\\nmeasurement for polymers remain challenging and are continuously\\nexplored by researchers in polymer informatics.\\n\\n# Discussion\\n\\nPolymer informatics is a promising tool for discovery of novel polymers.\\nWith a sufficiently large data set to support the use of modern machine\\nlearning technology, a data-driven approach of polymer design will\\nsignificantly improve the pace of making new functional polymers,\\nsatisfying the rapidly expanding demand on polymeric materials in modern\\nsociety (e.g., deformable electronic devices[@MCBRIDE202072]). One of\\nthe most important elements of polymer informatics is the availability\\nof large open databases. Building such databases for polymer is\\nchallenging because of many reasons: (1) difficulty of encoding the\\nhierarchical structure of polymers for machine learning purposes, (2)\\ninconsistent naming rules throughout the history of polymer science, (3)\\nlack of data sharing due to many privately own industrial data, etc.\\nNonetheless, this is an essential step towards a fully data-driven\\ndesign process. Many efforts have been made to build the backbone\\ntechnologies necessary to exploit the potential benefit of polymer\\ninformatics, such as developing new descriptors to better capture the\\nphysical properties of polymers and new simulation methods to estimate\\npolymer properties with higher accuracy in a shorter time. The true\\npower of polymer informatics is to release polymer scientists from the\\nlow efficiency trial-and-error design process, thus, to free up more\\ntime for higher level design concepts and theoretical advancements. Such\\nopportunity can be realized only if we work together to push for a more\\nopen community in polymer science, where everyone can benefit from the\\nnew paradigm of polymer design. An easy first step to take would be to\\nengage in the field of polymer informatics and experience the new way of\\nstudying polymers ourselves.\\n\\n::: acknowledgement\\nThis work was supported in part by the \"Materials Research by\\nInformation Integration\" Initiative (MI2I) project of the Support\\nProgram for Starting Up Innovation Hub from Japan Science and Technology\\nAgency (JST). S.W. gratefully acknowledges financial support from JSPS\\nKAKENHI Grant Number JP18K18017. R.Y. acknowledges financial support\\nfrom a Grant-in-Aid for Scientific Research (B) 15H02672 and a\\nGrant-in-Aid for Scientific Research (A) 19H01132 from the Japan Society\\nfor the Promotion of Science (JSPS).\\n:::\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
