{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: This API is under development and may undergo changes in future releases.\n",
    "# Backwards compatibility is not guaranteed at this time.\n",
    "\n",
    "from datashaper import NoopVerbCallbacks\n",
    "from pydantic import PositiveInt, validate_call\n",
    "\n",
    "from graphrag.config.models.graph_rag_config import GraphRagConfig\n",
    "from graphrag.index.llm import load_llm\n",
    "from graphrag.index.progress import PrintProgressReporter\n",
    "\n",
    "from graphrag.prompt_tune.generator import (\n",
    "    MAX_TOKEN_COUNT,\n",
    "    create_community_summarization_prompt,\n",
    "    create_entity_extraction_prompt,\n",
    "    create_entity_summarization_prompt,\n",
    "    detect_language,\n",
    "    generate_community_report_rating,\n",
    "    generate_community_reporter_role,\n",
    "    generate_domain,\n",
    "    generate_entity_relationship_examples,\n",
    "    generate_entity_types,\n",
    "    generate_persona,\n",
    ")\n",
    "from graphrag.prompt_tune.loader import (\n",
    "    MIN_CHUNK_SIZE,\n",
    "    load_docs_in_chunks,\n",
    "    read_config_parameters\n",
    ")\n",
    "from graphrag.prompt_tune.types import DocSelectionType\n",
    "from graphrag.prompt_tune.generator.entity_extraction_prompt import ENTITY_EXTRACTION_FILENAME\n",
    "from graphrag.prompt_tune.generator.community_report_summarization import COMMUNITY_SUMMARIZATION_FILENAME\n",
    "from graphrag.prompt_tune.generator.entity_summarization_prompt import ENTITY_SUMMARIZATION_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "INFO: Reading settings from settings.yaml\n"
     ]
    }
   ],
   "source": [
    "config_file = './settings.yaml'\n",
    "root = './'\n",
    "output = './prompts'\n",
    "reporter = PrintProgressReporter(\"\")\n",
    "config = read_config_parameters(root, reporter, config_file)\n",
    "\n",
    "chunk_size = 256\n",
    "limit: PositiveInt = 15\n",
    "selection_method = DocSelectionType.AUTO\n",
    "# domain = \"computational ploymer science\"\n",
    "domain = \"Materials Science and Computational Chemistry\"\n",
    "language = \"English\"\n",
    "max_tokens = 2048\n",
    "skip_entity_types = False\n",
    "min_examples_required = 10\n",
    "n_subset_max = 1000\n",
    "k: PositiveInt = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Input (InputFileType.csv).Loaded 20 documents\n",
      "Domain: Materials Science and Computational Chemistry\n"
     ]
    }
   ],
   "source": [
    "# Retrieve documents\n",
    "doc_list = await load_docs_in_chunks(\n",
    "    root=root,\n",
    "    config=config,\n",
    "    limit=limit,\n",
    "    select_method=selection_method,\n",
    "    reporter=reporter,\n",
    "    chunk_size=chunk_size,\n",
    "    n_subset_max=n_subset_max,\n",
    "    k=k,\n",
    ")\n",
    "print(f\"Loaded {len(doc_list)} documents\")\n",
    "\n",
    "# Create LLM from config\n",
    "llm = load_llm(\n",
    "    \"prompt_tuning\",\n",
    "    config.llm.type,\n",
    "    NoopVerbCallbacks(),\n",
    "    None,\n",
    "    config.llm.model_dump(),\n",
    ")\n",
    "\n",
    "if not domain:\n",
    "    reporter.info(\"Generating domain...\")\n",
    "    domain = await generate_domain(llm, doc_list)\n",
    "    reporter.info(f\"Generated domain: {domain}\")\n",
    "\n",
    "print(f\"Domain: {domain}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['## b) Multi-fidelity co-Kriging\\n\\n\\n\\n',\n",
       " '## A. Monomer/Oligomer scale: The scales of chemical specifity\\n\\n\\n\\nThe basic building blocks are the monomers. They can have a simple chemical structure, as in the case of many commodity polymers such as polystyrene, or a rather complicated structure, as in the case of biopolymers such as RNA, DNA, or proteins. The structure of the monomers on the monomer scale determines local properties such as the charges and the polarization, the solubility in a solvent [101], the existence and structure of a hydra- tion shell [102], the local affinity to surfaces [103], or - in studies of polymer reactions, the monomer re- activity [104]. In general, these properties are also influenced by the larger scale structure of polymer systems. For example, the effective monomer re- activity depends on the accessibility of the reactive sites, which is determined not only by the local elec- tronic and steric monomer structure, but also by the polymer conformation [104, 105]. Likewise, the ef- fective charges and/or polarization of monomers de- pend on the local environment [106, 107]. In most cases, however, the corrections due to the larger scale structure',\n",
       " ' predictions ( -- ) of the meta learner along with experimental data points (.) for Tg (blue), Tm (red) and Ta (green) of four selected copolymers across the entire composition range. The 95% confidence intervals of the predictions are shown as :selected:\\n\\nshaded bands. In all cases, there is a high level of agreement between predictions and experimental data points. Interestingly, the meta learner predicts averaged trends through the experimental data points. For example, in the case of copolymer (b), the predicted trend of Ta takes an averaged pathway through the scattered experimental data points across the range of the copolymer compositions. Also, the predicted trends display an appropriate level of smoothness, which indicates that the meta learner was regulated properly during training (we are using dropouts), thus avoiding both overfitting or underfitting. Another interesting finding is that the meta learner is capable of distilling key knowledge from the data set, as shown for Tm of polymer (b) in Figure 4: although no experimental data point is present at weight fraction 0, the meta learner predicts an upwards trend for Tm. This Tm trend is inferred from the Tg trend for the same polymer. Apparently, the data on which',\n",
       " ', the values of metrics in this case are also lesser than the model using both descriptors. Hence we can conclude that calculated descriptors also add value to the model. From these tests, we find that the R2 shows a value of > 0.9 in both calculated and learnt descriptor case. Therefore, if one is not interested in using the learnt descriptors in order to keep the model more explainable, then also a R2 ~ 0.92 can be attained using the calculated descriptors alone. Further, we also verify the fact that both learnt and calculated descriptors provide useful information as removing either reduces the values of all metrics. The high R2 value of 0.9949 for the model using both descriptors validates the idea that the configurational fingerprint adds value to the predictive capabilities of the model.\\n\\nThe residual curve is also plotted (Figure 3) to see differences between the actual and predicted values. The residual plot shows the ideal behaviour of being uniformly distributed around zero. Additionally, the residual plot shows that there are no correlations and most of the values lie between +0.2. Anomalously high value at X~75000 occurs because the position vector takes very large values in this case. It is a singular exceptional case when the MC simulation ends up taking very',\n",
       " '270\\n\\n1.313\\n\\n1.501\\n\\n1.206 (+/-) 0.197\\n\\n1.517 (+/-) 0.101 1.605 (+/-) 0. 054\\n\\n(+/-) 0.256\\n\\n(+/-) 0.244\\n\\n(+/-) 0.115 (+/-) 0.124\\n\\n\\n\\n||lonic|||Conductivity||(S/cm)|||\\n|---|---|---|---|---|---|---|---|---|\\n||0.0000 0.0005||0.0010||0.0015|0.0020||0.0025|\\n||||||||||\\n|***|||||||||\\n|*SCCC*|||||||||\\n|*C(C)N*|||||||||',\n",
       " \"- justable parameters to fit for accuracy.22,25 Thus, the Widom method could still be the most promising strat- egy to solve this problem.\\n\\nAnother theoretical method is self-consistent field the- ory. This is a continuum approach that effectively pre- dicts phase diagrams of complex polymeric systems in the limit of high molecular weight chains (N > 00) and high-density liquids. In this context, fluctuations\\n\\nare suppressed, and the specific monomeric structure of the sample becomes less significant. Field-theoretical cal- culations rely on phenomenological interaction parame- ters and do not directly connect to the atomistic pic- ture. Compared with mean-field and continuum theories, particle-based methods hold an advantage by directly connecting to the local structural information while in- corporating fluctuations. 26\\n\\nOur proposed approach combines Widom's one-step, one-molecule insertion technique with a coarse-grained (CG) representation of polymer liquids based on the Inte- gral Equation theory of Coarse-Graining (IECG).27 The IECG method is an extension of polymer Reference In- teraction Site Model (polymer RISM or PRISM) theory, which is itself an extension of atomic Ornstein-Zernike (O\",\n",
       " '## 2.1. Polymers as Hypergraphs\\n\\n\\n\\nIt is a common practice[7,12,51,52] to regard the structural formula of a molecule as an or- dinary graph, where atoms are nodes, bonds are edges, and edges connect exactly two nodes. For polyurethanes, ordinary graph depictions would require prohibitively many nodes and edges. To address this, we employ a generalized graph called a hypergraph[53], which allows individual edges to join more than one node. Any edge that connects a subset of the nodes in the hypergraph is called a hyperedge. Consider the product of two monomers (1,3 bis(isocy- anatomethyl)cyclohexane and diethylene glycol) as shown in Figure 2(i). Originally, the graph required 21 nodes and 21 edges. However, if we construct each hyperedge by selecting the subset of nodes according to the monomer type, as shown in Figure 2(ii), the hypergraph for this molecule requires only 2 hyperedges. This dramatically reduces the representation cost for large polyurethane chains.\\n\\nFor increased convenience, we will visualize the hypergraph representations using the line graph[54] form shown in Figure 2(iii). In',\n",
       " 'Sherck et al [328] and Weyman et al [329] have recently developed systematic bottom-up coarse- graining strategies for deriving field-based models with non-bonded monomer interactions that are not restricted to the Flory Huggins form (3). Their idea is to proceed in two steps. In the first step, a CG particle-based with soft pair potentials of given func- tional form is determined from reference simulations of a microscopic model, e.g., by relative entropy min- imization [328] or by matching the RDF. The sec- ond step is a Hubbard stratonovich transformation that turns the particle model into an auxiliary field model, which can then be studied by field-theoretical simulations. The second step involves an inversion of the pair potential which is not possible for hard core potentials, therefore the first step is essential and cannot be omitted. This still remains true if one replaces the Hubbard-Stratonovich transforma- tion by a delta functional transformation in order to obtain a field theory of the type (4, 5). The under- lying density-based potential does not have to be an integral over a local free energy density f(, p), it could also describe nonlocal interactions as, e.g., in',\n",
       " '## a) Gaussian process regression (GPR)\\n\\n\\n\\n',\n",
       " '## Static coarse-graining\\n\\n\\n\\n1. Structure-based coarse-graining\\n\\nStructure-based coarse-graining techniques are typically used to design particle-based CG models with the goal to reproduce structural properties of the FG system such as spatial correlation functions. The CG variables are the positions Ri of CG par- ticles, and the optimization task consists in finding the best approximation for the free energy landscape U[Ri] or the configuration dependent force field Fj [Ri] in the phase space of the CG variables. Re- garding equilibrium static coarse-graining, the field is already quite advanced. The CG bonded interac- tions can be calculated in a straightforward manner by sampling, e.g., bond length and bond angle distri- butions in small reference simulations. To determine non-bonded CG interactions, researchers can use the open-source package VOTCA [263] (www.votca.org) and select between a range of established methods\\n\\n[5, 7] such as inverse Monte Carlo (IMC) [264], it- erative Boltzmann inversion (IBI) [265-269], force matching (FM) [270-274], or relative entropy (RE) minimization between the CG and the FG distri- bution [',\n",
       " \" to capture a polymer's chain architecture and sequence isomerism by describing its average repeating unit.\\n\\nThe result of the wD-MPNN's processing of the input graph is h, a learned numerical representation of the molecular ensemble that defines a polymer and its properties. This is used as the input of a feed-forward neural network to predict the polymer properties of interest, with the whole architecture being trained end-to-end. Additional details of the wD-MPNN architecture are in the SI Extended Methods, and an implementation is available on GitHub (see Data Availability).\\n\\n\",\n",
       " \" our MMPolymer.\\n\\n4.2.2 Adaptability for various downstream settings. We also explore the predictive capacity of our MMPolymer when only utilizing sin- gle modality information (either polymer 1D sequential information\\n\\nor 3D structural information) during fine-tuning. As shown in Ta- ble 3, compared to the best baseline on each polymer property dataset, both MMPolymer-1D (i.e., only utilize polymer 1D sequen- tial information during fine-tuning) and MMPolymer-3D (i.e., only utilize polymer 3D structural information during fine-tuning) con- sistently achieve lower RMSE and higher R2 on most datasets. This\\n\\nCIKM '24, October 21-25, 2024, Boise, ID, USA\\n\\nFanmeng Wang et al.\",\n",
       " ']. The analysis code used\\n\\nto compute ionic conductivity is consistent with the one used to generate the HTP-MD database and is available at https://github.com/TRI-AMDD/htp_md. More details about MD simulations, dataset composition, and computing ionic conductivity have been included in 3.4 section, as well as previous studies [35, 25, 50, 33]. The above-described simulation protocol has been previously employed to assess the computed ion transport properties of polymers in the HTP-MD database and compare them with the experimentally measured ionic conductivity values. [35]\\n\\nThe repeat units of the generated polymers are polymerized to have at least 150 heavy atoms (non-H) in their backbone, with the two ends terminated by methyl groups. This approach is consistent with the method used to generate the HTP-MD database, allowing us to compare the performance of newly generated polymers with the training set. Also, to ensure robustness, each candidate underwent five independent simulation replicas to determine its conductivity. Given the randomness in MD simulation results originating from different conformation sampling, this rigorous step was crucial for ascertaining the potential of each proposed polymer.\\n\\nThe feedback mechanism of our platform plays a vital role in its',\n",
       " '024|-0.006|+0.025|\\n|Eat|+0.028|-0.046|+0.011|-0.019|\\n\\n\\nfinding highlights the adaptability of our MMPolymer, demonstrat- ing that it has acquired adequate general knowledge through our multimodal multitask pretraining paradigm, enabling MMPolymer to flexibly choose modality information based on the characteristics of the property being predicted and the specific requirements of the corresponding fine-tuning task.',\n",
       " ' xy < A with an - an efficient lattice Monte Carlo scheme where a coarse- error ~ 1/VA. For large x >> 1 only small y contribute grained monomer occupies 8 lattice sites on a simple cubic to the integral; the underlined term in the integral can be\\n\\nlattice (i.e., the volume fraction is 8p) and bonds between replaced by 2 and we obtain asymptotically Ic(x) = 4x monomers can vary in length and direction. All length in agreement with the Padé approximation, Eq. (26). If scales are given in units of the lattice constant. Systems the first subdominant contribution to the integral is also with an annealed size distribution are obtained by at- computed one gets Ic(x) = 4x - 1.13x for large x. For tributing a finite scission energy E to each bond which small test chains, the integral provides the first correction has to be paid whenever the bond between two monomers Ic(x) = 2x, i.e., it vanishes for x -> 0 as already noted. In short, we recover the known asymptotic for short and long test chains but the crossover is very sluggish. The simple',\n",
       " \"## 5 Conclusion\\n\\n\\n\\nOur model takes into account polymer's stereoregularity (i.e. tacticity) and correctly represents the difference between isotactic and syndiotactic PNIPA; the results are in good accordance with atomistic simulations. Moreover, the developed CG model represents globule-to-coil transition, which is still unaccessible by all-atom MD. The proposed approach might be advantageously exploited to study other thermoresponsive and/or stereo(ir)regular polymers; it allows to address big time- and lenghtscales.\\n\\n\",\n",
       " ' the polymer property. To handle this, we augment our PolyGrammar with an additional set of production rules focusing on the representation and generation of functional groups. We also demonstrate the effectiveness of our augmented PolyGrammar us- ing the polyacrylate as an illustrative example. This functional-group grammar together with the basic PolyGrammar (full set of the production rules in Supporting Information) serves as a hierarchical generative model for polymers, where the latter one handles the backbone and the former one focuses on the functional residue of each composed monomer. More examples are shown in Supporting Information.\\n\\n',\n",
       " ' the dashed line.\\n\\ntion is that (taken apart different prefactors) the same effective interaction potential, Eq. (15), enters the per- turbation calculation in the low wavevector limit. A non- extensive correction duc(n) ~ +1/ yn in three dimensions is thus to be expected.\\n\\nWe thank the Université de Strasbourg, the CNRS, and the ESF-STIPOMAT programme for financial support. We are in- debted to S.P. Obukhov and A.N. Semenov for helpful discus-',\n",
       " 'erty prediction pipeline is compared with the state-of-the-art handcrafted Polymer Genome8 (PG) fingerprint based pipeline pioneered previously. Using the ultrafast polyBRET polymer informatics pipeline, we are in a position to predict the properties of the 100 million hypo- thetical polymers intending to find property boundaries of the polymer universe. This work contributes to expediting the discovery, design, development, and deployment of polymers by harnessing the true power of language, data, and artificial intelligence models.',\n",
       " ' to understand the polymer structures merely from the numeric vector.\\n\\nValid. Generative models that build on a well-defined representation scheme are highly coveted[40], particularly for their ability to efficiently build large corpora of example structures. However, the result is only useful if the examples generated by the model are guar- anteed to be chemically valid. This is challenging to enforce for polymers, as there are many hard chemical constraints (e.g., valency conditions) and other restrictions to account for. The likelihood of violating these constraints increases as the target molecules get larger.\\n\\nMachine learning techniques including support vector machines (SVM)[41], recurrent neural networks (RNN)[1-4], generative adversarial networks (GAN)[9-12], and AE have been used as generative models for molecules. However, these methods often produce outputs that are chemically invalid, even when limited to small molecules. It is even more challenging for these methods to generate valid polymers, due to the large number of generation steps re- quired to realize such large molecules. Although several recent efforts based on AE[35,36] and reinforcement learning (RL)[42,43] have been proposed to produce valid polymers, it is not clear how well they generalize - i.e']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Generating persona...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You are an expert in Materials Science and Computational Chemistry. You are skilled at analyzing complex data sets, mapping out relationships within scientific communities, and understanding the intricate structures of research networks. You are adept at helping people identify key influencers, collaboration patterns, and the overall structure of the community of interest in these specialized fields.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not language:\n",
    "    reporter.info(\"Detecting language...\")\n",
    "    language = await detect_language(llm, doc_list)\n",
    "\n",
    "reporter.info(\"Generating persona...\")\n",
    "persona = await generate_persona(llm, domain)\n",
    "persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A float score between 0-10 that represents the relevance of the text to materials science and computational chemistry, focusing on the significance of the information for understanding chemical structures, properties, and predictive modeling, with 1 being trivial or irrelevant and 10 being highly significant, insightful, and impactful for advancing knowledge and research in the field.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_report_ranking = await generate_community_report_rating(\n",
    "        llm, domain=domain, persona=persona, docs=doc_list\n",
    "    )\n",
    "\n",
    "community_report_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Generating entity types...\n",
      "Entity types: 51\n",
      "chemical_structure,polymer,monomer,property,method,model,simulation,descriptor,interaction,dataset,algorithm,technique,tool,theory,representation,prediction,trend,confidence_interval,residual_plot,conductivity,interaction_parameter,potential,field_model,graph,hypergraph,node,edge,hyperedge,particle,force_field,energy_landscape,correlation_function,architecture,neural_network,fine_tuning,modality,Monte_Carlo,lattice,scission_energy,stereoregularity,tacticity,transition,functional_group,production_rule,generative_model,constraint,support_vector_machine,recurrent_neural_network,generative_adversarial_network,autoencoder,reinforcement_learning\n"
     ]
    }
   ],
   "source": [
    "entity_types = None\n",
    "\n",
    "if not skip_entity_types:\n",
    "    reporter.info(\"Generating entity types...\")\n",
    "    entity_types = await generate_entity_types(\n",
    "        llm,\n",
    "        domain=domain,\n",
    "        persona=persona,\n",
    "        docs=doc_list,\n",
    "        json_mode=config.llm.model_supports_json or False,\n",
    "    )\n",
    "\n",
    "    print(f\"Entity types: {len(entity_types)}\")\n",
    "    print(','.join(entity_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chemical_structure,polymer,monomer,property,method,model,simulation,descriptor,interaction,dataset,algorithm,technique,tool,theory,representation,prediction,trend,confidence_interval,residual_plot,conductivity,interaction_parameter,potential,field_model,graph,hypergraph,node,edge,hyperedge,particle,force_field,energy_landscape,correlation_function,architecture,neural_network,fine_tuning,modality,Monte_Carlo,lattice,scission_energy,stereoregularity,tacticity,transition,functional_group,production_rule,generative_model,constraint,support_vector_machine,recurrent_neural_network,generative_adversarial_network,autoencoder,reinforcement_learning\n"
     ]
    }
   ],
   "source": [
    "print(','.join(entity_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Generating entity relationship examples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'(\"entity\"{tuple_delimiter}MULTI-FIDELITY CO-KRIGING{tuple_delimiter}METHOD{tuple_delimiter}Multi-fidelity co-Kriging is a statistical method used to combine data from multiple sources of varying fidelity to improve prediction accuracy)\\n{record_delimiter}\\n{completion_delimiter}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter.info(\"Generating entity relationship examples...\")\n",
    "examples = await generate_entity_relationship_examples(\n",
    "    llm,\n",
    "    persona=persona,\n",
    "    entity_types=entity_types,\n",
    "    docs=doc_list,\n",
    "    language=language,\n",
    "    json_mode=False,  # config.llm.model_supports_json should be used, but this prompts are used in non-json by the index engine\n",
    ")\n",
    "\n",
    "print(f\"Examples: {len(examples)}\")\n",
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Generating entity extraction prompt...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n-Goal-\\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\\n\\n-Steps-\\n1. Identify all entities. For each identified entity, extract the following information:\\n- entity_name: Name of the entity, capitalized\\n- entity_type: One of the following types: [chemical_structure, polymer, monomer, property, method, model, simulation, descriptor, interaction, dataset, algorithm, technique, tool, theory, representation, prediction, trend, confidence_interval, residual_plot, conductivity, interaction_parameter, potential, field_model, graph, hypergraph, node, edge, hyperedge, particle, force_field, energy_landscape, correlation_function, architecture, neural_network, fine_tuning, modality, Monte_Carlo, lattice, scission_energy, stereoregularity, tacticity, transition, functional_group, production_rule, generative_model, constraint, support_vector_machine, recurrent_neural_network, generative_adversarial_network, autoencoder, reinforcement_learning]\\n- entity_description: Comprehensive description of the entity\\'s attributes and activities\\nFormat each entity as (\"entity\"{tuple_delimiter}<entity_name>{tuple_delimiter}<entity_type>{tuple_delimiter}<entity_description>)\\n\\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\\nFor each pair of related entities, extract the following information:\\n- source_entity: name of the source entity, as identified in step 1\\n- target_entity: name of the target entity, as identified in step 1\\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\\n- relationship_strength: an integer score between 1 to 10, indicating strength of the relationship between the source entity and target entity\\nFormat each relationship as (\"relationship\"{tuple_delimiter}<source_entity>{tuple_delimiter}<target_entity>{tuple_delimiter}<relationship_description>{tuple_delimiter}<relationship_strength>)\\n\\n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **{record_delimiter}** as the list delimiter.\\n\\n4. If you have to translate into English, just translate the descriptions, nothing else!\\n\\n5. When finished, output {completion_delimiter}.\\n\\n-Examples-\\n######################\\n\\nExample 1:\\n\\nentity_types: [chemical_structure, polymer, monomer, property, method, model, simulation, descriptor, interaction, dataset, algorithm, technique, tool, theory, representation, prediction, trend, confidence_interval, residual_plot, conductivity, interaction_parameter, potential, field_model, graph, hypergraph, node, edge, hyperedge, particle, force_field, energy_landscape, correlation_function, architecture, neural_network, fine_tuning, modality, Monte_Carlo, lattice, scission_energy, stereoregularity, tacticity, transition, functional_group, production_rule, generative_model, constraint, support_vector_machine, recurrent_neural_network, generative_adversarial_network, autoencoder, reinforcement_learning]\\ntext:\\n## b) Multi-fidelity co-Kriging\\n\\n\\n\\n\\n------------------------\\noutput:\\n(\"entity\"{tuple_delimiter}MULTI-FIDELITY CO-KRIGING{tuple_delimiter}METHOD{tuple_delimiter}Multi-fidelity co-Kriging is a statistical method used to combine data from multiple sources of varying fidelity to improve prediction accuracy)\\n{record_delimiter}\\n{completion_delimiter}\\n#############################\\n\\n\\nExample 2:\\n\\nentity_types: [chemical_structure, polymer, monomer, property, method, model, simulation, descriptor, interaction, dataset, algorithm, technique, tool, theory, representation, prediction, trend, confidence_interval, residual_plot, conductivity, interaction_parameter, potential, field_model, graph, hypergraph, node, edge, hyperedge, particle, force_field, energy_landscape, correlation_function, architecture, neural_network, fine_tuning, modality, Monte_Carlo, lattice, scission_energy, stereoregularity, tacticity, transition, functional_group, production_rule, generative_model, constraint, support_vector_machine, recurrent_neural_network, generative_adversarial_network, autoencoder, reinforcement_learning]\\ntext:\\n## A. Monomer/Oligomer scale: The scales of chemical specifity\\n\\n\\n\\nThe basic building blocks are the monomers. They can have a simple chemical structure, as in the case of many commodity polymers such as polystyrene, or a rather complicated structure, as in the case of biopolymers such as RNA, DNA, or proteins. The structure of the monomers on the monomer scale determines local properties such as the charges and the polarization, the solubility in a solvent [101], the existence and structure of a hydra- tion shell [102], the local affinity to surfaces [103], or - in studies of polymer reactions, the monomer re- activity [104]. In general, these properties are also influenced by the larger scale structure of polymer systems. For example, the effective monomer re- activity depends on the accessibility of the reactive sites, which is determined not only by the local elec- tronic and steric monomer structure, but also by the polymer conformation [104, 105]. Likewise, the ef- fective charges and/or polarization of monomers de- pend on the local environment [106, 107]. In most cases, however, the corrections due to the larger scale structure\\n------------------------\\noutput:\\n(\"entity\"{tuple_delimiter}MONOMER{tuple_delimiter}monomer{tuple_delimiter}The basic building blocks of polymers, which can have simple or complicated chemical structures, determining local properties such as charges, polarization, solubility, hydration shell structure, local affinity to surfaces, and reactivity)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}POLYSTYRENE{tuple_delimiter}polymer{tuple_delimiter}A commodity polymer with a simple chemical structure)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}RNA{tuple_delimiter}polymer{tuple_delimiter}A biopolymer with a complicated chemical structure)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}DNA{tuple_delimiter}polymer{tuple_delimiter}A biopolymer with a complicated chemical structure)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}PROTEINS{tuple_delimiter}polymer{tuple_delimiter}Biopolymers with complicated chemical structures)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}CHARGES{tuple_delimiter}property{tuple_delimiter}Local properties of monomers influenced by their structure)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}POLARIZATION{tuple_delimiter}property{tuple_delimiter}Local properties of monomers influenced by their structure)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}SOLUBILITY{tuple_delimiter}property{tuple_delimiter}Local property of monomers in a solvent)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}HYDRATION SHELL{tuple_delimiter}property{tuple_delimiter}The structure of a hydration shell around monomers)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}LOCAL AFFINITY TO SURFACES{tuple_delimiter}property{tuple_delimiter}The local affinity of monomers to surfaces)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}MONOMER REACTIVITY{tuple_delimiter}property{tuple_delimiter}The reactivity of monomers in polymer reactions)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}POLYMER CONFORMATION{tuple_delimiter}property{tuple_delimiter}The larger scale structure of polymer systems that influences monomer reactivity)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}POLYSTYRENE{tuple_delimiter}Polystyrene is an example of a monomer with a simple chemical structure{tuple_delimiter}8)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}RNA{tuple_delimiter}RNA is an example of a monomer with a complicated chemical structure{tuple_delimiter}8)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}DNA{tuple_delimiter}DNA is an example of a monomer with a complicated chemical structure{tuple_delimiter}8)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}PROTEINS{tuple_delimiter}Proteins are examples of monomers with complicated chemical structures{tuple_delimiter}8)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}CHARGES{tuple_delimiter}The structure of monomers determines their local properties such as charges{tuple_delimiter}7)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}POLARIZATION{tuple_delimiter}The structure of monomers determines their local properties such as polarization{tuple_delimiter}7)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}SOLUBILITY{tuple_delimiter}The structure of monomers determines their solubility in a solvent{tuple_delimiter}7)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}HYDRATION SHELL{tuple_delimiter}The structure of monomers determines the structure of their hydration shell{tuple_delimiter}7)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}LOCAL AFFINITY TO SURFACES{tuple_delimiter}The structure of monomers determines their local affinity to surfaces{tuple_delimiter}7)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}MONOMER REACTIVITY{tuple_delimiter}The structure of monomers determines their reactivity in polymer reactions{tuple_delimiter}7)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MONOMER{tuple_delimiter}POLYMER CONFORMATION{tuple_delimiter}The larger scale structure of polymer systems influences the effective monomer reactivity{tuple_delimiter}6)\\n{completion_delimiter}\\n#############################\\n\\n\\nExample 3:\\n\\nentity_types: [chemical_structure, polymer, monomer, property, method, model, simulation, descriptor, interaction, dataset, algorithm, technique, tool, theory, representation, prediction, trend, confidence_interval, residual_plot, conductivity, interaction_parameter, potential, field_model, graph, hypergraph, node, edge, hyperedge, particle, force_field, energy_landscape, correlation_function, architecture, neural_network, fine_tuning, modality, Monte_Carlo, lattice, scission_energy, stereoregularity, tacticity, transition, functional_group, production_rule, generative_model, constraint, support_vector_machine, recurrent_neural_network, generative_adversarial_network, autoencoder, reinforcement_learning]\\ntext:\\n predictions ( -- ) of the meta learner along with experimental data points (.) for Tg (blue), Tm (red) and Ta (green) of four selected copolymers across the entire composition range. The 95% confidence intervals of the predictions are shown as :selected:\\n\\nshaded bands. In all cases, there is a high level of agreement between predictions and experimental data points. Interestingly, the meta learner predicts averaged trends through the experimental data points. For example, in the case of copolymer (b), the predicted trend of Ta takes an averaged pathway through the scattered experimental data points across the range of the copolymer compositions. Also, the predicted trends display an appropriate level of smoothness, which indicates that the meta learner was regulated properly during training (we are using dropouts), thus avoiding both overfitting or underfitting. Another interesting finding is that the meta learner is capable of distilling key knowledge from the data set, as shown for Tm of polymer (b) in Figure 4: although no experimental data point is present at weight fraction 0, the meta learner predicts an upwards trend for Tm. This Tm trend is inferred from the Tg trend for the same polymer. Apparently, the data on which\\n------------------------\\noutput:\\n(\"entity\"{tuple_delimiter}PREDICTIONS{tuple_delimiter}PREDICTION{tuple_delimiter}Predictions made by the meta learner along with experimental data points for Tg, Tm, and Ta of four selected copolymers across the entire composition range)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}META LEARNER{tuple_delimiter}MODEL{tuple_delimiter}A model used to predict trends and distill key knowledge from the dataset, showing high agreement with experimental data points)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}EXPERIMENTAL DATA POINTS{tuple_delimiter}DATASET{tuple_delimiter}Data points used to compare with the predictions made by the meta learner for Tg, Tm, and Ta of copolymers)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}TG{tuple_delimiter}PROPERTY{tuple_delimiter}Glass transition temperature of the copolymers, represented in blue)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}TM{tuple_delimiter}PROPERTY{tuple_delimiter}Melting temperature of the copolymers, represented in red)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}TA{tuple_delimiter}PROPERTY{tuple_delimiter}Another temperature property of the copolymers, represented in green)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}COPOLYMERS{tuple_delimiter}POLYMER{tuple_delimiter}Four selected copolymers whose Tg, Tm, and Ta are predicted and compared with experimental data points)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}CONFIDENCE INTERVALS{tuple_delimiter}CONFIDENCE_INTERVAL{tuple_delimiter}The 95% confidence intervals of the predictions shown as shaded bands)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}TRENDS{tuple_delimiter}TREND{tuple_delimiter}Averaged trends predicted by the meta learner through the experimental data points)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}DATA SET{tuple_delimiter}DATASET{tuple_delimiter}The dataset from which the meta learner distills key knowledge)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}DROPOUTS{tuple_delimiter}TECHNIQUE{tuple_delimiter}A technique used during the training of the meta learner to avoid overfitting or underfitting)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}PREDICTIONS{tuple_delimiter}META LEARNER{tuple_delimiter}The meta learner makes predictions for Tg, Tm, and Ta of copolymers{tuple_delimiter}9)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}PREDICTIONS{tuple_delimiter}EXPERIMENTAL DATA POINTS{tuple_delimiter}Predictions are compared with experimental data points for validation{tuple_delimiter}8)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}META LEARNER{tuple_delimiter}TRENDS{tuple_delimiter}The meta learner predicts averaged trends through the experimental data points{tuple_delimiter}8)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}META LEARNER{tuple_delimiter}DROPOUTS{tuple_delimiter}Dropouts are used during the training of the meta learner to regulate it and avoid overfitting or underfitting{tuple_delimiter}7)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}TM{tuple_delimiter}TG{tuple_delimiter}The Tm trend is inferred from the Tg trend for the same polymer{tuple_delimiter}6)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}META LEARNER{tuple_delimiter}DATA SET{tuple_delimiter}The meta learner distills key knowledge from the dataset{tuple_delimiter}7)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}CONFIDENCE INTERVALS{tuple_delimiter}PREDICTIONS{tuple_delimiter}The 95% confidence intervals of the predictions are shown as shaded bands{tuple_delimiter}6)\\n{record_delimiter}\\n{completion_delimiter}\\n#############################\\n\\n\\nExample 4:\\n\\nentity_types: [chemical_structure, polymer, monomer, property, method, model, simulation, descriptor, interaction, dataset, algorithm, technique, tool, theory, representation, prediction, trend, confidence_interval, residual_plot, conductivity, interaction_parameter, potential, field_model, graph, hypergraph, node, edge, hyperedge, particle, force_field, energy_landscape, correlation_function, architecture, neural_network, fine_tuning, modality, Monte_Carlo, lattice, scission_energy, stereoregularity, tacticity, transition, functional_group, production_rule, generative_model, constraint, support_vector_machine, recurrent_neural_network, generative_adversarial_network, autoencoder, reinforcement_learning]\\ntext:\\n, the values of metrics in this case are also lesser than the model using both descriptors. Hence we can conclude that calculated descriptors also add value to the model. From these tests, we find that the R2 shows a value of > 0.9 in both calculated and learnt descriptor case. Therefore, if one is not interested in using the learnt descriptors in order to keep the model more explainable, then also a R2 ~ 0.92 can be attained using the calculated descriptors alone. Further, we also verify the fact that both learnt and calculated descriptors provide useful information as removing either reduces the values of all metrics. The high R2 value of 0.9949 for the model using both descriptors validates the idea that the configurational fingerprint adds value to the predictive capabilities of the model.\\n\\nThe residual curve is also plotted (Figure 3) to see differences between the actual and predicted values. The residual plot shows the ideal behaviour of being uniformly distributed around zero. Additionally, the residual plot shows that there are no correlations and most of the values lie between +0.2. Anomalously high value at X~75000 occurs because the position vector takes very large values in this case. It is a singular exceptional case when the MC simulation ends up taking very\\n------------------------\\noutput:\\n(\"entity\"{tuple_delimiter}MODEL{tuple_delimiter}model{tuple_delimiter}A computational framework used to predict outcomes based on input descriptors)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}DESCRIPTOR{tuple_delimiter}descriptor{tuple_delimiter}Calculated or learnt features that add value to the model\\'s predictive capabilities)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}R2{tuple_delimiter}property{tuple_delimiter}A statistical measure that represents the proportion of the variance for a dependent variable that\\'s explained by an independent variable or variables in a regression model)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}CONFIGURATIONAL FINGERPRINT{tuple_delimiter}descriptor{tuple_delimiter}A specific type of descriptor that adds value to the predictive capabilities of the model)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}RESIDUAL PLOT{tuple_delimiter}residual_plot{tuple_delimiter}A graphical representation showing the differences between actual and predicted values, ideally uniformly distributed around zero)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}MC SIMULATION{tuple_delimiter}Monte_Carlo{tuple_delimiter}A Monte Carlo simulation that ends up taking very large values in certain cases)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MODEL{tuple_delimiter}DESCRIPTOR{tuple_delimiter}Descriptors add value to the model\\'s predictive capabilities{tuple_delimiter}9)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MODEL{tuple_delimiter}R2{tuple_delimiter}The R2 value indicates the model\\'s accuracy, with values > 0.9 showing high accuracy{tuple_delimiter}8)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MODEL{tuple_delimiter}CONFIGURATIONAL FINGERPRINT{tuple_delimiter}The configurational fingerprint adds value to the predictive capabilities of the model{tuple_delimiter}8)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}RESIDUAL PLOT{tuple_delimiter}MODEL{tuple_delimiter}The residual plot is used to evaluate the differences between actual and predicted values of the model{tuple_delimiter}7)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}MC SIMULATION{tuple_delimiter}RESIDUAL PLOT{tuple_delimiter}Anomalously high values in the residual plot occur due to the position vector taking very large values in the MC simulation{tuple_delimiter}6)\\n{completion_delimiter}\\n#############################\\n\\n\\nExample 5:\\n\\nentity_types: [chemical_structure, polymer, monomer, property, method, model, simulation, descriptor, interaction, dataset, algorithm, technique, tool, theory, representation, prediction, trend, confidence_interval, residual_plot, conductivity, interaction_parameter, potential, field_model, graph, hypergraph, node, edge, hyperedge, particle, force_field, energy_landscape, correlation_function, architecture, neural_network, fine_tuning, modality, Monte_Carlo, lattice, scission_energy, stereoregularity, tacticity, transition, functional_group, production_rule, generative_model, constraint, support_vector_machine, recurrent_neural_network, generative_adversarial_network, autoencoder, reinforcement_learning]\\ntext:\\n270\\n\\n1.313\\n\\n1.501\\n\\n1.206 (+/-) 0.197\\n\\n1.517 (+/-) 0.101 1.605 (+/-) 0. 054\\n\\n(+/-) 0.256\\n\\n(+/-) 0.244\\n\\n(+/-) 0.115 (+/-) 0.124\\n\\n\\n\\n||lonic|||Conductivity||(S/cm)|||\\n|---|---|---|---|---|---|---|---|---|\\n||0.0000 0.0005||0.0010||0.0015|0.0020||0.0025|\\n||||||||||\\n|***|||||||||\\n|*SCCC*|||||||||\\n|*C(C)N*|||||||||\\n------------------------\\noutput:\\n(\"entity\"{tuple_delimiter}IONIC CONDUCTIVITY{tuple_delimiter}conductivity{tuple_delimiter}Ionic conductivity is a measure of a material\\'s ability to conduct an electric current through the movement of ions, typically measured in S/cm)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}SCCC{tuple_delimiter}chemical_structure{tuple_delimiter}SCCC is a chemical structure notation, possibly representing a specific molecular configuration)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}C(C)N{tuple_delimiter}chemical_structure{tuple_delimiter}C(C)N is a chemical structure notation, possibly representing a specific molecular configuration)\\n{record_delimiter}\\n(\"entity\"{tuple_delimiter}CONFIDENCE INTERVAL{tuple_delimiter}confidence_interval{tuple_delimiter}Confidence interval is a range of values that is likely to contain the true value of an unknown population parameter, expressed with a certain level of confidence)\\n{record_delimiter}\\n(\"relationship\"{tuple_delimiter}IONIC CONDUCTIVITY{tuple_delimiter}CONFIDENCE INTERVAL{tuple_delimiter}The confidence interval provides a range within which the true value of the ionic conductivity is expected to fall{tuple_delimiter}7)\\n{completion_delimiter}\\n#############################\\n\\n\\n\\n-Real Data-\\n######################\\nentity_types: [chemical_structure, polymer, monomer, property, method, model, simulation, descriptor, interaction, dataset, algorithm, technique, tool, theory, representation, prediction, trend, confidence_interval, residual_plot, conductivity, interaction_parameter, potential, field_model, graph, hypergraph, node, edge, hyperedge, particle, force_field, energy_landscape, correlation_function, architecture, neural_network, fine_tuning, modality, Monte_Carlo, lattice, scission_energy, stereoregularity, tacticity, transition, functional_group, production_rule, generative_model, constraint, support_vector_machine, recurrent_neural_network, generative_adversarial_network, autoencoder, reinforcement_learning]\\ntext: {input_text}\\n######################\\noutput:'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter.info(\"Generating entity extraction prompt...\")\n",
    "entity_extraction_prompt = create_entity_extraction_prompt(\n",
    "    entity_types=entity_types,\n",
    "    docs=doc_list,\n",
    "    examples=examples,\n",
    "    language=language,\n",
    "    json_mode=False,  # config.llm.model_supports_json should be used, but these prompts are used in non-json by the index engine\n",
    "    encoding_model=config.encoding_model,\n",
    "    max_token_count=max_tokens,\n",
    "    min_examples_required=min_examples_required,\n",
    ")\n",
    "\n",
    "entity_extraction_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Generating entity summarization prompt...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nYou are an expert in Materials Science and Computational Chemistry. You are skilled at analyzing complex data sets, mapping out relationships within scientific communities, and understanding the intricate structures of research networks. You are adept at helping people identify key influencers, collaboration patterns, and the overall structure of the community of interest in these specialized fields.\\nUsing your expertise, you're asked to generate a comprehensive summary of the data provided below.\\nGiven one or two entities, and a list of descriptions, all related to the same entity or group of entities.\\nPlease concatenate all of these into a single, concise description in English. Make sure to include information collected from all the descriptions.\\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\\nMake sure it is written in third person, and include the entity names so we have the full context.\\n\\nEnrich it as much as you can with relevant information from the nearby text, this is very important.\\n\\nIf no answer is possible, or the description is empty, only convey information that is provided within the text.\\n#######\\n-Data-\\nEntities: {entity_name}\\nDescription List: {description_list}\\n#######\\nOutput:\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter.info(\"Generating entity summarization prompt...\")\n",
    "entity_summarization_prompt = create_entity_summarization_prompt(\n",
    "    persona=persona,\n",
    "    language=language,\n",
    ")\n",
    "\n",
    "entity_summarization_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Generating community reporter role...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A community analyst that is examining the field of Materials Science and Computational Chemistry, given a list of entities that belong to the community as well as their relationships and optional associated claims. The analysis will be used to inform decision-makers about key influencers, collaboration patterns, and the overall structure of the community, as well as significant developments and their potential impact.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter.info(\"Generating community reporter role...\")\n",
    "community_reporter_role = await generate_community_reporter_role(\n",
    "    llm, domain=domain, persona=persona, docs=doc_list\n",
    ")\n",
    "\n",
    "community_reporter_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Generating community summarization prompt...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou are an expert in Materials Science and Computational Chemistry. You are skilled at analyzing complex data sets, mapping out relationships within scientific communities, and understanding the intricate structures of research networks. You are adept at helping people identify key influencers, collaboration patterns, and the overall structure of the community of interest in these specialized fields.\\n\\n# Goal\\nWrite a comprehensive assessment report of a community taking on the role of a A community analyst that is examining the field of Materials Science and Computational Chemistry, given a list of entities that belong to the community as well as their relationships and optional associated claims. The analysis will be used to inform decision-makers about key influencers, collaboration patterns, and the overall structure of the community, as well as significant developments and their potential impact.. The content of this report includes an overview of the community\\'s key entities and relationships.\\n\\n# Report Structure\\nThe report should include the following sections:\\n- TITLE: community\\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\\n- SUMMARY: An executive summary of the community\\'s overall structure, how its entities are related to each other, and significant points associated with its entities.\\n- REPORT RATING: A float score between 0-10 that represents the relevance of the text to materials science and computational chemistry, focusing on the significance of the information for understanding chemical structures, properties, and predictive modeling, with 1 being trivial or irrelevant and 10 being highly significant, insightful, and impactful for advancing knowledge and research in the field.\\n- RATING EXPLANATION: Give a single sentence explanation of the rating.\\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\\n\\nReturn output as a well-formed JSON-formatted string with the following format. Don\\'t use any unnecessary escape sequences. The output should be a single JSON object that can be parsed by json.loads.\\n    {\\n        \"title\": \"<report_title>\",\\n        \"summary\": \"<executive_summary>\",\\n        \"rating\": <threat_severity_rating>,\\n        \"rating_explanation\": \"<rating_explanation>\"\\n        \"findings\": \"[{\"summary\":\"<insight_1_summary>\", \"explanation\": \"<insight_1_explanation\"}, {\"summary\":\"<insight_2_summary>\", \"explanation\": \"<insight_2_explanation\"}]\"\\n    }\\n\\n# Grounding Rules\\nAfter each paragraph, add data record reference if the content of the paragraph was derived from one or more data records. Reference is in the format of [records: <record_source> (<record_id_list>, ...<record_source> (<record_id_list>)]. If there are more than 10 data records, show the top 10 most relevant records.\\nEach paragraph should contain multiple sentences of explanation and concrete examples with specific named entities. All paragraphs must have these references at the start and end. Use \"NONE\" if there are no related roles or records. Everything should be in English.\\n\\nExample paragraph with references added:\\nThis is a paragraph of the output text [records: Entities (1, 2, 3), Claims (2, 5), Relationships (10, 12)]\\n\\n# Example Input\\n-----------\\nText:\\n\\nEntities\\n\\nid,entity,description\\n5,ABILA CITY PARK,Abila City Park is the location of the POK rally\\n\\nRelationships\\n\\nid,source,target,description\\n37,ABILA CITY PARK,POK RALLY,Abila City Park is the location of the POK rally\\n38,ABILA CITY PARK,POK,POK is holding a rally in Abila City Park\\n39,ABILA CITY PARK,POKRALLY,The POKRally is taking place at Abila City Park\\n40,ABILA CITY PARK,CENTRAL BULLETIN,Central Bulletin is reporting on the POK rally taking place in Abila City Park\\n\\nOutput:\\n{\\n    \"title\": \"Abila City Park and POK Rally\",\\n    \"summary\": \"The community revolves around the Abila City Park, which is the location of the POK rally. The park has relationships with POK, POKRALLY, and Central Bulletin, all\\nof which are associated with the rally event.\",\\n    \"rating\": 5.0,\\n    \"rating_explanation\": \"The impact rating is moderate due to the potential for unrest or conflict during the POK rally.\",\\n    \"findings\": [\\n        {\\n            \"summary\": \"Abila City Park as the central location\",\\n            \"explanation\": \"Abila City Park is the central entity in this community, serving as the location for the POK rally. This park is the common link between all other\\nentities, suggesting its significance in the community. The park\\'s association with the rally could potentially lead to issues such as public disorder or conflict, depending on the\\nnature of the rally and the reactions it provokes. [records: Entities (5), Relationships (37, 38, 39, 40)]\"\\n        },\\n        {\\n            \"summary\": \"POK\\'s role in the community\",\\n            \"explanation\": \"POK is another key entity in this community, being the organizer of the rally at Abila City Park. The nature of POK and its rally could be a potential\\nsource of threat, depending on their objectives and the reactions they provoke. The relationship between POK and the park is crucial in understanding the dynamics of this community.\\n[records: Relationships (38)]\"\\n        },\\n        {\\n            \"summary\": \"POKRALLY as a significant event\",\\n            \"explanation\": \"The POKRALLY is a significant event taking place at Abila City Park. This event is a key factor in the community\\'s dynamics and could be a potential\\nsource of threat, depending on the nature of the rally and the reactions it provokes. The relationship between the rally and the park is crucial in understanding the dynamics of this\\ncommunity. [records: Relationships (39)]\"\\n        },\\n        {\\n            \"summary\": \"Role of Central Bulletin\",\\n            \"explanation\": \"Central Bulletin is reporting on the POK rally taking place in Abila City Park. This suggests that the event has attracted media attention, which could\\namplify its impact on the community. The role of Central Bulletin could be significant in shaping public perception of the event and the entities involved. [records: Relationships\\n(40)]\"\\n        }\\n    ]\\n\\n}\\n\\n# Real Data\\n\\nUse the following text for your answer. Do not make anything up in your answer.\\n\\nText:\\n{input_text}\\nOutput:'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter.info(\"Generating community summarization prompt...\")\n",
    "community_summarization_prompt = create_community_summarization_prompt(\n",
    "    persona=persona,\n",
    "    role=community_reporter_role,\n",
    "    report_rating_description=community_report_ranking,\n",
    "    language=language,\n",
    ")\n",
    "\n",
    "community_summarization_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Writing prompts to prompts\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "output_path = Path(output)\n",
    "if output_path:\n",
    "    reporter.info(f\"Writing prompts to {output_path}\")\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    entity_extraction_prompt_path = output_path / ENTITY_EXTRACTION_FILENAME\n",
    "    entity_summarization_prompt_path = output_path / ENTITY_SUMMARIZATION_FILENAME\n",
    "    community_summarization_prompt_path = (\n",
    "        output_path / COMMUNITY_SUMMARIZATION_FILENAME\n",
    "    )\n",
    "    # Write files to output path\n",
    "    with entity_extraction_prompt_path.open(\"wb\") as file:\n",
    "        file.write(entity_extraction_prompt.encode(encoding=\"utf-8\", errors=\"strict\"))\n",
    "    with entity_summarization_prompt_path.open(\"wb\") as file:\n",
    "        file.write(entity_summarization_prompt.encode(encoding=\"utf-8\", errors=\"strict\"))\n",
    "    with community_summarization_prompt_path.open(\"wb\") as file:\n",
    "        file.write(community_summarization_prompt.encode(encoding=\"utf-8\", errors=\"strict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoget",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
