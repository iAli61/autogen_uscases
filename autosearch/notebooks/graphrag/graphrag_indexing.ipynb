{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from graphrag.config import create_graphrag_config\n",
    "from graphrag.config.config_file_loader import (\n",
    "    load_config_from_file,\n",
    "    resolve_config_path_with_root,\n",
    ")\n",
    "from graphrag.config.enums import CacheType\n",
    "from graphrag.config.logging import enable_logging_with_config\n",
    "\n",
    "from graphrag.index.api import build_index\n",
    "from graphrag.index.graph.extractors.claims.prompts import CLAIM_EXTRACTION_PROMPT\n",
    "from graphrag.index.graph.extractors.community_reports.prompts import COMMUNITY_REPORT_PROMPT\n",
    "from graphrag.index.graph.extractors.graph.prompts import GRAPH_EXTRACTION_PROMPT\n",
    "from graphrag.index.graph.extractors.summarize.prompts import SUMMARIZE_PROMPT\n",
    "from graphrag.index.init_content import INIT_DOTENV, INIT_YAML\n",
    "from graphrag.index.progress import ProgressReporter\n",
    "from graphrag.index.progress.load_progress_reporter import load_progress_reporter\n",
    "from graphrag.index.validate_config import validate_config_names\n",
    "\n",
    "# Ignore warnings from numba\n",
    "warnings.filterwarnings(\"ignore\", message=\".*NumbaDeprecationWarning.*\")\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = \"/home/azureuser/autogen_uscases/autosearch/notebooks/graphrag\"\n",
    "config = \"settings.yaml\"\n",
    "init = False\n",
    "verbose = True\n",
    "resume = None,\n",
    "memprofile = True\n",
    "nocache = False\n",
    "reporter = None\n",
    "config = None\n",
    "emit = None\n",
    "dryrun = False\n",
    "overlay_defaults = False\n",
    "skip_validations = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _redact(input: dict) -> str:\n",
    "    \"\"\"Sanitize the config json.\"\"\"\n",
    "\n",
    "    # Redact any sensitive configuration\n",
    "    def redact_dict(input: dict) -> dict:\n",
    "        if not isinstance(input, dict):\n",
    "            return input\n",
    "\n",
    "        result = {}\n",
    "        for key, value in input.items():\n",
    "            if key in {\n",
    "                \"api_key\",\n",
    "                \"connection_string\",\n",
    "                \"container_name\",\n",
    "                \"organization\",\n",
    "            }:\n",
    "                if value is not None:\n",
    "                    result[key] = \"==== REDACTED ====\"\n",
    "            elif isinstance(value, dict):\n",
    "                result[key] = redact_dict(value)\n",
    "            elif isinstance(value, list):\n",
    "                result[key] = [redact_dict(i) for i in value]\n",
    "            else:\n",
    "                result[key] = value\n",
    "        return result\n",
    "\n",
    "    redacted_dict = redact_dict(input)\n",
    "    return json.dumps(redacted_dict, indent=4)\n",
    "\n",
    "def _logger(reporter: ProgressReporter):\n",
    "    def info(msg: str, verbose: bool = False):\n",
    "        log.info(msg)\n",
    "        if verbose:\n",
    "            reporter.info(msg)\n",
    "\n",
    "    def error(msg: str, verbose: bool = False):\n",
    "        log.error(msg)\n",
    "        if verbose:\n",
    "            reporter.error(msg)\n",
    "\n",
    "    def success(msg: str, verbose: bool = False):\n",
    "        log.info(msg)\n",
    "        if verbose:\n",
    "            reporter.success(msg)\n",
    "\n",
    "    return info, error, success\n",
    "\n",
    "\n",
    "def _register_signal_handlers(reporter: ProgressReporter):\n",
    "    import signal\n",
    "\n",
    "    def handle_signal(signum, _):\n",
    "        # Handle the signal here\n",
    "        # reporter.info(f\"Received signal {signum}, exiting...\")\n",
    "        reporter.dispose()\n",
    "        for task in asyncio.all_tasks():\n",
    "            task.cancel()\n",
    "        # reporter.info(\"All tasks cancelled. Exiting...\")\n",
    "\n",
    "    # Register signal handlers for SIGINT and SIGHUP\n",
    "    signal.signal(signal.SIGINT, handle_signal)\n",
    "\n",
    "    if sys.platform != \"win32\":\n",
    "        signal.signal(signal.SIGHUP, handle_signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run the pipeline with the given config.\"\"\"\n",
    "progress_reporter = None\n",
    "# info, error, success = _logger(progress_reporter)\n",
    "run_id = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if overlay_defaults or config:\n",
    "    config_path = (\n",
    "        Path(root) / config if config else resolve_config_path_with_root(root)\n",
    "    )\n",
    "    default_config = load_config_from_file(config_path)\n",
    "else:\n",
    "    try:\n",
    "        config_path = resolve_config_path_with_root(root)\n",
    "        default_config = load_config_from_file(config_path)\n",
    "    except FileNotFoundError:\n",
    "        default_config = create_graphrag_config(root_dir=root)\n",
    "\n",
    "if nocache:\n",
    "    default_config.cache.type = CacheType.none\n",
    "\n",
    "enabled_logging = None\n",
    "# if enabled_logging:\n",
    "#     info(f\"Logging enabled at {log_path}\", True)\n",
    "# else:\n",
    "#     info(\n",
    "#         f\"Logging not enabled for config {_redact(default_config.model_dump())}\",\n",
    "#         True,\n",
    "#     )\n",
    "\n",
    "if skip_validations:\n",
    "    validate_config_names(progress_reporter, default_config)\n",
    "\n",
    "# info(f\"Starting pipeline run for: {run_id}, {dryrun=}\", verbose)\n",
    "# info(\n",
    "#     f\"Using default configuration: {_redact(default_config.model_dump())}\",\n",
    "#     verbose,\n",
    "# )\n",
    "\n",
    "# if dryrun:\n",
    "#     info(\"Dry run complete, exiting...\", True)\n",
    "#     sys.exit(0)\n",
    "\n",
    "pipeline_emit = emit.split(\",\") if emit else None\n",
    "\n",
    "# _register_signal_handlers(progress_reporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"llm\": {\n",
      "        \"api_key\": \"==== REDACTED ====\",\n",
      "        \"type\": \"azure_openai_chat\",\n",
      "        \"model\": \"gpt-4o\",\n",
      "        \"max_tokens\": 4000,\n",
      "        \"temperature\": 0.0,\n",
      "        \"top_p\": 1.0,\n",
      "        \"n\": 1,\n",
      "        \"request_timeout\": 180.0,\n",
      "        \"api_base\": \"https://aoai-sweden-505.openai.azure.com/\",\n",
      "        \"api_version\": \"2023-08-01-preview\",\n",
      "        \"proxy\": null,\n",
      "        \"cognitive_services_endpoint\": null,\n",
      "        \"deployment_name\": \"gpt-4o\",\n",
      "        \"model_supports_json\": true,\n",
      "        \"tokens_per_minute\": 0,\n",
      "        \"requests_per_minute\": 0,\n",
      "        \"max_retries\": 10,\n",
      "        \"max_retry_wait\": 10.0,\n",
      "        \"sleep_on_rate_limit_recommendation\": true,\n",
      "        \"concurrent_requests\": 25\n",
      "    },\n",
      "    \"parallelization\": {\n",
      "        \"stagger\": 0.3,\n",
      "        \"num_threads\": 50\n",
      "    },\n",
      "    \"async_mode\": \"threaded\",\n",
      "    \"root_dir\": \"/home/azureuser/autogen_uscases/autosearch/notebooks/graphrag\",\n",
      "    \"reporting\": {\n",
      "        \"type\": \"file\",\n",
      "        \"base_dir\": \"output/${timestamp}/reports\",\n",
      "        \"storage_account_blob_url\": null\n",
      "    },\n",
      "    \"storage\": {\n",
      "        \"type\": \"file\",\n",
      "        \"base_dir\": \"output/${timestamp}/artifacts\",\n",
      "        \"storage_account_blob_url\": null\n",
      "    },\n",
      "    \"cache\": {\n",
      "        \"type\": \"file\",\n",
      "        \"base_dir\": \"cache\",\n",
      "        \"storage_account_blob_url\": null\n",
      "    },\n",
      "    \"input\": {\n",
      "        \"type\": \"file\",\n",
      "        \"file_type\": \"csv\",\n",
      "        \"base_dir\": \"input\",\n",
      "        \"storage_account_blob_url\": null,\n",
      "        \"encoding\": \"utf-8\",\n",
      "        \"file_pattern\": \".*\\\\.csv$\",\n",
      "        \"file_filter\": null,\n",
      "        \"source_column\": \"url\",\n",
      "        \"timestamp_column\": \"last_updated_date\",\n",
      "        \"timestamp_format\": \"%Y-%m-%dT%H:%M:%S%z\",\n",
      "        \"text_column\": \"page_content\",\n",
      "        \"title_column\": \"title\",\n",
      "        \"document_attribute_columns\": []\n",
      "    },\n",
      "    \"embed_graph\": {\n",
      "        \"enabled\": true,\n",
      "        \"num_walks\": 10,\n",
      "        \"walk_length\": 40,\n",
      "        \"window_size\": 2,\n",
      "        \"iterations\": 3,\n",
      "        \"random_seed\": 597832,\n",
      "        \"strategy\": null\n",
      "    },\n",
      "    \"embeddings\": {\n",
      "        \"llm\": {\n",
      "            \"api_key\": \"==== REDACTED ====\",\n",
      "            \"type\": \"azure_openai_embedding\",\n",
      "            \"model\": \"text-embedding-3-small\",\n",
      "            \"max_tokens\": 4000,\n",
      "            \"temperature\": 0,\n",
      "            \"top_p\": 1,\n",
      "            \"n\": 1,\n",
      "            \"request_timeout\": 180.0,\n",
      "            \"api_base\": \"https://aoai-gpt4-505.openai.azure.com\",\n",
      "            \"api_version\": \"2024-02-15-preview\",\n",
      "            \"proxy\": null,\n",
      "            \"cognitive_services_endpoint\": null,\n",
      "            \"deployment_name\": \"text-embedding-3-small\",\n",
      "            \"model_supports_json\": null,\n",
      "            \"tokens_per_minute\": 0,\n",
      "            \"requests_per_minute\": 0,\n",
      "            \"max_retries\": 10,\n",
      "            \"max_retry_wait\": 10.0,\n",
      "            \"sleep_on_rate_limit_recommendation\": true,\n",
      "            \"concurrent_requests\": 25\n",
      "        },\n",
      "        \"parallelization\": {\n",
      "            \"stagger\": 0.3,\n",
      "            \"num_threads\": 50\n",
      "        },\n",
      "        \"async_mode\": \"threaded\",\n",
      "        \"batch_size\": 16,\n",
      "        \"batch_max_tokens\": 8191,\n",
      "        \"target\": \"required\",\n",
      "        \"skip\": [],\n",
      "        \"vector_store\": null,\n",
      "        \"strategy\": null\n",
      "    },\n",
      "    \"chunks\": {\n",
      "        \"size\": 1200,\n",
      "        \"overlap\": 10,\n",
      "        \"group_by_columns\": [\n",
      "            \"id\"\n",
      "        ],\n",
      "        \"strategy\": null,\n",
      "        \"encoding_model\": null\n",
      "    },\n",
      "    \"snapshots\": {\n",
      "        \"graphml\": true,\n",
      "        \"raw_entities\": true,\n",
      "        \"top_level_nodes\": true\n",
      "    },\n",
      "    \"entity_extraction\": {\n",
      "        \"llm\": {\n",
      "            \"api_key\": \"==== REDACTED ====\",\n",
      "            \"type\": \"azure_openai_chat\",\n",
      "            \"model\": \"gpt-4o\",\n",
      "            \"max_tokens\": 4000,\n",
      "            \"temperature\": 0.0,\n",
      "            \"top_p\": 1.0,\n",
      "            \"n\": 1,\n",
      "            \"request_timeout\": 180.0,\n",
      "            \"api_base\": \"https://aoai-sweden-505.openai.azure.com/\",\n",
      "            \"api_version\": \"2023-08-01-preview\",\n",
      "            \"proxy\": null,\n",
      "            \"cognitive_services_endpoint\": null,\n",
      "            \"deployment_name\": \"gpt-4o\",\n",
      "            \"model_supports_json\": true,\n",
      "            \"tokens_per_minute\": 0,\n",
      "            \"requests_per_minute\": 0,\n",
      "            \"max_retries\": 10,\n",
      "            \"max_retry_wait\": 10.0,\n",
      "            \"sleep_on_rate_limit_recommendation\": true,\n",
      "            \"concurrent_requests\": 25\n",
      "        },\n",
      "        \"parallelization\": {\n",
      "            \"stagger\": 0.3,\n",
      "            \"num_threads\": 50\n",
      "        },\n",
      "        \"async_mode\": \"threaded\",\n",
      "        \"prompt\": \"prompts/entity_extraction.txt\",\n",
      "        \"entity_types\": [\n",
      "            \"chemical_structure\",\n",
      "            \"polymer\",\n",
      "            \"monomer\",\n",
      "            \"property\",\n",
      "            \"method\",\n",
      "            \"model\",\n",
      "            \"simulation\",\n",
      "            \"descriptor\",\n",
      "            \"interaction\",\n",
      "            \"dataset\",\n",
      "            \"algorithm\",\n",
      "            \"technique\",\n",
      "            \"tool\",\n",
      "            \"theory\",\n",
      "            \"representation\",\n",
      "            \"prediction\",\n",
      "            \"trend\",\n",
      "            \"confidence_interval\",\n",
      "            \"residual_plot\",\n",
      "            \"conductivity\",\n",
      "            \"interaction_parameter\",\n",
      "            \"potential\",\n",
      "            \"field_model\",\n",
      "            \"hypergraph\",\n",
      "            \"particle\",\n",
      "            \"force_field\",\n",
      "            \"energy_landscape\",\n",
      "            \"correlation_function\",\n",
      "            \"architecture\",\n",
      "            \"neural_network\",\n",
      "            \"fine_tuning\",\n",
      "            \"modality\",\n",
      "            \"Monte_Carlo\",\n",
      "            \"lattice\",\n",
      "            \"energy\",\n",
      "            \"stereoregularity\",\n",
      "            \"tacticity\",\n",
      "            \"transition\",\n",
      "            \"functional_group\",\n",
      "            \"measurement\",\n",
      "            \"generative_model\",\n",
      "            \"constraint\",\n",
      "            \"quantum_calculation\",\n",
      "            \"generative_adversarial_network\",\n",
      "            \"autoencoder\",\n",
      "            \"reinforcement_learning\"\n",
      "        ],\n",
      "        \"max_gleanings\": 1,\n",
      "        \"strategy\": null,\n",
      "        \"encoding_model\": null\n",
      "    },\n",
      "    \"summarize_descriptions\": {\n",
      "        \"llm\": {\n",
      "            \"api_key\": \"==== REDACTED ====\",\n",
      "            \"type\": \"azure_openai_chat\",\n",
      "            \"model\": \"gpt-4o\",\n",
      "            \"max_tokens\": 4000,\n",
      "            \"temperature\": 0.0,\n",
      "            \"top_p\": 1.0,\n",
      "            \"n\": 1,\n",
      "            \"request_timeout\": 180.0,\n",
      "            \"api_base\": \"https://aoai-sweden-505.openai.azure.com/\",\n",
      "            \"api_version\": \"2023-08-01-preview\",\n",
      "            \"proxy\": null,\n",
      "            \"cognitive_services_endpoint\": null,\n",
      "            \"deployment_name\": \"gpt-4o\",\n",
      "            \"model_supports_json\": true,\n",
      "            \"tokens_per_minute\": 0,\n",
      "            \"requests_per_minute\": 0,\n",
      "            \"max_retries\": 10,\n",
      "            \"max_retry_wait\": 10.0,\n",
      "            \"sleep_on_rate_limit_recommendation\": true,\n",
      "            \"concurrent_requests\": 25\n",
      "        },\n",
      "        \"parallelization\": {\n",
      "            \"stagger\": 0.3,\n",
      "            \"num_threads\": 50\n",
      "        },\n",
      "        \"async_mode\": \"threaded\",\n",
      "        \"prompt\": \"prompts/summarize_descriptions.txt\",\n",
      "        \"max_length\": 500,\n",
      "        \"strategy\": null\n",
      "    },\n",
      "    \"community_reports\": {\n",
      "        \"llm\": {\n",
      "            \"api_key\": \"==== REDACTED ====\",\n",
      "            \"type\": \"azure_openai_chat\",\n",
      "            \"model\": \"gpt-4o\",\n",
      "            \"max_tokens\": 4000,\n",
      "            \"temperature\": 0.0,\n",
      "            \"top_p\": 1.0,\n",
      "            \"n\": 1,\n",
      "            \"request_timeout\": 180.0,\n",
      "            \"api_base\": \"https://aoai-sweden-505.openai.azure.com/\",\n",
      "            \"api_version\": \"2023-08-01-preview\",\n",
      "            \"proxy\": null,\n",
      "            \"cognitive_services_endpoint\": null,\n",
      "            \"deployment_name\": \"gpt-4o\",\n",
      "            \"model_supports_json\": true,\n",
      "            \"tokens_per_minute\": 0,\n",
      "            \"requests_per_minute\": 0,\n",
      "            \"max_retries\": 10,\n",
      "            \"max_retry_wait\": 10.0,\n",
      "            \"sleep_on_rate_limit_recommendation\": true,\n",
      "            \"concurrent_requests\": 25\n",
      "        },\n",
      "        \"parallelization\": {\n",
      "            \"stagger\": 0.3,\n",
      "            \"num_threads\": 50\n",
      "        },\n",
      "        \"async_mode\": \"threaded\",\n",
      "        \"prompt\": \"prompts/community_report.txt\",\n",
      "        \"max_length\": 2000,\n",
      "        \"max_input_length\": 8000,\n",
      "        \"strategy\": null\n",
      "    },\n",
      "    \"claim_extraction\": {\n",
      "        \"llm\": {\n",
      "            \"api_key\": \"==== REDACTED ====\",\n",
      "            \"type\": \"azure_openai_chat\",\n",
      "            \"model\": \"gpt-4o\",\n",
      "            \"max_tokens\": 4000,\n",
      "            \"temperature\": 0.0,\n",
      "            \"top_p\": 1.0,\n",
      "            \"n\": 1,\n",
      "            \"request_timeout\": 180.0,\n",
      "            \"api_base\": \"https://aoai-sweden-505.openai.azure.com/\",\n",
      "            \"api_version\": \"2023-08-01-preview\",\n",
      "            \"proxy\": null,\n",
      "            \"cognitive_services_endpoint\": null,\n",
      "            \"deployment_name\": \"gpt-4o\",\n",
      "            \"model_supports_json\": true,\n",
      "            \"tokens_per_minute\": 0,\n",
      "            \"requests_per_minute\": 0,\n",
      "            \"max_retries\": 10,\n",
      "            \"max_retry_wait\": 10.0,\n",
      "            \"sleep_on_rate_limit_recommendation\": true,\n",
      "            \"concurrent_requests\": 25\n",
      "        },\n",
      "        \"parallelization\": {\n",
      "            \"stagger\": 0.3,\n",
      "            \"num_threads\": 50\n",
      "        },\n",
      "        \"async_mode\": \"threaded\",\n",
      "        \"enabled\": false,\n",
      "        \"prompt\": \"prompts/claim_extraction.txt\",\n",
      "        \"description\": \"Any claims or facts that could be relevant to information discovery.\",\n",
      "        \"max_gleanings\": 1,\n",
      "        \"strategy\": null,\n",
      "        \"encoding_model\": null\n",
      "    },\n",
      "    \"cluster_graph\": {\n",
      "        \"max_cluster_size\": 10,\n",
      "        \"strategy\": null\n",
      "    },\n",
      "    \"umap\": {\n",
      "        \"enabled\": true\n",
      "    },\n",
      "    \"local_search\": {\n",
      "        \"text_unit_prop\": 0.5,\n",
      "        \"community_prop\": 0.1,\n",
      "        \"conversation_history_max_turns\": 5,\n",
      "        \"top_k_entities\": 10,\n",
      "        \"top_k_relationships\": 10,\n",
      "        \"temperature\": 0.0,\n",
      "        \"top_p\": 1.0,\n",
      "        \"n\": 1,\n",
      "        \"max_tokens\": 12000,\n",
      "        \"llm_max_tokens\": 2000\n",
      "    },\n",
      "    \"global_search\": {\n",
      "        \"temperature\": 0.0,\n",
      "        \"top_p\": 1.0,\n",
      "        \"n\": 1,\n",
      "        \"max_tokens\": 12000,\n",
      "        \"data_max_tokens\": 12000,\n",
      "        \"map_max_tokens\": 1000,\n",
      "        \"reduce_max_tokens\": 2000,\n",
      "        \"concurrency\": 32\n",
      "    },\n",
      "    \"encoding_model\": \"cl100k_base\",\n",
      "    \"skip_workflows\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(_redact(default_config.model_dump()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/autoget/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 60 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 60 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 60 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 60 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 60 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 55 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 48 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 47 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 47 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 46 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 44 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 44 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 44 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 41 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 55 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 55 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 49 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 44 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 35 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 60 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 60 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 60 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 48 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 48 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 47 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 45 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 42 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 55 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 49 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 49 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 46 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 46 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 44 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 43 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 36 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 55 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 49 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 48 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 41 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 34 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 31 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 55 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 46 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 45 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 44 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 43 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 43 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 42 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 39 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 34 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 55 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 55 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 49 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 48 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 47 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 45 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 43 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 55 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 49 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 48 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 48 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 37 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 35 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 59 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 54 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 49 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 48 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 47 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 46 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 43 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 40 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 37 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 58 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 57 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 56 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 55 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 53 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 10/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 10/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 10/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 10/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 51 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 50 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 49 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 49 seconds. Follow recommendation? True\n",
      "extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 47 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 46 seconds. Follow recommendation? True\n",
      "Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 46 seconds. Follow recommendation? True\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py:147\u001b[0m, in \u001b[0;36mRateLimitingLLM.__call__.<locals>.do_attempt\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delegate(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py:49\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke_json(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py:53\u001b[0m, in \u001b[0;36mBaseLLM._invoke\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_llm(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LLMOutput(output\u001b[38;5;241m=\u001b[39moutput)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/openai/openai_chat_llm.py:53\u001b[0m, in \u001b[0;36mOpenAIChatLLM._execute_llm\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;241m*\u001b[39mhistory,\n\u001b[1;32m     51\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m},\n\u001b[1;32m     52\u001b[0m ]\n\u001b[0;32m---> 53\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     54\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py:1339\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1338\u001b[0m validate_response_format(response_format)\n\u001b[0;32m-> 1339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1341\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m   1342\u001b[0m         {\n\u001b[1;32m   1343\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   1344\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   1345\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   1346\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   1347\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   1348\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   1349\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   1350\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   1351\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   1352\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   1354\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   1355\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   1356\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   1357\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   1358\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   1359\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   1360\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   1361\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   1362\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   1363\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   1364\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   1365\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   1366\u001b[0m         },\n\u001b[1;32m   1367\u001b[0m         completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m   1368\u001b[0m     ),\n\u001b[1;32m   1369\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   1370\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1371\u001b[0m     ),\n\u001b[1;32m   1372\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   1373\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1374\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[1;32m   1375\u001b[0m )\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py:1816\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1813\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1814\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1815\u001b[0m )\n\u001b[0;32m-> 1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py:1510\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m   1502\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1503\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1511\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1512\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1513\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1514\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1515\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[1;32m   1516\u001b[0m     )\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py:1611\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1610\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1614\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1615\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1620\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-08-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 52 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m build_index(\n\u001b[1;32m      2\u001b[0m         default_config,\n\u001b[1;32m      3\u001b[0m         run_id,\n\u001b[1;32m      4\u001b[0m         memprofile,\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m         pipeline_emit,\n\u001b[1;32m      7\u001b[0m     )\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/index/api.py:63\u001b[0m, in \u001b[0;36mbuild_index\u001b[0;34m(config, run_id, memory_profile, progress_reporter, emit)\u001b[0m\n\u001b[1;32m     59\u001b[0m pipeline_cache \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     NoopPipelineCache() \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m CacheType\u001b[38;5;241m.\u001b[39mnone \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     62\u001b[0m outputs: \u001b[38;5;28mlist\u001b[39m[PipelineRunResult] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m run_pipeline_with_config(\n\u001b[1;32m     64\u001b[0m     pipeline_config,\n\u001b[1;32m     65\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[1;32m     66\u001b[0m     memory_profile\u001b[38;5;241m=\u001b[39mmemory_profile,\n\u001b[1;32m     67\u001b[0m     cache\u001b[38;5;241m=\u001b[39mpipeline_cache,\n\u001b[1;32m     68\u001b[0m     progress_reporter\u001b[38;5;241m=\u001b[39mprogress_reporter,\n\u001b[1;32m     69\u001b[0m     emit\u001b[38;5;241m=\u001b[39m([TableEmitterType(e) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m emit] \u001b[38;5;28;01mif\u001b[39;00m emit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m     70\u001b[0m     is_resume_run\u001b[38;5;241m=\u001b[39mresume,\n\u001b[1;32m     71\u001b[0m ):\n\u001b[1;32m     72\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m progress_reporter:\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/index/run.py:154\u001b[0m, in \u001b[0;36mrun_pipeline_with_config\u001b[0;34m(config_or_path, workflows, dataset, storage, cache, callbacks, progress_reporter, input_post_process_steps, additional_verbs, additional_workflows, emit, memory_profile, run_id, is_resume_run, **_kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo dataset provided!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m run_pipeline(\n\u001b[1;32m    155\u001b[0m     workflows\u001b[38;5;241m=\u001b[39mworkflows,\n\u001b[1;32m    156\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m    157\u001b[0m     storage\u001b[38;5;241m=\u001b[39mstorage,\n\u001b[1;32m    158\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m    159\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    160\u001b[0m     input_post_process_steps\u001b[38;5;241m=\u001b[39mpost_process_steps,\n\u001b[1;32m    161\u001b[0m     memory_profile\u001b[38;5;241m=\u001b[39mmemory_profile,\n\u001b[1;32m    162\u001b[0m     additional_verbs\u001b[38;5;241m=\u001b[39madditional_verbs,\n\u001b[1;32m    163\u001b[0m     additional_workflows\u001b[38;5;241m=\u001b[39madditional_workflows,\n\u001b[1;32m    164\u001b[0m     progress_reporter\u001b[38;5;241m=\u001b[39mprogress_reporter,\n\u001b[1;32m    165\u001b[0m     emit\u001b[38;5;241m=\u001b[39memit,\n\u001b[1;32m    166\u001b[0m     is_resume_run\u001b[38;5;241m=\u001b[39mis_resume_run,\n\u001b[1;32m    167\u001b[0m ):\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m table\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/index/run.py:325\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(workflows, dataset, storage, cache, callbacks, progress_reporter, input_post_process_steps, additional_verbs, additional_workflows, emit, memory_profile, is_resume_run, **_kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m inject_workflow_data_dependencies(workflow)\n\u001b[1;32m    324\u001b[0m workflow_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 325\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m workflow\u001b[38;5;241m.\u001b[39mrun(context, callbacks)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m write_workflow_stats(workflow, result, workflow_start_time)\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Save the output from the workflow\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/datashaper/workflow/workflow.py:369\u001b[0m, in \u001b[0;36mWorkflow.run\u001b[0;34m(self, context, callbacks)\u001b[0m\n\u001b[1;32m    367\u001b[0m current_id \u001b[38;5;241m=\u001b[39m nodes\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    368\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph[current_id]\n\u001b[0;32m--> 369\u001b[0m timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_verb(node, context, callbacks)\n\u001b[1;32m    370\u001b[0m verb_timings\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    371\u001b[0m     VerbTiming(\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39mnode_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m     )\n\u001b[1;32m    377\u001b[0m )\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# move to the next verb\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/datashaper/workflow/workflow.py:415\u001b[0m, in \u001b[0;36mWorkflow._execute_verb\u001b[0;34m(self, node, context, callbacks)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;66;03m# Unroll the result if it's a coroutine\u001b[39;00m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# (we need to do this before calling on_step_end)\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39miscoroutine(result):\n\u001b[0;32m--> 415\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    417\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError executing verb \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;241m.\u001b[39mverb\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/index/verbs/entities/extraction/entity_extract.py:161\u001b[0m, in \u001b[0;36mentity_extract\u001b[0;34m(input, cache, callbacks, column, id_column, to, strategy, graph_to, async_mode, entity_types, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     num_started \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [result\u001b[38;5;241m.\u001b[39mentities, result\u001b[38;5;241m.\u001b[39mgraphml_graph]\n\u001b[0;32m--> 161\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m derive_from_rows(\n\u001b[1;32m    162\u001b[0m     output,\n\u001b[1;32m    163\u001b[0m     run_strategy,\n\u001b[1;32m    164\u001b[0m     callbacks,\n\u001b[1;32m    165\u001b[0m     scheduling_type\u001b[38;5;241m=\u001b[39masync_mode,\n\u001b[1;32m    166\u001b[0m     num_threads\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    169\u001b[0m to_result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    170\u001b[0m graph_to_result \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/datashaper/execution/derive_from_rows.py:33\u001b[0m, in \u001b[0;36mderive_from_rows\u001b[0;34m(input, transform, callbacks, num_threads, scheduling_type)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m derive_from_rows_asyncio(\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28minput\u001b[39m, transform, callbacks, num_threads\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m AsyncType\u001b[38;5;241m.\u001b[39mThreaded:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m derive_from_rows_asyncio_threads(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28minput\u001b[39m, transform, callbacks, num_threads\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported scheduling type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduling_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/datashaper/execution/derive_from_rows_asyncio_threads.py:40\u001b[0m, in \u001b[0;36mderive_from_rows_asyncio_threads\u001b[0;34m(input, transform, callbacks, num_threads)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m thread\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[execute_task(task) \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks])\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m derive_from_rows_base(\u001b[38;5;28minput\u001b[39m, transform, callbacks, gather)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/datashaper/execution/derive_from_rows_base.py:49\u001b[0m, in \u001b[0;36mderive_from_rows_base\u001b[0;34m(input, transform, callbacks, gather)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         tick(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m gather(execute)\n\u001b[1;32m     51\u001b[0m tick\u001b[38;5;241m.\u001b[39mdone()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m error, stack \u001b[38;5;129;01min\u001b[39;00m errors:\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/datashaper/execution/derive_from_rows_asyncio_threads.py:38\u001b[0m, in \u001b[0;36mderive_from_rows_asyncio_threads.<locals>.gather\u001b[0;34m(execute)\u001b[0m\n\u001b[1;32m     35\u001b[0m         thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m thread\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[execute_task(task) \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks])\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/asyncio/tasks.py:385\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/asyncio/tasks.py:316\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    314\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/datashaper/execution/derive_from_rows_asyncio_threads.py:36\u001b[0m, in \u001b[0;36mderive_from_rows_asyncio_threads.<locals>.gather.<locals>.execute_task\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# fire off the thread\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m thread\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/datashaper/execution/derive_from_rows_base.py:39\u001b[0m, in \u001b[0;36mderive_from_rows_base.<locals>.execute\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     37\u001b[0m     result \u001b[38;5;241m=\u001b[39m transform(row[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39miscoroutine(result):\n\u001b[0;32m---> 39\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     logging\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel transformation error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/index/verbs/entities/extraction/entity_extract.py:151\u001b[0m, in \u001b[0;36mentity_extract.<locals>.run_strategy\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    149\u001b[0m text \u001b[38;5;241m=\u001b[39m row[column]\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m row[id_column]\n\u001b[0;32m--> 151\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m strategy_exec(\n\u001b[1;32m    152\u001b[0m     [Document(text\u001b[38;5;241m=\u001b[39mtext, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m)],\n\u001b[1;32m    153\u001b[0m     entity_types,\n\u001b[1;32m    154\u001b[0m     callbacks,\n\u001b[1;32m    155\u001b[0m     cache,\n\u001b[1;32m    156\u001b[0m     strategy_config,\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    158\u001b[0m num_started \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [result\u001b[38;5;241m.\u001b[39mentities, result\u001b[38;5;241m.\u001b[39mgraphml_graph]\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/index/verbs/entities/extraction/strategies/graph_intelligence/run_graph_intelligence.py:41\u001b[0m, in \u001b[0;36mrun_gi\u001b[0;34m(docs, entity_types, reporter, pipeline_cache, args)\u001b[0m\n\u001b[1;32m     39\u001b[0m llm_type \u001b[38;5;241m=\u001b[39m llm_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, LLMType\u001b[38;5;241m.\u001b[39mStaticResponse)\n\u001b[1;32m     40\u001b[0m llm \u001b[38;5;241m=\u001b[39m load_llm(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity_extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m, llm_type, reporter, pipeline_cache, llm_config)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_extract_entities(llm, docs, entity_types, reporter, args)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/index/verbs/entities/extraction/strategies/graph_intelligence/run_graph_intelligence.py:88\u001b[0m, in \u001b[0;36mrun_extract_entities\u001b[0;34m(llm, docs, entity_types, reporter, args)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prechunked:\n\u001b[1;32m     86\u001b[0m     text_list \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text_list))\n\u001b[0;32m---> 88\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m extractor(\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mlist\u001b[39m(text_list),\n\u001b[1;32m     90\u001b[0m     {\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity_types\u001b[39m\u001b[38;5;124m\"\u001b[39m: entity_types,\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuple_delimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: tuple_delimiter,\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecord_delimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: record_delimiter,\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion_delimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: completion_delimiter,\n\u001b[1;32m     95\u001b[0m     },\n\u001b[1;32m     96\u001b[0m )\n\u001b[1;32m     98\u001b[0m graph \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39moutput\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Map the \"source_id\" back to the \"id\" field\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py:122\u001b[0m, in \u001b[0;36mGraphExtractor.__call__\u001b[0;34m(self, texts, prompt_variables)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc_index, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(texts):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;66;03m# Invoke the entity extraction\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_document(text, prompt_variables)\n\u001b[1;32m    123\u001b[0m         source_doc_map[doc_index] \u001b[38;5;241m=\u001b[39m text\n\u001b[1;32m    124\u001b[0m         all_records[doc_index] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py:161\u001b[0m, in \u001b[0;36mGraphExtractor._process_document\u001b[0;34m(self, text, prompt_variables)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Repeat to ensure we maximize entity count\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_gleanings):\n\u001b[0;32m--> 161\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm(\n\u001b[1;32m    162\u001b[0m         CONTINUE_PROMPT,\n\u001b[1;32m    163\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextract-continuation-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    164\u001b[0m         history\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mhistory,\n\u001b[1;32m    165\u001b[0m     )\n\u001b[1;32m    166\u001b[0m     results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# if this is the final glean, don't bother updating the continuation flag\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/openai/json_parsing_llm.py:34\u001b[0m, in \u001b[0;36mJsonParsingLLM.__call__\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28minput\u001b[39m: CompletionInput,\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[LLMInput],\n\u001b[1;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMOutput[CompletionOutput]:\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the LLM with the input and kwargs.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delegate(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mjson \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m         _, parsed_json \u001b[38;5;241m=\u001b[39m try_parse_json_object(result\u001b[38;5;241m.\u001b[39moutput)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py:37\u001b[0m, in \u001b[0;36mOpenAITokenReplacingLLM.__call__\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m history \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m perform_variable_replacements(\u001b[38;5;28minput\u001b[39m, history, variables)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delegate(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py:33\u001b[0m, in \u001b[0;36mOpenAIHistoryTrackingLLM.__call__\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the LLM.\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m history \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m---> 33\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delegate(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMOutput(\n\u001b[1;32m     35\u001b[0m     output\u001b[38;5;241m=\u001b[39moutput\u001b[38;5;241m.\u001b[39moutput,\n\u001b[1;32m     36\u001b[0m     json\u001b[38;5;241m=\u001b[39moutput\u001b[38;5;241m.\u001b[39mjson,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     ],\n\u001b[1;32m     42\u001b[0m )\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/base/caching_llm.py:96\u001b[0m, in \u001b[0;36mCachingLLM.__call__\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_cache_miss(cache_key, name)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Compute the new result\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delegate(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Cache the new result\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py:177\u001b[0m, in \u001b[0;36mRateLimitingLLM.__call__\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_semaphore:\n\u001b[0;32m--> 177\u001b[0m         result, start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m execute_with_retry()\n\u001b[1;32m    179\u001b[0m end \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    180\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount_response_tokens(result\u001b[38;5;241m.\u001b[39moutput)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py:159\u001b[0m, in \u001b[0;36mRateLimitingLLM.__call__.<locals>.execute_with_retry\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_with_retry\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[LLMOutput[TOut], \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m attempt_number\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m retryer:\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m attempt:\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_limiter \u001b[38;5;129;01mand\u001b[39;00m input_tokens \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:166\u001b[0m, in \u001b[0;36mAsyncRetrying.__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__anext__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AttemptManager:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m         do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_state)\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m do \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:153\u001b[0m, in \u001b[0;36mAsyncRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py:99\u001b[0m, in \u001b[0;36mwrap_to_async_func.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py:165\u001b[0m, in \u001b[0;36mRateLimitingLLM.__call__.<locals>.execute_with_retry\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m         start \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    164\u001b[0m         attempt_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m do_attempt(), start\n\u001b[1;32m    167\u001b[0m log\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetries exhausted for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m RetriesExhaustedError(name, max_retries)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py:151\u001b[0m, in \u001b[0;36mRateLimitingLLM.__call__.<locals>.do_attempt\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_limit_errors)):\n\u001b[1;32m    150\u001b[0m         sleep_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_sleep_recommendation(e)\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m sleep_for(sleep_time)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py:140\u001b[0m, in \u001b[0;36mRateLimitingLLM.__call__.<locals>.sleep_for\u001b[0;34m(time)\u001b[0m\n\u001b[1;32m    131\u001b[0m log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failed to invoke LLM \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m attempts. Cause: rate limit exceeded, will retry. Recommended sleep for \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m seconds. Follow recommendation? \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     follow_recommendation,\n\u001b[1;32m    138\u001b[0m )\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_recommendation \u001b[38;5;129;01mand\u001b[39;00m time:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(time)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/asyncio/tasks.py:665\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    661\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[1;32m    662\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[1;32m    663\u001b[0m                     future, result)\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    667\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/asyncio/futures.py:287\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/asyncio/tasks.py:385\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m/anaconda/envs/autoget/lib/python3.12/asyncio/futures.py:198\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m _CANCELLED:\n\u001b[1;32m    197\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_cancelled_error()\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m!=\u001b[39m _FINISHED:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mInvalidStateError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult is not ready.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outputs = await build_index(\n",
    "        default_config,\n",
    "        run_id,\n",
    "        memprofile,\n",
    "        None,\n",
    "        pipeline_emit,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoget",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
