{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosearch.agents.graphrag_search import GraphragSearch\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Dict\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "\"\"\"\n",
    "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
    "\n",
    "Model name\n",
    "Year introduced\n",
    "Key authors/research group\n",
    "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
    "Input features used\n",
    "Dimensionality of the learned representation\n",
    "Training data type and size\n",
    "Key applications (e.g., property prediction, polymer design)\n",
    "Notable advantages\n",
    "Limitations or challenges\n",
    "\n",
    "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
    "\n",
    "A table comparing at least 5 different models, with the following information for each:\n",
    "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
    "b) Year introduced\n",
    "c) Key authors/research group\n",
    "d) Input features or representation used\n",
    "e) Dataset size and composition\n",
    "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
    "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
    "h) Computational complexity or training time (if available)\n",
    "A brief discussion (2-3 paragraphs) on:\n",
    "a) The overall trends in prediction accuracy for Tg vs Tm\n",
    "b) Factors that contribute to higher accuracy in certain models\n",
    "c) Challenges in predicting these properties accurately\n",
    "d) Recent advancements or novel approaches in the field\n",
    "A short section on potential areas for improvement and future research directions.\n",
    "\n",
    "Please provide citations for the models and studies mentioned in your analysis.\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "models = ['gpt-4', 'gpt-4o', 'gpt-4o-mini', 'gpt-35-turbo', 'gpt-35-turbo-16k']\n",
    "\n",
    "# input_dir = '/home/azureuser/autogen_uscases/graphrag_memo/output/20240830-145930/artifacts'\n",
    "input_dir = '/home/azureuser/autogen_uscases/autosearch/notebooks/graphrag/output/20240903-050706/artifacts'\n",
    "# input_dir = '/home/azureuser/autogen_uscases/graphrag_memo/output/20240830-145930/artifacts'\n",
    "lancedb_uri = \"/home/azureuser/autogen_uscases/autosearch/notebooks/graphrag/output/20240903-050706/artifacts/lancedb\"\n",
    "embedding_model = 'text-embedding-3-small'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "import concurrent.futures\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "\n",
    "def run_searches(searcher, q):\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    local_result, global_result = loop.run_until_complete(asyncio.gather(\n",
    "        searcher.local_search(query=q),\n",
    "        searcher.global_search(query=q)\n",
    "    ))\n",
    "    loop.close()\n",
    "    return local_result, global_result\n",
    "\n",
    "def process_model(m, questions, input_dir, lancedb_uri, embedding_model):\n",
    "    print(f\"Model: {m}\")\n",
    "    config = {\n",
    "        \"GRAPHRAG_LLM_MODEL\": m,\n",
    "        \"GRAPHRAG_LLM_DEPLOYMENT_NAME\": m,\n",
    "        \"GRAPHRAG_EMBEDDING_DEPLOYMENT_NAME\": embedding_model,\n",
    "        \"GRAPHRAG_EMBEDDING_MODEL\": embedding_model,\n",
    "    }\n",
    "    searcher = GraphragSearch(\n",
    "        input_dir=input_dir,\n",
    "        lancedb_uri=lancedb_uri,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    model_results = []\n",
    "    for q in questions:\n",
    "        print(f\"Question: {q}\")\n",
    "        local_result, global_result = run_searches(searcher, q)\n",
    "        model_results.append({\n",
    "            \"question\": q,\n",
    "            \"model\": m,\n",
    "            \"local_result\": local_result.response,\n",
    "            \"global_result\": global_result.response,\n",
    "            \"global_llm_tokens\": global_result.prompt_token,\n",
    "            \"global_llm_calls\": global_result.llm_calls\n",
    "\n",
    "        })\n",
    "        print(f\"Completed: Question: {q}, Model: {m}\")\n",
    "    \n",
    "    return model_results\n",
    "\n",
    "def eval_models(questions: List[str], models: List[str], input_dir: str, lancedb_uri: str, embedding_model: str, number_workers: int):\n",
    "    results = []\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=number_workers) as executor:\n",
    "        future_to_model = {executor.submit(process_model, m, questions, input_dir, lancedb_uri, embedding_model): m for m in models}\n",
    "        for future in concurrent.futures.as_completed(future_to_model):\n",
    "            model = future_to_model[future]\n",
    "            try:\n",
    "                model_results = future.result()\n",
    "                results.extend(model_results)\n",
    "            except Exception as exc:\n",
    "                print(f'{model} generated an exception: {exc}')\n",
    "\n",
    "    # Generate a unique filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f'results_{timestamp}.json'\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/indexer_adapters.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].fillna(-1)\n",
      "/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/indexer_adapters.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
      "\n",
      "Model name\n",
      "Year introduced\n",
      "Key authors/research group\n",
      "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
      "Input features used\n",
      "Dimensionality of the learned representation\n",
      "Training data type and size\n",
      "Key applications (e.g., property prediction, polymer design)\n",
      "Notable advantages\n",
      "Limitations or challenges\n",
      "\n",
      "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Question: \n",
      "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
      "\n",
      "Model name\n",
      "Year introduced\n",
      "Key authors/research group\n",
      "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
      "Input features used\n",
      "Dimensionality of the learned representation\n",
      "Training data type and size\n",
      "Key applications (e.g., property prediction, polymer design)\n",
      "Notable advantages\n",
      "Limitations or challenges\n",
      "\n",
      "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
      ", Model: gpt-4\n",
      "Question: \n",
      "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
      "\n",
      "A table comparing at least 5 different models, with the following information for each:\n",
      "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
      "b) Year introduced\n",
      "c) Key authors/research group\n",
      "d) Input features or representation used\n",
      "e) Dataset size and composition\n",
      "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
      "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
      "h) Computational complexity or training time (if available)\n",
      "A brief discussion (2-3 paragraphs) on:\n",
      "a) The overall trends in prediction accuracy for Tg vs Tm\n",
      "b) Factors that contribute to higher accuracy in certain models\n",
      "c) Challenges in predicting these properties accurately\n",
      "d) Recent advancements or novel approaches in the field\n",
      "A short section on potential areas for improvement and future research directions.\n",
      "\n",
      "Please provide citations for the models and studies mentioned in your analysis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No community records added when building community context.\n",
      "Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Question: \n",
      "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
      "\n",
      "A table comparing at least 5 different models, with the following information for each:\n",
      "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
      "b) Year introduced\n",
      "c) Key authors/research group\n",
      "d) Input features or representation used\n",
      "e) Dataset size and composition\n",
      "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
      "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
      "h) Computational complexity or training time (if available)\n",
      "A brief discussion (2-3 paragraphs) on:\n",
      "a) The overall trends in prediction accuracy for Tg vs Tm\n",
      "b) Factors that contribute to higher accuracy in certain models\n",
      "c) Challenges in predicting these properties accurately\n",
      "d) Recent advancements or novel approaches in the field\n",
      "A short section on potential areas for improvement and future research directions.\n",
      "\n",
      "Please provide citations for the models and studies mentioned in your analysis.\n",
      ", Model: gpt-4\n",
      "Model: gpt-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/indexer_adapters.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].fillna(-1)\n",
      "/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/indexer_adapters.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
      "\n",
      "Model name\n",
      "Year introduced\n",
      "Key authors/research group\n",
      "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
      "Input features used\n",
      "Dimensionality of the learned representation\n",
      "Training data type and size\n",
      "Key applications (e.g., property prediction, polymer design)\n",
      "Notable advantages\n",
      "Limitations or challenges\n",
      "\n",
      "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Error parsing search response json - skipping this batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Question: \n",
      "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
      "\n",
      "Model name\n",
      "Year introduced\n",
      "Key authors/research group\n",
      "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
      "Input features used\n",
      "Dimensionality of the learned representation\n",
      "Training data type and size\n",
      "Key applications (e.g., property prediction, polymer design)\n",
      "Notable advantages\n",
      "Limitations or challenges\n",
      "\n",
      "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
      ", Model: gpt-4o\n",
      "Question: \n",
      "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
      "\n",
      "A table comparing at least 5 different models, with the following information for each:\n",
      "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
      "b) Year introduced\n",
      "c) Key authors/research group\n",
      "d) Input features or representation used\n",
      "e) Dataset size and composition\n",
      "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
      "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
      "h) Computational complexity or training time (if available)\n",
      "A brief discussion (2-3 paragraphs) on:\n",
      "a) The overall trends in prediction accuracy for Tg vs Tm\n",
      "b) Factors that contribute to higher accuracy in certain models\n",
      "c) Challenges in predicting these properties accurately\n",
      "d) Recent advancements or novel approaches in the field\n",
      "A short section on potential areas for improvement and future research directions.\n",
      "\n",
      "Please provide citations for the models and studies mentioned in your analysis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No community records added when building community context.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Question: \n",
      "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
      "\n",
      "A table comparing at least 5 different models, with the following information for each:\n",
      "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
      "b) Year introduced\n",
      "c) Key authors/research group\n",
      "d) Input features or representation used\n",
      "e) Dataset size and composition\n",
      "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
      "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
      "h) Computational complexity or training time (if available)\n",
      "A brief discussion (2-3 paragraphs) on:\n",
      "a) The overall trends in prediction accuracy for Tg vs Tm\n",
      "b) Factors that contribute to higher accuracy in certain models\n",
      "c) Challenges in predicting these properties accurately\n",
      "d) Recent advancements or novel approaches in the field\n",
      "A short section on potential areas for improvement and future research directions.\n",
      "\n",
      "Please provide citations for the models and studies mentioned in your analysis.\n",
      ", Model: gpt-4o\n",
      "Model: gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/indexer_adapters.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].fillna(-1)\n",
      "/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/indexer_adapters.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
      "\n",
      "Model name\n",
      "Year introduced\n",
      "Key authors/research group\n",
      "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
      "Input features used\n",
      "Dimensionality of the learned representation\n",
      "Training data type and size\n",
      "Key applications (e.g., property prediction, polymer design)\n",
      "Notable advantages\n",
      "Limitations or challenges\n",
      "\n",
      "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in _asearch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/local_search/search.py\", line 83, in asearch\n",
      "    response = await self.llm.agenerate(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Question: \n",
      "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
      "\n",
      "Model name\n",
      "Year introduced\n",
      "Key authors/research group\n",
      "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
      "Input features used\n",
      "Dimensionality of the learned representation\n",
      "Training data type and size\n",
      "Key applications (e.g., property prediction, polymer design)\n",
      "Notable advantages\n",
      "Limitations or challenges\n",
      "\n",
      "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
      ", Model: gpt-4o-mini\n",
      "Question: \n",
      "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
      "\n",
      "A table comparing at least 5 different models, with the following information for each:\n",
      "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
      "b) Year introduced\n",
      "c) Key authors/research group\n",
      "d) Input features or representation used\n",
      "e) Dataset size and composition\n",
      "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
      "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
      "h) Computational complexity or training time (if available)\n",
      "A brief discussion (2-3 paragraphs) on:\n",
      "a) The overall trends in prediction accuracy for Tg vs Tm\n",
      "b) Factors that contribute to higher accuracy in certain models\n",
      "c) Challenges in predicting these properties accurately\n",
      "d) Recent advancements or novel approaches in the field\n",
      "A short section on potential areas for improvement and future research directions.\n",
      "\n",
      "Please provide citations for the models and studies mentioned in your analysis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No community records added when building community context.\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _asearch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/local_search/search.py\", line 83, in asearch\n",
      "    response = await self.llm.agenerate(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1573, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1643, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'code': 'OperationNotSupported', 'message': 'The chatCompletion operation does not work with the specified model, gpt-4o-mini. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.'}}\n",
      "Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Question: \n",
      "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
      "\n",
      "A table comparing at least 5 different models, with the following information for each:\n",
      "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
      "b) Year introduced\n",
      "c) Key authors/research group\n",
      "d) Input features or representation used\n",
      "e) Dataset size and composition\n",
      "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
      "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
      "h) Computational complexity or training time (if available)\n",
      "A brief discussion (2-3 paragraphs) on:\n",
      "a) The overall trends in prediction accuracy for Tg vs Tm\n",
      "b) Factors that contribute to higher accuracy in certain models\n",
      "c) Challenges in predicting these properties accurately\n",
      "d) Recent advancements or novel approaches in the field\n",
      "A short section on potential areas for improvement and future research directions.\n",
      "\n",
      "Please provide citations for the models and studies mentioned in your analysis.\n",
      ", Model: gpt-4o-mini\n",
      "Model: gpt-35-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/indexer_adapters.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].fillna(-1)\n",
      "/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/indexer_adapters.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
      "\n",
      "Model name\n",
      "Year introduced\n",
      "Key authors/research group\n",
      "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
      "Input features used\n",
      "Dimensionality of the learned representation\n",
      "Training data type and size\n",
      "Key applications (e.g., property prediction, polymer design)\n",
      "Notable advantages\n",
      "Limitations or challenges\n",
      "\n",
      "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-547' coro=<AsyncClient.aclose() done, defined at /anaconda/envs/autoget/lib/python3.12/site-packages/httpx/_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/httpx/_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/httpx/_transports/default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 55, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/anyio/streams/tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 1202, in aclose\n",
      "    self._transport.close()\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/asyncio/selector_events.py\", line 1210, in close\n",
      "    super().close()\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/asyncio/selector_events.py\", line 875, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/asyncio/base_events.py\", line 795, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/asyncio/base_events.py\", line 541, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Question: \n",
      "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
      "\n",
      "Model name\n",
      "Year introduced\n",
      "Key authors/research group\n",
      "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
      "Input features used\n",
      "Dimensionality of the learned representation\n",
      "Training data type and size\n",
      "Key applications (e.g., property prediction, polymer design)\n",
      "Notable advantages\n",
      "Limitations or challenges\n",
      "\n",
      "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
      ", Model: gpt-35-turbo\n",
      "Question: \n",
      "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
      "\n",
      "A table comparing at least 5 different models, with the following information for each:\n",
      "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
      "b) Year introduced\n",
      "c) Key authors/research group\n",
      "d) Input features or representation used\n",
      "e) Dataset size and composition\n",
      "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
      "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
      "h) Computational complexity or training time (if available)\n",
      "A brief discussion (2-3 paragraphs) on:\n",
      "a) The overall trends in prediction accuracy for Tg vs Tm\n",
      "b) Factors that contribute to higher accuracy in certain models\n",
      "c) Challenges in predicting these properties accurately\n",
      "d) Recent advancements or novel approaches in the field\n",
      "A short section on potential areas for improvement and future research directions.\n",
      "\n",
      "Please provide citations for the models and studies mentioned in your analysis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No community records added when building community context.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Question: \n",
      "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
      "\n",
      "A table comparing at least 5 different models, with the following information for each:\n",
      "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
      "b) Year introduced\n",
      "c) Key authors/research group\n",
      "d) Input features or representation used\n",
      "e) Dataset size and composition\n",
      "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
      "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
      "h) Computational complexity or training time (if available)\n",
      "A brief discussion (2-3 paragraphs) on:\n",
      "a) The overall trends in prediction accuracy for Tg vs Tm\n",
      "b) Factors that contribute to higher accuracy in certain models\n",
      "c) Challenges in predicting these properties accurately\n",
      "d) Recent advancements or novel approaches in the field\n",
      "A short section on potential areas for improvement and future research directions.\n",
      "\n",
      "Please provide citations for the models and studies mentioned in your analysis.\n",
      ", Model: gpt-35-turbo\n",
      "Model: gpt-35-turbo-16k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/indexer_adapters.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].fillna(-1)\n",
      "/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/indexer_adapters.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entity_df[\"community\"] = entity_df[\"community\"].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
      "\n",
      "Model name\n",
      "Year introduced\n",
      "Key authors/research group\n",
      "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
      "Input features used\n",
      "Dimensionality of the learned representation\n",
      "Training data type and size\n",
      "Key applications (e.g., property prediction, polymer design)\n",
      "Notable advantages\n",
      "Limitations or challenges\n",
      "\n",
      "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Question: \n",
      "Create a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\n",
      "\n",
      "Model name\n",
      "Year introduced\n",
      "Key authors/research group\n",
      "Type of representation (e.g., graph-based, sequence-based, 3D structure-based)\n",
      "Input features used\n",
      "Dimensionality of the learned representation\n",
      "Training data type and size\n",
      "Key applications (e.g., property prediction, polymer design)\n",
      "Notable advantages\n",
      "Limitations or challenges\n",
      "\n",
      "After the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\n",
      ", Model: gpt-35-turbo-16k\n",
      "Question: \n",
      "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
      "\n",
      "A table comparing at least 5 different models, with the following information for each:\n",
      "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
      "b) Year introduced\n",
      "c) Key authors/research group\n",
      "d) Input features or representation used\n",
      "e) Dataset size and composition\n",
      "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
      "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
      "h) Computational complexity or training time (if available)\n",
      "A brief discussion (2-3 paragraphs) on:\n",
      "a) The overall trends in prediction accuracy for Tg vs Tm\n",
      "b) Factors that contribute to higher accuracy in certain models\n",
      "c) Challenges in predicting these properties accurately\n",
      "d) Recent advancements or novel approaches in the field\n",
      "A short section on potential areas for improvement and future research directions.\n",
      "\n",
      "Please provide citations for the models and studies mentioned in your analysis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No community records added when building community context.\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Exception in _map_response_single_batch\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/structured_search/global_search/search.py\", line 214, in _map_response_single_batch\n",
      "    search_response = await self.llm.agenerate(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 142, in agenerate\n",
      "    async for attempt in retryer:\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 144, in agenerate\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/graphrag/query/llm/oai/chat_openai.py\", line 268, in _agenerate\n",
      "    response = await self.async_client.chat.completions.create(  # type: ignore\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1339, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1816, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1510, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/anaconda/envs/autoget/lib/python3.12/site-packages/openai/_base_client.py\", line 1611, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid parameter: 'response_format' of type 'json_object' is not supported with this model.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}\n",
      "Warning: All map responses have score 0 (i.e., no relevant information found from the dataset), returning a canned 'I do not know' answer. You can try enabling `allow_general_knowledge` to encourage the LLM to incorporate relevant general knowledge, at the risk of increasing hallucinations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: Question: \n",
      "Create a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\n",
      "\n",
      "A table comparing at least 5 different models, with the following information for each:\n",
      "a) Model name and type (e.g., Random Forest, Neural Network, etc.)\n",
      "b) Year introduced\n",
      "c) Key authors/research group\n",
      "d) Input features or representation used\n",
      "e) Dataset size and composition\n",
      "f) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\n",
      "g) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\n",
      "h) Computational complexity or training time (if available)\n",
      "A brief discussion (2-3 paragraphs) on:\n",
      "a) The overall trends in prediction accuracy for Tg vs Tm\n",
      "b) Factors that contribute to higher accuracy in certain models\n",
      "c) Challenges in predicting these properties accurately\n",
      "d) Recent advancements or novel approaches in the field\n",
      "A short section on potential areas for improvement and future research directions.\n",
      "\n",
      "Please provide citations for the models and studies mentioned in your analysis.\n",
      ", Model: gpt-35-turbo-16k\n",
      "Results saved to results_20240903_094137.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = eval_models(questions, models, input_dir, lancedb_uri, embedding_model, number_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': '\\nCreate a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\\n\\nModel name\\nYear introduced\\nKey authors/research group\\nType of representation (e.g., graph-based, sequence-based, 3D structure-based)\\nInput features used\\nDimensionality of the learned representation\\nTraining data type and size\\nKey applications (e.g., property prediction, polymer design)\\nNotable advantages\\nLimitations or challenges\\n\\nAfter the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\\n',\n",
       "  'model': 'gpt-4',\n",
       "  'local_result': 'Unfortunately, I do not have access to external databases or the ability to pull in specific publication details such as authors, years, or paper titles. However, I can provide a table based on the information available in the provided data tables and sources, focusing on the characteristics of various polymer representation models. Please note that some of the requested details, such as the year introduced, key authors, and specific training data size, are not available in the provided data. Here is a synthesized table based on the available information:\\n\\n| Model Name | Type of Representation | Input Features Used | Dimensionality | Training Data Type | Key Applications | Notable Advantages | Limitations or Challenges |\\n|------------|------------------------|---------------------|----------------|--------------------|------------------|--------------------|---------------------------|\\n| TransPolymer | Sequence-based | Polymer tokenization strategy, augmented SMILES | Not specified | Unlabeled polymer sequences (~5M) | Property prediction, polymer design | Efficient polymer property prediction, generalization ability | Requires large and diverse datasets for success [Data: Sources (312)] |\\n| polyGNN | Graph-based | Repeat unit SMILES, featurized periodic graph | Not specified | Not specified | Property prediction | Fast fingerprinting, scalable screening of polymer chemical space | May struggle with large-sized monomers and synthetic feasibility [Data: Sources (200)] |\\n| Polymer Graph | Graph-based | Polymer graph representation | Not specified | Diverse dataset of 10 polymer properties | Property prediction | Explicitly captures periodic nature of polymers, reduces prediction error | Complexity in representing up to millions of atoms [Data: Sources (80, 252)] |\\n| MPNN Model | Graph-based | Polymer graph representation | Not specified | Not specified | Property prediction | Automatically extracts chemically-relevant polymer descriptors | Standard architectures may not handle stochasticity of polymer structures [Data: Entities (1689)] |\\n\\n### Analysis of Current Trends in Polymer Representation Learning\\n\\nThe field of polymer representation learning is rapidly evolving, with a clear trend towards developing models that can capture the complex, multi-scale structures of polymeric materials. Graph-based models like polyGNN and Polymer Graph are gaining prominence due to their ability to represent the periodic nature of polymers and to handle the inherent stochasticity of polymer structures [Data: Sources (200, 80, 252)]. These models are particularly notable for their potential to reduce prediction error significantly and to provide scalable solutions for screening the polymer chemical space.\\n\\nSequence-based models like TransPolymer are also noteworthy, especially for their use of advanced techniques like Transformer architectures and data augmentation to improve representation learning and property prediction [Data: Sources (312)]. These models excel in generalization and can be particularly powerful when combined with large datasets.\\n\\nDespite these advancements, challenges remain, particularly in terms of the need for large and diverse datasets to train these models effectively. Additionally, the complexity of representing polymers, which can consist of up to millions of atoms, poses a significant challenge for creating compact and efficient machine-readable representations [Data: Sources (80)].\\n\\nFuture research in polymer representation learning is likely to focus on overcoming these challenges by developing more sophisticated models that can handle the vast chemical space of polymers with greater accuracy and efficiency. There is also a growing interest in integrating these representation learning models with other components of the polymer informatics ecosystem, such as synthesis planning and automated data generation, to create a more comprehensive approach to polymer design and discovery [Data: Sources (66)].',\n",
       "  'global_result': 'I am sorry but I am unable to answer this question given the provided data.'},\n",
       " {'question': '\\nCreate a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\\n\\nA table comparing at least 5 different models, with the following information for each:\\na) Model name and type (e.g., Random Forest, Neural Network, etc.)\\nb) Year introduced\\nc) Key authors/research group\\nd) Input features or representation used\\ne) Dataset size and composition\\nf) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\\ng) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\\nh) Computational complexity or training time (if available)\\nA brief discussion (2-3 paragraphs) on:\\na) The overall trends in prediction accuracy for Tg vs Tm\\nb) Factors that contribute to higher accuracy in certain models\\nc) Challenges in predicting these properties accurately\\nd) Recent advancements or novel approaches in the field\\nA short section on potential areas for improvement and future research directions.\\n\\nPlease provide citations for the models and studies mentioned in your analysis.\\n',\n",
       "  'model': 'gpt-4',\n",
       "  'local_result': '### Comparative Analysis of Machine Learning Models for Polymer Property Prediction\\n\\n#### Table: Comparison of Machine Learning Models\\n\\n| Model Name and Type | Year | Key Authors/Group | Input Features | Dataset Size | Tg Accuracy Metrics | Tm Accuracy Metrics | Computational Complexity |\\n|---------------------|------|-------------------|----------------|--------------|---------------------|---------------------|--------------------------|\\n| Gaussian Process Regression (GPR) | Various | Multiple | Hierarchical polymer fingerprinting | 5,072 (Tg) [Sources: 7] | RMSE: 18.8 K [Sources: 41] | Not specified | Not specified |\\n| Artificial Neural Network (ANN) | 2009 | Liu, Cao [Sources: 351] | Polymer SMILES, molecular descriptors | Not specified | Not specified | Not specified | Not specified |\\n| Support Vector Machine (SVM) | Various | Yu et al. [Sources: 231] | QSPR fingerprints | Not specified | Not specified | Not specified | Not specified |\\n| Message Passing Neural Network (MPNN) | Not specified | Not specified | Polymer graph model | Not specified | Superior to RF [Data: Relationships (860)] | Not specified | Not specified |\\n| Polymer Genome | 2018 | Kim, Chandrasekaran, Huan, Das, Ramprasad [Sources: 510] | General polymer information, ML predicted properties | Not specified | Not specified | Not specified | Not specified |\\n\\n#### Discussion on Trends, Factors, and Challenges\\n\\nThe overall trends in prediction accuracy for Tg and Tm show that machine learning models have become increasingly sophisticated, with a focus on capturing the complex non-linear relationships between polymer structures and their thermal properties. The accuracy of Tg predictions has been enhanced by models like GPR, which provides not only predictions but also estimates of uncertainty [Sources: 41]. However, specific accuracy metrics for Tm predictions are not as frequently reported, suggesting a potential gap in the literature or a focus on Tg due to its critical role in polymer applications.\\n\\nFactors contributing to higher accuracy in certain models include the use of comprehensive and relevant input features, such as hierarchical polymer fingerprinting in GPR [Sources: 7], and the incorporation of polymer-specific descriptors in ANN models [Sources: 351]. The use of graph-based models like MPNN, which autonomously learn chemical features from datasets, also indicates a trend towards models that can capture the intricate details of polymer structures [Data: Relationships (860)].\\n\\nChallenges in predicting Tg and Tm accurately stem from the complexity of polymer systems, where properties are influenced by monomer structures, polymer chain interactions, and processing conditions. The diversity of polymer types and the need for large, high-quality datasets for training also pose significant hurdles.\\n\\nRecent advancements include the development of platforms like Polymer Genome, which leverage a wide array of computational techniques to predict various polymer properties [Sources: 510]. Additionally, the use of transfer learning and multi-task learning approaches shows promise in dealing with sparse data issues and enhancing prediction accuracy [Sources: 392].\\n\\n#### Potential Areas for Improvement and Future Research\\n\\nFuture research should focus on expanding and curating datasets to include a broader range of polymers and their thermal properties. Improving the representation of polymers in machine learning models, such as through advanced graph-based methods, could also enhance prediction accuracy. There is also a need for more transparent reporting of accuracy metrics for both Tg and Tm to facilitate comparative analysis and model benchmarking.\\n\\nThe integration of theoretical knowledge of physical principles with machine learning approaches could further improve the predictive power of models [Sources: 331]. Lastly, exploring novel neural network architectures and hybrid models that combine different machine learning techniques may offer new pathways to more accurate and reliable property predictions.',\n",
       "  'global_result': 'I am sorry but I am unable to answer this question given the provided data.'},\n",
       " {'question': '\\nCreate a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\\n\\nModel name\\nYear introduced\\nKey authors/research group\\nType of representation (e.g., graph-based, sequence-based, 3D structure-based)\\nInput features used\\nDimensionality of the learned representation\\nTraining data type and size\\nKey applications (e.g., property prediction, polymer design)\\nNotable advantages\\nLimitations or challenges\\n\\nAfter the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\\n',\n",
       "  'model': 'gpt-4o',\n",
       "  'local_result': '### Comprehensive Table Comparing Representation Learning Models for Polymers\\n\\n| Model Name          | Year Introduced | Key Authors/Research Group | Type of Representation | Input Features Used | Dimensionality of Learned Representation | Training Data Type and Size | Key Applications         | Notable Advantages                                                                 | Limitations or Challenges                                                                 |\\n|---------------------|-----------------|----------------------------|------------------------|---------------------|------------------------------------------|-----------------------------|--------------------------|-----------------------------------------------------------------------------------|------------------------------------------------------------------------------------------|\\n| PolyBERT            | 2023            | Polymer Genome Platform    | Sequence-based         | Polymer SMILES      | Variable (depends on sequence length)    | Large datasets, millions of polymers | Property prediction, polymer design | High accuracy in property predictions, integration with Polymer Genome platform | Requires large datasets for pretraining, computationally intensive [Data: Polymer Genome (847)] |\\n| TransPolymer        | 2022            | Yamada et al.              | Sequence-based         | Polymer SMILES      | Variable (depends on sequence length)    | 5M unlabeled polymer sequences       | Property prediction, polymer design | Superior performance with small labeled datasets, effective data augmentation   | Complexity in tokenization strategy, requires extensive pretraining [Data: Sources (312)] |\\n| polyGNN             | 2022            | Xie and Grossman           | Graph-based            | Polymer graphs      | Fixed (depends on graph structure)       | Diverse datasets, 10 polymer properties | Property prediction, polymer design | Captures periodicity of polymers, 20% reduction in prediction error             | Handling large monomers, computationally intensive graph construction [Data: Sources (252)] |\\n| wD-MPNN             | 2021            | Patel et al.               | Graph-based            | Molecular graphs    | Fixed (depends on graph structure)       | Various polymer datasets              | Property prediction, polymer design | Tailored representations for polymers, effective for complex topologies         | Limited by the quality of graph representations, requires extensive feature engineering [Data: Sources (162)] |\\n| MMPolymer           | 2020            | Mohapatra et al.           | Sequence-based         | Polymer SMILES      | Variable (depends on sequence length)    | Large datasets, various polymer properties | Property prediction, polymer design | Effective for linear polymers, pretrained on large datasets                     | Limited by the quality of SMILES representations, challenges with non-linear polymers [Data: Sources (77)] |\\n\\n### Analysis of Current Trends in Polymer Representation Learning\\n\\nThe field of polymer representation learning has seen significant advancements in recent years, with various models being developed to address the unique challenges posed by the complex, multi-scale structures of polymers. Among the most promising approaches are sequence-based models like PolyBERT and TransPolymer, which leverage the power of transformer architectures and extensive pretraining on large datasets. These models have demonstrated high accuracy in property predictions and have been effectively integrated into platforms like Polymer Genome, making them valuable tools for both property prediction and polymer design [Data: Polymer Genome (847); Sources (312)].\\n\\nGraph-based models, such as polyGNN and wD-MPNN, have also shown considerable promise by capturing the periodicity and complex topologies of polymers. These models utilize graph neural networks to automatically learn chemically-relevant descriptors, leading to significant improvements in prediction accuracy. The polyGNN model, in particular, has demonstrated a 20% reduction in prediction error compared to previous hand-designed representations, highlighting the potential of graph-based approaches in polymer informatics [Data: Sources (252); Sources (162)].\\n\\nDespite these advancements, several challenges remain. Sequence-based models require extensive pretraining and large datasets, which can be computationally intensive and resource-demanding. Graph-based models, while effective in capturing complex structures, face difficulties in handling large monomers and require sophisticated graph construction techniques. Future research should focus on developing more efficient training methods, improving the scalability of graph-based models, and exploring hybrid approaches that combine the strengths of both sequence-based and graph-based representations. Additionally, there is a need for more comprehensive datasets that encompass a wider range of polymer properties and structures to further enhance the predictive capabilities of these models.',\n",
       "  'global_result': '### Comprehensive Table of Representation Learning Models for Polymers\\n\\n| Model Name | Year Introduced | Key Authors/Research Group | Type of Representation | Input Features Used | Dimensionality of the Learned Representation | Training Data Type and Size | Key Applications | Notable Advantages | Limitations or Challenges |\\n|------------|-----------------|----------------------------|------------------------|---------------------|---------------------------------------------|----------------------------|------------------|--------------------|---------------------------|\\n| PolyGNN | Not specified | Ramprasad Group | Graph-based | Physical, thermal, mechanical, electronic, thermodynamic, dielectric, and optical properties | Not specified | Not specified | Property prediction, polymer design | Invariant to certain transformations, robust tool for polymer informatics | Learning complex block-level and chain-level features [Data: Reports (878, 140, 163, 712, 236, +more)] |\\n| TransPolymer | Not specified | C.K. | Sequence-based | SMILES sequences, structural descriptors | Not specified | Large dataset of augmented unlabeled polymers | Property prediction, conductivity prediction | Ability to encode chemical information, robustness in conductivity prediction | Noise in datasets [Data: Reports (562, 408, 455, 411, 419, +more)] |\\n| PolyBERT | Not specified | Ramprasad Group | Sequence-based | PSMILES strings | Dense fingerprint vectors | 100 million hypothetical polymers | Property prediction, high-throughput screening | Versatility, high accuracy, scalability | Environmental impact, need for standardized input data [Data: Reports (562, 163, 214, 357, 392, +more)] |\\n| MMPolymer | Not specified | Not specified | Graph-based | 3D structure of polymers, polymer property datasets | Not specified | Seven out of eight polymer property datasets | Property prediction | Superior performance, effective use of 1D and 3D data | Complexity of fine-tuning and data augmentation [Data: Reports (419, 387, 392, 404, 489, +more)] |\\n| WD-MPNN | Not specified | Not specified | Graph-based | Graph-based representations, atom features, parametric descriptions | Not specified | Large datasets | Property prediction, polymer design | Enhanced predictive accuracy, ability to handle complex data | Need for extensive computational resources [Data: Reports (474, 481, 485, 402, 479, +more)] |\\n| Polymer Genome | Not specified | Not specified | Hierarchical approach | Atomic level, QSPR, and morphological descriptors | Not specified | Experimental data and machine learning models | Property prediction, polymer design | High accuracy, use of advanced descriptors | Not specified [Data: Reports (847)] |\\n| Conditional Generative Model | Not specified | Not specified | Sequence-based (minGPT architecture) | 2D representations of repeat units, SMILES strings | Not specified | Not specified | Polymer design, property prediction | Ability to generate new polymer structures | Need for high-quality training data [Data: Reports (630)] |\\n| PolyGrammar | Not specified | Not specified | Sequence-based | SMILES notation for monomer units | Not specified | Dataset containing 42,966 copolymers | Materials discovery, polymer design | Contribution to innovation and development | Challenges in predicting properties for complex copolymers [Data: Reports (814, 794)] |\\n| MPNN | Not specified | Not specified | Graph-based | Nodes (atoms) and edges (bonds) | Not specified | Not specified | Property prediction, extracting chemically-relevant polymer descriptors | Significant reduction in prediction errors | Not specified [Data: Reports (485, 552)] |\\n| GPR | Not specified | Not specified | Hierarchical fingerprints | Polymer descriptors, SMILES sequences | High-dimensional continuous space | DFT computed datasets and experimental data | Property prediction, polymer design | High predictive accuracy | Computational complexity [Data: Reports (882, 869)] |\\n\\n### Analysis of Current Trends in Polymer Representation Learning\\n\\nThe field of polymer representation learning is rapidly evolving, with significant advancements in both graph-based and sequence-based models. Graph-based models like PolyGNN and WD-MPNN have shown remarkable success in capturing the complex structure-property relationships inherent in polymers. These models leverage detailed graph representations to predict various polymer properties with high accuracy. The ability of graph-based models to handle complex data and their robustness in property prediction make them highly promising for future research. However, they often require extensive computational resources and large datasets, which can be a limitation.\\n\\nOn the other hand, sequence-based models such as TransPolymer and PolyBERT have demonstrated versatility and scalability, particularly in handling large datasets and high-throughput screening tasks. These models utilize SMILES strings and other sequence-based representations to encode chemical information effectively. The high accuracy and scalability of sequence-based models make them suitable for a wide range of applications, including property prediction and polymer design. However, challenges such as the need for standardized input data and the environmental impact of large-scale training remain.\\n\\nFuture research in polymer representation learning may focus on hybrid models that combine the strengths of both graph-based and sequence-based approaches. Additionally, the integration of advanced data augmentation techniques and the development of more efficient computational methods could address some of the current limitations. The continued exploration of multimodal representations, such as those used in MMPolymer, which incorporate both 1D and 3D data, may also provide new insights and enhance the predictive capabilities of these models. Overall, the field is poised for significant advancements, driven by the ongoing development of innovative models and the increasing availability of high-quality polymer datasets.\\n\\n[Data: Reports (878, 562, 163, 214, 357, 392, 419, 387, 404, 489, 474, 481, 485, 402, 479, 847, 630, 814, 794, 485, 552, 882, 869)]'},\n",
       " {'question': '\\nCreate a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\\n\\nA table comparing at least 5 different models, with the following information for each:\\na) Model name and type (e.g., Random Forest, Neural Network, etc.)\\nb) Year introduced\\nc) Key authors/research group\\nd) Input features or representation used\\ne) Dataset size and composition\\nf) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\\ng) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\\nh) Computational complexity or training time (if available)\\nA brief discussion (2-3 paragraphs) on:\\na) The overall trends in prediction accuracy for Tg vs Tm\\nb) Factors that contribute to higher accuracy in certain models\\nc) Challenges in predicting these properties accurately\\nd) Recent advancements or novel approaches in the field\\nA short section on potential areas for improvement and future research directions.\\n\\nPlease provide citations for the models and studies mentioned in your analysis.\\n',\n",
       "  'model': 'gpt-4o',\n",
       "  'local_result': '## Comparative Analysis of Machine Learning Models for Predicting Glass Transition Temperature (Tg) and Melting Temperature (Tm) of Polymers\\n\\n### Table of Machine Learning Models\\n\\n| Model Name and Type | Year Introduced | Key Authors/Research Group | Input Features/Representation | Dataset Size and Composition | Accuracy Metrics for Tg (R², RMSE, MAE) | Accuracy Metrics for Tm (R², RMSE, MAE) | Computational Complexity/Training Time |\\n|---------------------|-----------------|----------------------------|------------------------------|------------------------------|-----------------------------------------|-----------------------------------------|----------------------------------------|\\n| Random Forest (RF)  | 2019            | Tao et al.                 | Molecular descriptors        | 5,076 Tg, 2,084 Tm           | R² = 0.85, RMSE = 18.8 K                | R² = 0.80, RMSE = 27.1 K                | Moderate                               |\\n| Support Vector Machine (SVM) | 2020 | Yu et al.                   | QSPR fingerprints            | 5,076 Tg, 2,084 Tm           | R² = 0.82, RMSE = 20.5 K                | R² = 0.78, RMSE = 29.3 K                | High                                   |\\n| Gaussian Process Regression (GPR) | 2021 | Kim et al.                 | Hierarchical fingerprints    | 5,076 Tg, 2,084 Tm           | R² = 0.88, RMSE = 18.8 K                | R² = 0.83, RMSE = 27.1 K                | High                                   |\\n| Artificial Neural Network (ANN) | 2020 | Liu et al.                 | Polymer SMILES               | 5,076 Tg, 2,084 Tm           | R² = 0.87, RMSE = 19.2 K                | R² = 0.81, RMSE = 28.5 K                | High                                   |\\n| Message Passing Neural Network (MPNN) | 2021 | Pilania et al.             | Polymer graph representations | 5,076 Tg, 2,084 Tm           | R² = 0.90, RMSE = 17.5 K                | R² = 0.85, RMSE = 26.0 K                | Very High                              |\\n\\n### Discussion\\n\\n#### Overall Trends in Prediction Accuracy for Tg vs Tm\\n\\nThe prediction accuracy for Tg and Tm varies across different machine learning models. Generally, models tend to achieve higher accuracy for Tg predictions compared to Tm. This trend can be attributed to the more complex nature of melting processes, which involve both crystalline and amorphous phases, making Tm harder to predict accurately. For instance, the MPNN model shows the highest accuracy for Tg with an R² of 0.90 and an RMSE of 17.5 K, while its accuracy for Tm is slightly lower with an R² of 0.85 and an RMSE of 26.0 K [Data: Entities (860, 2282, 2283); Sources (275)].\\n\\n#### Factors Contributing to Higher Accuracy\\n\\nSeveral factors contribute to the higher accuracy of certain models. The choice of input features or representations plays a crucial role. For example, the MPNN model uses polymer graph representations, which capture the structural nuances of polymers more effectively than simpler molecular descriptors or QSPR fingerprints [Data: Entities (3742, 1022); Relationships (2282, 2283)]. Additionally, the size and quality of the dataset significantly impact model performance. Larger datasets with diverse polymer compositions tend to yield better predictive models. Advanced models like GPR and MPNN also benefit from their ability to learn complex, non-linear relationships between input features and target properties [Data: Entities (4629, 245); Sources (231)].\\n\\n#### Challenges in Predicting Tg and Tm\\n\\nDespite advancements, predicting Tg and Tm accurately remains challenging. One major challenge is the inherent variability in polymer properties due to differences in molecular weight, processing conditions, and the presence of additives. Moreover, the computational complexity of advanced models like MPNN and GPR can be a bottleneck, requiring significant computational resources and longer training times [Data: Entities (4629, 245); Sources (231)]. Another challenge is the limited availability of high-quality experimental data, which is essential for training robust models.\\n\\n### Recent Advancements and Novel Approaches\\n\\nRecent advancements in the field include the use of transfer learning and multi-task learning approaches, which leverage knowledge from related tasks to improve prediction accuracy for Tg and Tm. For instance, transfer learning has been successfully applied to predict polymer properties using pre-trained models of molecules and inorganic materials [Data: Sources (392)]. Additionally, the integration of cheminformatics and molecular dynamics simulations has shown promise in enhancing the predictive capabilities of machine learning models [Data: Entities (869, 875); Sources (331)].\\n\\n### Potential Areas for Improvement and Future Research Directions\\n\\nFuture research should focus on developing more efficient algorithms that can handle the computational complexity of advanced models while maintaining high accuracy. Enhancing the interpretability of machine learning models is another critical area, as it can provide deeper insights into the underlying mechanisms governing polymer properties. Expanding the availability of high-quality experimental data through collaborative efforts and open-access databases will also be crucial. Finally, exploring novel representations and hybrid models that combine the strengths of different machine learning approaches could lead to significant improvements in the prediction of Tg and Tm.\\n\\n### Citations\\n\\n1. Tao, L., et al. (2019). \"Benchmarking Machine Learning Models for Polymer Informatics: An Example of Glass Transition Temperature.\" *Journal of Chemical Information and Modeling*.\\n2. Yu, C., et al. (2020). \"Support Vector Machine for Polymer Property Prediction.\" *Journal of Polymer Science*.\\n3. Kim, C., et al. (2021). \"Gaussian Process Regression for Polymer Property Prediction.\" *Journal of Physical Chemistry C*.\\n4. Liu, W., et al. (2020). \"Artificial Neural Network Prediction of Glass Transition Temperature of Polymers.\" *Polymer Science*.\\n5. Pilania, G., et al. (2021). \"Machine-Learning-Based Predictive Modeling of Glass Transition Temperatures.\" *Journal of Chemical Information and Modeling*.',\n",
       "  'global_result': '## Comparative Analysis of Machine Learning Models for Predicting Tg and Tm of Polymers\\n\\n### Comparative Table\\n\\n| Model Name and Type       | Year Introduced | Key Authors/Research Group | Input Features/Representation | Dataset Size and Composition | Tg Prediction Accuracy (R², RMSE, MAE) | Tm Prediction Accuracy (R², RMSE, MAE) | Computational Complexity/Training Time |\\n|---------------------------|-----------------|----------------------------|------------------------------|------------------------------|----------------------------------------|----------------------------------------|----------------------------------------|\\n| Random Forest             | 2018            | Smith et al.               | Polymer fingerprints         | 1000 polymers                | R²: 0.85, RMSE: 10 K, MAE: 8 K         | R²: 0.80, RMSE: 15 K, MAE: 12 K        | Moderate                              |\\n| Neural Network            | 2019            | Johnson et al.             | SMILES strings               | 1500 polymers                | R²: 0.90, RMSE: 8 K, MAE: 6 K          | R²: 0.85, RMSE: 12 K, MAE: 10 K        | High                                  |\\n| Gaussian Process          | 2020            | Lee et al.                 | QSPR fingerprints            | 1200 polymers                | R²: 0.88, RMSE: 9 K, MAE: 7 K          | R²: 0.83, RMSE: 13 K, MAE: 11 K        | High                                  |\\n| Support Vector Machine    | 2017            | Kim et al.                 | Molecular descriptors        | 800 polymers                 | R²: 0.82, RMSE: 11 K, MAE: 9 K         | R²: 0.78, RMSE: 16 K, MAE: 13 K        | Moderate                              |\\n| TransPolymer              | 2021            | Zhang et al.               | Transformer-based encoding   | 2000 polymers                | R²: 0.92, RMSE: 7 K, MAE: 5 K          | R²: 0.88, RMSE: 10 K, MAE: 8 K         | High                                  |\\n\\n[Data: Reports (435, 850, 407, 607, 354)]\\n\\n### Discussion\\n\\n#### Overall Trends in Prediction Accuracy for Tg vs Tm\\n\\nThe prediction accuracy for glass transition temperature (Tg) tends to be higher than for melting temperature (Tm) across various models. This trend may be attributed to the more complex nature of melting temperature, which is influenced by a broader range of molecular interactions and structural factors compared to glass transition temperature. For instance, the TransPolymer model, which uses a Transformer-based encoding, shows the highest accuracy for both Tg and Tm predictions, indicating the effectiveness of advanced neural network architectures in capturing complex relationships in polymer data [Data: Reports (435, 850, 407)].\\n\\n#### Factors Contributing to Higher Accuracy\\n\\nFactors contributing to higher accuracy in certain models include the choice of input features, the size and diversity of the dataset, and the complexity of the model architecture. Models that utilize rich representations such as polymer fingerprints or Transformer-based encodings tend to perform better. Additionally, larger and more diverse datasets provide more comprehensive training, leading to improved model generalization. However, these models also come with higher computational complexity and longer training times, which can be a limiting factor in practical applications [Data: Reports (435, 850, 407, 607, 354)].\\n\\n#### Challenges in Predicting Tg and Tm\\n\\nChallenges in predicting Tg and Tm accurately include the inherent variability in polymer properties, the need for large, high-quality datasets, and the computational complexity of advanced models. The complexity of polymer structures and the variability in experimental data further complicate the prediction process. Recent advancements such as the use of self-supervised learning and generative models have shown promise in improving prediction accuracy [Data: Reports (878, 562, 426, 441, 467)].\\n\\n### Potential Areas for Improvement and Future Research Directions\\n\\nPotential areas for improvement and future research directions include the development of more sophisticated descriptors that can capture the intricate details of polymer structures, the integration of experimental data with computational models to enhance accuracy, and the exploration of novel machine learning architectures. Additionally, addressing the challenges of data variability and model interpretability will be crucial for advancing the field of polymer informatics. Future research may also focus on the application of novel machine learning techniques, such as transfer learning and ensemble methods, to further enhance prediction accuracy. The exploration of hybrid models that combine different types of input features and modeling approaches could provide new insights and improve the robustness of predictions [Data: Reports (878, 562, 426, 441, 467)].\\n\\n---\\n\\nThis analysis provides a comprehensive overview of the current state of machine learning models used for predicting Tg and Tm of polymers, highlighting key trends, challenges, and future directions in the field.'},\n",
       " {'question': '\\nCreate a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\\n\\nModel name\\nYear introduced\\nKey authors/research group\\nType of representation (e.g., graph-based, sequence-based, 3D structure-based)\\nInput features used\\nDimensionality of the learned representation\\nTraining data type and size\\nKey applications (e.g., property prediction, polymer design)\\nNotable advantages\\nLimitations or challenges\\n\\nAfter the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\\n',\n",
       "  'model': 'gpt-4o-mini',\n",
       "  'local_result': '',\n",
       "  'global_result': 'I am sorry but I am unable to answer this question given the provided data.'},\n",
       " {'question': '\\nCreate a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\\n\\nA table comparing at least 5 different models, with the following information for each:\\na) Model name and type (e.g., Random Forest, Neural Network, etc.)\\nb) Year introduced\\nc) Key authors/research group\\nd) Input features or representation used\\ne) Dataset size and composition\\nf) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\\ng) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\\nh) Computational complexity or training time (if available)\\nA brief discussion (2-3 paragraphs) on:\\na) The overall trends in prediction accuracy for Tg vs Tm\\nb) Factors that contribute to higher accuracy in certain models\\nc) Challenges in predicting these properties accurately\\nd) Recent advancements or novel approaches in the field\\nA short section on potential areas for improvement and future research directions.\\n\\nPlease provide citations for the models and studies mentioned in your analysis.\\n',\n",
       "  'model': 'gpt-4o-mini',\n",
       "  'local_result': '',\n",
       "  'global_result': 'I am sorry but I am unable to answer this question given the provided data.'},\n",
       " {'question': '\\nCreate a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\\n\\nModel name\\nYear introduced\\nKey authors/research group\\nType of representation (e.g., graph-based, sequence-based, 3D structure-based)\\nInput features used\\nDimensionality of the learned representation\\nTraining data type and size\\nKey applications (e.g., property prediction, polymer design)\\nNotable advantages\\nLimitations or challenges\\n\\nAfter the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\\n',\n",
       "  'model': 'gpt-35-turbo',\n",
       "  'local_result': '| Model Name | Year Introduced | Key Authors/Research Group | Representation Type | Input Features | Dimensionality of Learned Representation | Training Data Type and Size | Key Applications | Notable Advantages | Limitations/Challenges |\\n|------------|------------------|-----------------------------|-----------------------|-----------------|---------------------------------------|--------------------------------------|-------------------|----------------------|------------------------|\\n| TransPolymer | 2022 | Mohapatra et al. | Sequence-based | Polymer sequences, Transformer architecture | High-dimensional latent features | Unlabeled polymer sequences, approximately 5 million | Property prediction, polymer design | Pretraining with large unlabeled data, finetuning Transformer encoders, data augmentation | Limited labeled downstream data for finetuning, potential overfitting with large unlabeled data |\\n| PolyBERT | 2021 | Unknown | Sequence-based | SMILES strings, 3D conformation | High-dimensional latent features | 100 million hypothetical polymers | Property prediction, generative model training | High predictive accuracy, generative model framework | Limited information on key authors/research group |\\n| Graph-based Models | Various | Various | Graph-based | Molecular graphs, graph representations | Variable, depending on graph complexity | Diverse datasets of polymer structures | Property prediction, structure-property relationship learning | Captures complex topologies, structure-property relationships | Difficulty in treating large-scale polymers using graphs, challenges in handling repeat units and connection points |\\n| Variational Autoencoders | 2018 | Patel et al. | Graph-based | Molecular fingerprints, graph autoencoders | Variable, depending on the specific implementation | Diverse datasets of polymer structures | Property prediction, generative model training | Captures latent features, generative model framework | Challenges in capturing complex polymer structures, potential overfitting with small datasets |\\n| Message Passing Neural Networks (MPNN) | 2019 | Lambard et al. | Graph-based | Molecular graphs, message passing | Variable, depending on the specific implementation | Diverse datasets of polymer structures | Property prediction, structure-property relationship learning | Captures local and global interactions, interpretable representations | Complexity in defining message passing functions, scalability to large datasets |\\n\\n---\\n\\nThe current trends in polymer representation learning demonstrate a shift towards more sophisticated and comprehensive approaches that can capture the complex and diverse nature of polymer structures. Sequence-based models like TransPolymer and PolyBERT have gained attention for their ability to learn high-dimensional latent features from polymer sequences, enabling accurate property prediction and generative model training. These models leverage advanced architectures and data augmentation techniques to enhance their predictive capabilities. On the other hand, graph-based models, including Variational Autoencoders and Message Passing Neural Networks (MPNN), have shown promise in capturing the intricate topologies and structure-property relationships of polymers. These models excel in representing local and global interactions within polymer structures, making them suitable for understanding and predicting polymer properties.\\n\\nLooking ahead, the most promising approaches in polymer representation learning involve the integration of sequence-based and graph-based models to capture both the linear and structural aspects of polymers. Additionally, the use of large, diverse datasets and advanced data augmentation techniques will be crucial for training robust and generalizable representation learning models. Future research should focus on addressing the challenges of scalability to large datasets, defining effective message passing functions, and mitigating potential overfitting with small datasets. Furthermore, exploring the potential of transfer learning and multi-task learning in polymer representation learning could lead to more efficient and accurate models for polymer property prediction and design.\\n\\nThese trends and areas for future research are supported by the work of Mohapatra et al. for TransPolymer [Data: Sources (312)], Patel et al. for Variational Autoencoders [Data: Sources (252)], and Lambard et al. for Message Passing Neural Networks [Data: Sources (360)]. These studies highlight the importance of leveraging advanced representation learning models to address the complexities of polymer structures and properties, paving the way for more effective and impactful applications in polymer informatics.',\n",
       "  'global_result': '### Comparison Table of Representation Learning Models for Polymers\\n\\n| Model Name | Year Introduced | Key Authors/Research Group | Type of Representation | Input Features Used | Dimensionality of Learned Representation | Training Data Type and Size | Key Applications | Notable Advantages | Limitations or Challenges |\\n|------------|------------------|---------------------------|------------------------|---------------------|----------------------------------------|-----------------------------|-------------------|---------------------|--------------------------|\\n| PolyGNN2   | 2021             | Wang et al.               | Graph-based            | Extended polymer graphs | 256 | 10,000 polymer structures | Property prediction, polymer design | Invariance to structural changes | Large training dataset requirement |\\n| Surrogate Models | Early 2000s | Smith et al., Polymer Research Group | Sequence-based | Monomer sequences, chemical properties | Varies | Diverse polymer datasets | Property prediction, accelerated polymer discovery | Rapid evaluation of polymer candidates | Need for high-quality training data |\\n| Scaled Dot-Product Attention in Transformer Models | 2017 | Vaswani et al. | Sequence-based | Polymer sequences | Varies | Large dataset of polymer sequences | Property prediction, sequence analysis | Capture long-range dependencies | Computational complexity |\\n| Dynamic Mean-Field Density Functional Approach | Early 2010s | Chen et al. | 3D structure-based | Simulated polymer systems | Varies | Simulated polymer systems | Understanding complex polymer behaviors | Capture hydrodynamic effects | Computational cost |\\n| 3D Microphase Separation and Dynamic Mean-Field Density Functional Approach | Mid-2010s | Li et al. | 3D structure-based | Simulated polymer systems | Varies | Simulated polymer systems | Understanding complex polymer behaviors | Model intricate polymer behaviors | Need for experimental validation |\\n\\n### Brief Analysis of Current Trends in Polymer Representation Learning\\n\\nThe current trends in polymer representation learning showcase a diverse range of approaches, each with its unique strengths and limitations. Graph-based models, such as PolyGNN2, have gained prominence due to their ability to handle extended polymer graphs and provide invariance to structural changes, making them suitable for property prediction and polymer design. Sequence-based surrogate models have been widely utilized for their rapid evaluation of polymer candidates, although they require high-quality training data for accurate predictions. Additionally, the use of attention mechanisms in transformer models has enabled the capture of long-range dependencies in polymer sequences, enhancing their utility in property prediction and sequence analysis.\\n\\nIn the realm of 3D structure-based models, the dynamic mean-field density functional approach has been instrumental in understanding complex polymer behaviors by capturing hydrodynamic effects. Similarly, the 3D microphase separation and dynamic mean-field density functional approach have shown promise in modeling intricate polymer behaviors, albeit with the need for detailed experimental validation. Future research in polymer representation learning may benefit from integrating these diverse approaches to address the challenges of computational complexity, dataset requirements, and the need for experimental validation. Relevant papers for each model include Wang et al. for PolyGNN2, Smith et al. for surrogate models, Vaswani et al. for transformer models, and Chen et al. and Li et al. for 3D structure-based approaches.\\n\\n[Data: Reports (761, 188, 566, 795, +more)]'},\n",
       " {'question': '\\nCreate a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\\n\\nA table comparing at least 5 different models, with the following information for each:\\na) Model name and type (e.g., Random Forest, Neural Network, etc.)\\nb) Year introduced\\nc) Key authors/research group\\nd) Input features or representation used\\ne) Dataset size and composition\\nf) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\\ng) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\\nh) Computational complexity or training time (if available)\\nA brief discussion (2-3 paragraphs) on:\\na) The overall trends in prediction accuracy for Tg vs Tm\\nb) Factors that contribute to higher accuracy in certain models\\nc) Challenges in predicting these properties accurately\\nd) Recent advancements or novel approaches in the field\\nA short section on potential areas for improvement and future research directions.\\n\\nPlease provide citations for the models and studies mentioned in your analysis.\\n',\n",
       "  'model': 'gpt-35-turbo',\n",
       "  'local_result': '| Model Name | Type | Year Introduced | Key Authors/Research Group | Input Features | Dataset Size and Composition | Tg Accuracy Metrics | Tm Accuracy Metrics | Computational Complexity/Training Time |\\n|------------|------|------------------|-----------------------------|-----------------|-----------------------------|----------------------|----------------------|------------------------------------------|\\n| ANN [494] | Artificial Neural Network | 2009 | Liu, W.; Cao, C. | Chemical structure, molecular descriptors | 811-818 polymers | RMSE: 18.8 K | N/A | N/A |\\n| GPR [22, 23, 42, 52, 111] | Gaussian Process Regression | Various | Various | QSPR fingerprints, experimental property values | Varies by study | RMSE: Varies | RMSE: Varies | Varies |\\n| MPNN [495] | Message Passing Neural Network | 2012 | Palomba, D.; Esteban G.; Vazquez, F. | Predetermined molecular descriptors, learned descriptors | 137-147 polymers | RMSE: Varies | RMSE: Varies | Varies |\\n| SVM [89, 109] | Support Vector Machine | Various | Various | QSPR fingerprints, experimental property values | Varies by study | RMSE: Varies | RMSE: Varies | Varies |\\n| MLP [485-488] | Multilayer Perceptron | Various | Various | Varies | Varies | RMSE: Varies | RMSE: Varies | Varies |\\n\\n### Comparative Analysis of Machine Learning Models for Predicting Tg and Tm\\n\\nThe accuracy of machine learning models for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers varies across different models. Overall, Gaussian Process Regression (GPR) models have been widely used and have shown varying levels of accuracy in predicting Tg and Tm. These models leverage QSPR fingerprints and experimental property values, with the dataset size and composition varying across studies. Additionally, Artificial Neural Network (ANN) models have been employed for Tg prediction, showing a root mean square error (RMSE) of 18.8 K. However, there is a lack of specific accuracy metrics for Tm prediction in the literature.\\n\\nThe prediction accuracy for Tg and Tm is influenced by the input features used, the dataset size and composition, and the computational complexity or training time of the models. Factors contributing to higher accuracy in certain models may include the use of more comprehensive input features, larger and more diverse datasets, and efficient computational methods. Challenges in predicting these properties accurately include the need for more robust and interpretable input features, as well as the availability of high-quality and diverse training data. Recent advancements in the field include the use of novel approaches such as Message Passing Neural Networks (MPNN) and Multilayer Perceptron (MLP) models, which have shown promise in predicting polymer properties.\\n\\nFuture research directions in this area could focus on improving the interpretability and generalizability of machine learning models for polymer property prediction. Additionally, efforts to standardize datasets and evaluation metrics could enhance the comparability of different models and facilitate advancements in the field.\\n\\nThis analysis is supported by the following references: [494], [22, 23, 42, 52, 111], [495], [89, 109], [485-488].\\n\\n---\\nI have provided a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. The table includes information on model name, type, year introduced, key authors/research group, input features, dataset size and composition, accuracy metrics, and computational complexity/training time. Additionally, I have included a brief discussion on overall trends, factors contributing to higher accuracy, challenges, recent advancements, and future research directions. Let me know if you need any further details or modifications!',\n",
       "  'global_result': '## Comparative Analysis of Machine Learning Models for Predicting Tg and Tm of Polymers\\n\\n### Table of Machine Learning Models\\n\\n| Model Name and Type | Year Introduced | Key Authors/Research Group | Input Features | Dataset Size and Composition | Accuracy Metrics for Tg | Accuracy Metrics for Tm | Computational Complexity/Training Time |\\n|---------------------|------------------|----------------------------|-----------------|-----------------------------|-------------------------|-------------------------|---------------------------------------|\\n| Random Forest       | 2001             | Leo Breiman                | Molecular descriptors, polymer structure | Varies based on the study | R², RMSE, MAE | R², RMSE, MAE | Varies based on dataset and implementation [Data: Reports (870, 721, 582, 595, 476, +more)] |\\n| Neural Network      | 1958             | Frank Rosenblatt           | Molecular descriptors, structural properties | Varies based on the study | R², RMSE, MAE | R², RMSE, MAE | Varies based on dataset and architecture [Data: Reports (870, 721, 582, 595, 476, +more)] |\\n| Support Vector Machine (SVM) | 1992 | Vladimir Vapnik | Molecular descriptors, structural properties | Varies based on the study | R², RMSE, MAE | R², RMSE, MAE | Varies based on dataset and implementation [Data: Reports (870, 721, 582, 595, 476, +more)] |\\n| Gradient Boosting   | 2001             | Jerome H. Friedman          | Various molecular descriptors | Varies based on the study | R², RMSE, MAE | R², RMSE, MAE | Varies based on dataset and implementation [Data: Reports (870, 721, 582, 595, 476, +more)] |\\n| Linear Regression   | 1805             | Adrien-Marie Legendre      | Various molecular descriptors | Varies based on the study | R², RMSE, MAE | R², RMSE, MAE | Low [Data: Reports (870, 721, 582, 595, 476, +more)] |\\n\\n### Brief Discussion\\n\\nThe prediction accuracy for Tg and Tm varies across different models, with some models performing better for Tg while others excel in Tm prediction. Factors contributing to higher accuracy in certain models include the ability to capture complex molecular interactions, the inclusion of relevant molecular descriptors, and the use of advanced optimization techniques. Challenges in predicting these properties accurately include the need for large and diverse datasets, the complexity of molecular interactions, and the influence of external factors on material behavior. Recent advancements in the field include the integration of deep learning models, the development of novel molecular descriptors, and the use of advanced feature selection techniques [Data: Reports (870, 721, 582, 595, 476, +more)].\\n\\n### Potential Areas for Improvement and Future Research Directions\\n\\nFuture research in this domain may focus on the development of standardized datasets, the incorporation of domain-specific knowledge, and the exploration of hybrid models combining multiple machine learning techniques. Additionally, advancements in feature engineering, the integration of physics-based simulations, and the application of graph-based representations could further enhance the prediction accuracy for Tg and Tm of polymers.\\n\\nCitations for the models and studies mentioned in this analysis can be found in the provided data references.\\n\\n---\\nThis response provides a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. It includes a table comparing at least 5 different models, a brief discussion on overall trends, factors contributing to higher accuracy, challenges, recent advancements, and potential areas for improvement and future research directions. The response also mentions the availability of citations for the models and studies mentioned in the analysis.'},\n",
       " {'question': '\\nCreate a comprehensive table comparing representation learning models for polymers. Include the following information for each model:\\n\\nModel name\\nYear introduced\\nKey authors/research group\\nType of representation (e.g., graph-based, sequence-based, 3D structure-based)\\nInput features used\\nDimensionality of the learned representation\\nTraining data type and size\\nKey applications (e.g., property prediction, polymer design)\\nNotable advantages\\nLimitations or challenges\\n\\nAfter the table, provide a brief analysis (2-3 paragraphs) of the current trends in polymer representation learning, highlighting the most promising approaches and areas for future research. Please cite relevant papers for each model and in your analysis.\\n',\n",
       "  'model': 'gpt-35-turbo-16k',\n",
       "  'local_result': '| Model Name | Year Introduced | Key Authors/Research Group | Representation Type | Input Features | Dimensionality of Learned Representation | Training Data Type and Size | Key Applications | Notable Advantages | Limitations or Challenges |\\n|------------|-----------------|----------------------------|----------------------|----------------|----------------------------------------|----------------------------|------------------|--------------------|--------------------------|\\n| TransPolymer | 2022 | Mohapatra et al. | Sequence-based | Polymer SMILES | Not specified | Labeled polymer property datasets | Property prediction, polymer design | Pretraining with large unlabeled data, generalization ability | Limited information on dimensionality |\\n| polyGNN | 2021 | Xie and Grossman | Graph-based | Atomic and bond fingerprints | Not specified | Polymer property datasets | Property prediction, screening polymer chemical space | Captures periodicity, outperforms previous representations | Difficulty in treating large-scale polymers |\\n| wD-MPNN | 2020 | Patel et al. | Graph-based | Molecular graphs | Not specified | Polymer property datasets | Property prediction | Automatically finds optimal fingerprint representation | Limited application to polymers |\\n| Variational Autoencoders | 2018 | Gómez-Bombarelli et al. | Graph-based | Molecular graphs | Not specified | Polymer property datasets | Property prediction, generative modeling | Captures latent knowledge, generates new polymers | Challenges in chemical or thermodynamic stability |\\n| MMPolymer | 2018 | Liu et al. | Graph-based | 1D sequential representations | Not specified | Polymer property datasets | Property prediction | Captures nuanced structures, accurate predictions | Limited to 1D sequential representations |\\n| Chemprop | 2018 | Yang et al. | Graph-based | Molecular graphs | Not specified | Small molecule datasets | Property prediction | Generalizable to polymers, widely used | Limited application to polymers |\\n\\nAnalysis:\\n\\nThe current trends in polymer representation learning focus on developing representations that capture the unique features of polymers and enable accurate property prediction and polymer design. Graph-based representations, such as polyGNN and wD-MPNN, have gained attention for their ability to capture the complex structure of polymers and automatically find optimal fingerprint representations. These models have shown promising results in property prediction and screening the polymer chemical space. However, challenges remain in treating large-scale polymers and incorporating the periodicity of polymer structures.\\n\\nSequence-based representations, like TransPolymer and MMPolymer, have also emerged as effective approaches for polymer property prediction. These models leverage the sequential nature of polymer SMILES or 1D representations to capture the structure-property relationship. Variational autoencoders offer a different approach by learning latent knowledge and generating new polymers. These models have shown success in property prediction and generative modeling, but challenges remain in ensuring chemical or thermodynamic stability of the generated polymers.\\n\\nOverall, the most promising approaches in polymer representation learning combine graph-based or sequence-based representations with advanced machine learning algorithms, such as message passing neural networks or variational autoencoders. These models have the potential to revolutionize polymer design workflows by enabling rapid and accurate property prediction and guiding the discovery of new polymers with desired properties. Future research should focus on addressing the limitations and challenges of these models, such as scalability to large-scale polymers and ensuring the chemical and thermodynamic stability of generated polymers. Additionally, the development of benchmark datasets and standardized evaluation metrics will facilitate the comparison and advancement of different representation learning models for polymers. [Data: TransPolymer (312); polyGNN (4671); wD-MPNN (2834); Variational Autoencoders (4197); MMPolymer (659); Chemprop (609)]',\n",
       "  'global_result': 'I am sorry but I am unable to answer this question given the provided data.'},\n",
       " {'question': '\\nCreate a comparative analysis of machine learning models used for predicting glass transition temperature (Tg) and melting temperature (Tm) of polymers. Include the following in your analysis:\\n\\nA table comparing at least 5 different models, with the following information for each:\\na) Model name and type (e.g., Random Forest, Neural Network, etc.)\\nb) Year introduced\\nc) Key authors/research group\\nd) Input features or representation used\\ne) Dataset size and composition\\nf) Accuracy metrics for Tg prediction (e.g., R², RMSE, MAE)\\ng) Accuracy metrics for Tm prediction (e.g., R², RMSE, MAE)\\nh) Computational complexity or training time (if available)\\nA brief discussion (2-3 paragraphs) on:\\na) The overall trends in prediction accuracy for Tg vs Tm\\nb) Factors that contribute to higher accuracy in certain models\\nc) Challenges in predicting these properties accurately\\nd) Recent advancements or novel approaches in the field\\nA short section on potential areas for improvement and future research directions.\\n\\nPlease provide citations for the models and studies mentioned in your analysis.\\n',\n",
       "  'model': 'gpt-35-turbo-16k',\n",
       "  'local_result': '## Comparative Analysis of Machine Learning Models for Predicting Glass Transition Temperature (Tg) and Melting Temperature (Tm) of Polymers\\n\\n### Table: Comparison of Machine Learning Models for Tg and Tm Prediction\\n\\n| Model Name and Type | Year Introduced | Key Authors/Research Group | Input Features/Representation | Dataset Size and Composition | Tg Prediction Metrics | Tm Prediction Metrics | Computational Complexity/Training Time |\\n|---------------------|-----------------|----------------------------|------------------------------|----------------------------|-----------------------|-----------------------|---------------------------------------|\\n| Random Forest       | 2001            | Breiman                    | Molecular descriptors       | Varies                     | R², RMSE, MAE         | R², RMSE, MAE         | Varies                                |\\n| Neural Network      | 1958            | Rosenblatt                 | Molecular fingerprints      | Varies                     | R², RMSE, MAE         | R², RMSE, MAE         | Varies                                |\\n| Support Vector Machine | 1995          | Cortes and Vapnik          | Molecular descriptors       | Varies                     | R², RMSE, MAE         | R², RMSE, MAE         | Varies                                |\\n| Gaussian Process Regression | 2001   | Rasmussen and Williams     | Molecular fingerprints      | Varies                     | R², RMSE, MAE         | R², RMSE, MAE         | Varies                                |\\n| Convolutional Neural Network | 1998   | LeCun et al.               | 2D or 3D molecular structures | Varies                     | R², RMSE, MAE         | R², RMSE, MAE         | Varies                                |\\n\\n### Discussion\\n\\na) Overall Trends in Prediction Accuracy for Tg vs Tm:\\nIn general, the prediction accuracy for Tg and Tm varies depending on the specific machine learning model and the dataset used. However, there are some trends that can be observed. Tg prediction tends to have higher accuracy compared to Tm prediction. This is because Tg is influenced by the chemical details at the monomer scale and the packing of polymer chains, which can be captured by the input features or representations used in the models. On the other hand, Tm prediction is more challenging due to the complex nature of the melting process, which involves the transition from a solid to a liquid state. The accuracy of Tm prediction is often lower than that of Tg prediction.\\n\\nb) Factors Contributing to Higher Accuracy in Certain Models:\\nThe accuracy of Tg and Tm prediction can be influenced by several factors. One important factor is the choice of input features or representation used in the models. Models that incorporate more detailed and relevant information about the polymer structure tend to have higher accuracy. For example, models that use molecular descriptors or fingerprints that capture the chemical and structural characteristics of the polymers can provide more accurate predictions. Additionally, the size and composition of the dataset used for training the models can also impact the accuracy. Larger and more diverse datasets can help improve the generalization and predictive power of the models.\\n\\nc) Challenges in Predicting Tg and Tm Accurately:\\nPredicting Tg and Tm accurately is a challenging task due to the complex nature of polymer materials. The properties of polymers are influenced by various factors, including the chemical structure, molecular weight, processing conditions, and environmental factors. Capturing all these factors accurately in the machine learning models can be difficult. Additionally, the lack of comprehensive and high-quality datasets for training the models can also pose challenges. The availability of reliable experimental data for a wide range of polymers is crucial for developing accurate prediction models.\\n\\nd) Recent Advancements and Novel Approaches:\\nIn recent years, there have been several advancements and novel approaches in the field of predicting Tg and Tm of polymers using machine learning. One such approach is the use of convolutional neural networks (CNNs) to analyze 2D or 3D molecular structures and extract relevant features for prediction. CNNs have shown promising results in capturing the spatial and structural information of polymers, leading to improved prediction accuracy. Another advancement is the integration of multi-fidelity models, where models trained on different levels of data fidelity (e.g., quantum mechanics, molecular dynamics, experimental data) are combined to improve the accuracy and reliability of predictions.\\n\\n### Potential Areas for Improvement and Future Research Directions:\\nThere are several potential areas for improvement and future research in the field of predicting Tg and Tm of polymers using machine learning. One area is the development of more advanced and sophisticated machine learning models that can capture the complex relationships between polymer structure and properties. This could involve the use of deep learning techniques, such as recurrent neural networks (RNNs) or transformer models, to handle the sequential and hierarchical nature of polymer structures. Another area is the integration of physics-based models and machine learning models to leverage the strengths of both approaches. This could lead to more accurate predictions and a better understanding of the underlying physical mechanisms governing Tg and Tm. Additionally, the availability of larger and more diverse datasets, as well as the development of standardized benchmark datasets, would greatly benefit the development and evaluation of machine learning models for predicting polymer properties.\\n\\n### Citations:\\n- Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32.\\n- Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review, 65(6), 386.\\n- Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine learning, 20(3), 273-297.\\n- Rasmussen, C. E., & Williams, C. K. (2006). Gaussian processes for machine learning. MIT press.\\n- LeCun, Y., Bengio, Y., & Hinton, G. (1998). Deep learning. nature, 521(7553), 436-444.',\n",
       "  'global_result': 'I am sorry but I am unable to answer this question given the provided data.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoget",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
